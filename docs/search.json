[{"path":"index.html","id":"preamble","chapter":"1 Preamble","heading":"1 Preamble","text":"manual aims providing training implementation genomics-enabled decision support NextGen Cassava Breeding Project community practice partnerships.Associated manual provide codebase standard operating procedures reproducible BreedBase-integrated workflow.Two major sections currently planned:Genomic (Mate) Selection Workflow Example: Using example dataset Cassavabase, work hands-, demos, full workflow. Provide skeleton pipeline segment: purpose, SOP, checklist, template, necessary inputs, KPI outputs.Genomic (Mate) Selection Workflow Example: Using example dataset Cassavabase, work hands-, demos, full workflow. Provide skeleton pipeline segment: purpose, SOP, checklist, template, necessary inputs, KPI outputs.Data wrangling reproducibility: Intro hands-computing data environment / manipulation side things. Learning resources/links. excel! R, Tidyverse, functions, loops, bash / command line, genomic data manipulation programs.Data wrangling reproducibility: Intro hands-computing data environment / manipulation side things. Learning resources/links. excel! R, Tidyverse, functions, loops, bash / command line, genomic data manipulation programs.Collectively two components support learning Genomic prediction selection: practice.Genomic prediction selection: theoryStudents also may need/want learn statistical quantitative genetic theory. additional section planned , minimum provide guidance access reading learning resources. starters, (Lynch Walsh 1998; Falconer FALCONER 2003; Isik et al. 2017; Bernardo 2020)!","code":""},{"path":"overview-process-map.html","id":"overview-process-map","chapter":"2 Overview Process Map","heading":"2 Overview Process Map","text":"created several “process maps” varying levels detail, diagrammatically outline orders operations genomic selection. high-level overview process map:","code":""},{"path":"using-this-manual.html","id":"using-this-manual","chapter":"3 Using this manual","heading":"3 Using this manual","text":"","code":""},{"path":"using-this-manual.html","id":"suggested-workflow","chapter":"3 Using this manual","heading":"3.1 Suggested workflow","text":"Create workflowR repository genomic prediction analysis, following instructions .Create workflowR repository genomic prediction analysis, following instructions .Follow along following documents templates examples:\nGenomic Selection Manual (BOOK)\nGS Process Maps (see process map section , also placed strategically throughout manual). four total:\nOverview Process Map\nData Download Preparation Process Map\nPreliminary Analysis Cross-validation Process Map\nGenomic Mate Selection Process Map\n\nGS Checklist (~LINKED ~)\nFollow along following documents templates examples:Genomic Selection Manual (BOOK)Genomic Selection Manual (BOOK)GS Process Maps (see process map section , also placed strategically throughout manual). four total:\nOverview Process Map\nData Download Preparation Process Map\nPreliminary Analysis Cross-validation Process Map\nGenomic Mate Selection Process Map\nGS Process Maps (see process map section , also placed strategically throughout manual). four total:Overview Process MapOverview Process MapData Download Preparation Process MapData Download Preparation Process MapPreliminary Analysis Cross-validation Process MapPreliminary Analysis Cross-validation Process MapGenomic Mate Selection Process MapGenomic Mate Selection Process MapGS Checklist (~LINKED ~)GS Checklist (~LINKED ~)Use variant documents code examples complete genomic prediction analysis develop report results.Use variant documents code examples complete genomic prediction analysis develop report results.Advice best practices:\nChoose data, traits, cassavabase\nWork example code actually .\nFollow-functions don’t know going manual.\nstrive provide references tutorials, papers, etc. give context help learn detail desired..\n\nInevitably, want divergences, alterations, bells--whistles top process documented. SUGGEST altering developing process maps checklists go.\nUse combination Rmarkdown (.Rmd) Rscripts (.R) document analysis, demonstrated.\nTake time write commentary throughout. full sentences, intend ? interpret results? next step? Etc.\nTake time think naming datasets, files, folders, R objects, etc.\nUse Git version control, made easy Rstudio.\nPublish code GitHub report results webpage using GitHub Pages. demonstrate using package workflowR manage aspects.\nAdvice best practices:Choose data, traits, cassavabaseChoose data, traits, cassavabaseWork example code actually .\nFollow-functions don’t know going manual.\nstrive provide references tutorials, papers, etc. give context help learn detail desired..\nWork example code actually .Follow-functions don’t know going manual.strive provide references tutorials, papers, etc. give context help learn detail desired..Inevitably, want divergences, alterations, bells--whistles top process documented. SUGGEST altering developing process maps checklists go.Inevitably, want divergences, alterations, bells--whistles top process documented. SUGGEST altering developing process maps checklists go.Use combination Rmarkdown (.Rmd) Rscripts (.R) document analysis, demonstrated.Use combination Rmarkdown (.Rmd) Rscripts (.R) document analysis, demonstrated.Take time write commentary throughout. full sentences, intend ? interpret results? next step? Etc.Take time write commentary throughout. full sentences, intend ? interpret results? next step? Etc.Take time think naming datasets, files, folders, R objects, etc.Take time think naming datasets, files, folders, R objects, etc.Use Git version control, made easy Rstudio.Use Git version control, made easy Rstudio.Publish code GitHub report results webpage using GitHub Pages. demonstrate using package workflowR manage aspects.Publish code GitHub report results webpage using GitHub Pages. demonstrate using package workflowR manage aspects.","code":""},{"path":"using-this-manual.html","id":"prerequisites","chapter":"3 Using this manual","heading":"3.2 Prerequisites","text":"need install R, Rstudio relevant R packages advance. Instructions next section.need know least R syntax. Links learning resources also provided section . ’ve never used R , going trouble following coding aspects manual.","code":""},{"path":"using-this-manual.html","id":"install-software-and-packages","chapter":"3 Using this manual","heading":"3.3 Install software and packages","text":"","code":""},{"path":"using-this-manual.html","id":"r-rstudio-r-packages","chapter":"3 Using this manual","heading":"3.3.1 R, Rstudio, R packages","text":"Install R Rstudio\nInstall R Windows, Mac OS X, Ubuntu Tutorial\nInstalling R RStudio\nInstall R RstudioHow Install R Windows, Mac OS X, Ubuntu TutorialHow Install R Windows, Mac OS X, Ubuntu TutorialInstalling R RStudioInstalling R RStudioRstudioRstudioInstall packages\ntidyverse (includes dplyr, tidyr, ggplot2, magrittr really useful ones)\ngenomicMateSelectR\nworkflowr\nInstall packagestidyverse (includes dplyr, tidyr, ggplot2, magrittr really useful ones)genomicMateSelectRworkflowr","code":"\ninstall.packages(c(\"tidyverse\",\"workflowr\", \"sommer\", \"lme4\"))\ndevtools::install_github(\"wolfemd/genomicMateSelectR\", ref = 'master') "},{"path":"using-this-manual.html","id":"create-a-github-account","chapter":"3 Using this manual","heading":"3.3.2 Create a GitHub account","text":"like teach reproducible, open-access approach data science genomic selection.start, please go https://github.com/ create free account, don’t already one. show create web-based reports, like , analyses!","code":""},{"path":"using-this-manual.html","id":"command-line-programs","chapter":"3 Using this manual","heading":"3.3.3 Command-line Programs","text":"Using Cassavabase-derived data mostly, entirely removes need command-line informatics tools. However, able totally avoid example. Furthermore, valuable skill / experience learn.section “preparing genotype data” downstream steps check validity pedigree end needing bioinformatics tools.","code":""},{"path":"using-this-manual.html","id":"windows","chapter":"3 Using this manual","heading":"3.3.3.1 Windows","text":"three possible Linux-emulator applications colleagues recommended Windows users:1. Windows Subsystem Linux: https://docs.microsoft.com/en-us/windows/wsl/install2. Git BASH Windows: https://gitforwindows.org/3. Cygwin: https://www.cygwin.com/can’t give much advice beyond links. Get googling solutions!found open-access google doc: http://bit.ly/2FSSjH6 might provide guidance Windows users.BACK-PLAN: might explore setting Cornell-based BioHPC node allowing everyone log-remotely. BioHPC programs possibly want gives access memory/compute cores single laptop.","code":""},{"path":"using-this-manual.html","id":"mac","chapter":"3 Using this manual","heading":"3.3.3.2 Mac","text":"’ll already access commands ’ll demonstrate, e.g. grep, cut. recommend installing “Homebrew” enable easily install e.g. vcftools bcftools e.g. brew install vcftools terminal.","code":""},{"path":"using-this-manual.html","id":"programs-we-might-use","chapter":"3 Using this manual","heading":"3.3.3.3 Programs we might use","text":"Bioinformatics command-line software tools:\nvcftools\nbcftools\nplink1.9: comes late pipeline, actually describe process getting working () Mac laptop. pinch, can download unzip pre-complied plink program machine use ./plink run program.\nBioinformatics command-line software tools:vcftoolsvcftoolsbcftoolsbcftoolsplink1.9: comes late pipeline, actually describe process getting working () Mac laptop. pinch, can download unzip pre-complied plink program machine use ./plink run program.plink1.9: comes late pipeline, actually describe process getting working () Mac laptop. pinch, can download unzip pre-complied plink program machine use ./plink run program.commands might encounter, come pre-available, least Mac Linux command lines.commands might encounter, come pre-available, least Mac Linux command lines.","code":""},{"path":"using-this-manual.html","id":"learning-r-and-more","chapter":"3 Using this manual","heading":"3.4 Learning R and more","text":"R Data Science (https://r4ds..co.nz/):\nRstudio / Tidyverse team recommends (https://www.tidyverse.org/learn/), book “best place start learning tidyverse.” Just anyone able (1) read brief introduction (2) look table contents quickly find starting point meets level / interest.R Data Science (https://r4ds..co.nz/):\nRstudio / Tidyverse team recommends (https://www.tidyverse.org/learn/), book “best place start learning tidyverse.” Just anyone able (1) read brief introduction (2) look table contents quickly find starting point meets level / interest.Data Challenge Lab (https://datalab.stanford.edu/challenge-lab)students develop data skills solving progression increasingly difficult challenges. just discovered . much think useful. Especially amongst “Open Content” (https://dcl-docs.stanford.edu/home/). example:\nData Wranglinghttps://dcl-wrangle.stanford.edu/manip-basics.html\nFunctional Programminghttps://dcl-prog.stanford.edu/https://dcl-prog.stanford.edu/purrr-mutate.html (’ve told loops using purrr package functions confusing… check ).\nAlso:https://dcl-prog.stanford.edu/purrr-parallel.html\nData Challenge Lab (https://datalab.stanford.edu/challenge-lab)students develop data skills solving progression increasingly difficult challenges. just discovered . much think useful. Especially amongst “Open Content” (https://dcl-docs.stanford.edu/home/). example:Data Wranglinghttps://dcl-wrangle.stanford.edu/manip-basics.htmlData Wranglinghttps://dcl-wrangle.stanford.edu/manip-basics.htmlFunctional Programminghttps://dcl-prog.stanford.edu/https://dcl-prog.stanford.edu/purrr-mutate.html (’ve told loops using purrr package functions confusing… check ).\nAlso:https://dcl-prog.stanford.edu/purrr-parallel.htmlFunctional Programminghttps://dcl-prog.stanford.edu/https://dcl-prog.stanford.edu/purrr-mutate.html (’ve told loops using purrr package functions confusing… check ).\nAlso:https://dcl-prog.stanford.edu/purrr-parallel.htmlLearn tidyversehttps://www.tidyverse.org/learn/https://www.tidyverse.org/packages/Learn tidyversehttps://www.tidyverse.org/learn/https://www.tidyverse.org/packages/APS 135: Introduction Exploratory Data Analysis R(https://dzchilds.github.io/eda--bio/)\nuseful intro sections basics R Rstudio, seems come Plant Science department, .APS 135: Introduction Exploratory Data Analysis R(https://dzchilds.github.io/eda--bio/)\nuseful intro sections basics R Rstudio, seems come Plant Science department, .Stat545: Data wrangling, exploration, analysis Rhttps://stat545.com/Stat545: Data wrangling, exploration, analysis Rhttps://stat545.com/Compendium Learning Resources gDoc: google doc contains links/references . contains even , hope maintain growing, dynamic, comprehensive annotated list resources learning R, Rstudio, data science .","code":""},{"path":"using-this-manual.html","id":"rmarkdown-and-workflowr","chapter":"3 Using this manual","heading":"3.4.1 Rmarkdown and workflowR","text":"Rmarkdown Vignette Cheatsheetworkflowr: organized + reproducible + shareable data science R","code":""},{"path":"using-this-manual.html","id":"piping-code","chapter":"3 Using this manual","heading":"3.4.2 Piping code %>%","text":"YouTube Video Intromagrittr package page","code":""},{"path":"using-this-manual.html","id":"hotkeys","chapter":"3 Using this manual","heading":"3.4.3 Hotkeys","text":"Pretty critical learn , especially :CMD+Option+= create chunkShift+CMD+M = %>% pipe operatorCMD+Enter = submit (run) lines code Rmd R script console.","code":""},{"path":"using-this-manual.html","id":"r-sessions-packages-to-load","chapter":"3 Using this manual","heading":"3.5 R sessions, packages to load","text":"use tidyverse also genomicMateSelectR packages throughout pipeline.others may appear.recommend, pipeline segment, starting new R session. Begin segment, step load R packages:","code":"\nlibrary(tidyverse)\nlibrary(genomicMateSelectR)\nlibrary(gt) # just for the nice looking tables"},{"path":"using-this-manual.html","id":"high-performance-and-remote-computing","chapter":"3 Using this manual","heading":"3.6 High performance and remote computing","text":"example manual designed work laptop… least new one. ’ve got 16-cores 64GB RAM machine developed .practice, large number plots, clones SNPs actually work , use laptop computations.point, perhaps end pipeline run-want cover (remote) use high performance computing machines facilitate.","code":""},{"path":"process-maps.html","id":"process-maps","chapter":"4 Process maps","heading":"4 Process maps","text":"","code":""},{"path":"process-maps.html","id":"overview-process-map-1","chapter":"4 Process maps","heading":"4.1 Overview Process Map","text":"","code":""},{"path":"process-maps.html","id":"data-download-and-preparation-process-map","chapter":"4 Process maps","heading":"4.2 Data Download and Preparation Process Map","text":"","code":""},{"path":"process-maps.html","id":"preliminary-analysis-and-cross-validation-process-map","chapter":"4 Process maps","heading":"4.3 Preliminary Analysis and Cross-validation Process Map","text":"","code":""},{"path":"process-maps.html","id":"genomic-mate-selection-process-map","chapter":"4 Process maps","heading":"4.4 Genomic Mate Selection Process Map","text":"","code":""},{"path":"create_project.html","id":"create_project","chapter":"5 Create a project","heading":"5 Create a project","text":"","code":""},{"path":"create_project.html","id":"create-a-github-repository","chapter":"5 Create a project","heading":"5.1 Create a GitHub repository","text":"avoid conflict RStudio GitHub let’s create repository first GitHub.Go GitHub page create new repository.Add creative name description repository, please leave public option, allow create GitHub page share work us.going copy https link repository clone RStudio. Just click red button.let’s move RStudio.clone (Download) repository GitHub, click Project button top right RStudio (1˚) New Project....window named New Project Wizard appear, select Version Control, Git.open window Clone Git Repository. just paste link asked copy long time ago Repository URL: window. Create project subdirectory : select directory easy access , make easier locate later.suggest create folder Documents keep workflowr projects organized.","code":""},{"path":"create_project.html","id":"create-a-workflowr-project","chapter":"5 Create a project","heading":"5.2 Create a workflowr project","text":"workflowr package helps organize analysis aiming improve project management, reproducibility, team work. works version control software git. Git another incredible software works version control, saving changes project make way, allowing easily get back older versions track changes bugs.let’s start installing workflowr package","code":"\ninstall.packages(\"workflowr\")"},{"path":"create_project.html","id":"starting-your-workflowr-project","chapter":"5 Create a project","heading":"5.2.1 Starting your workflowr project","text":"Let’s start reading workflowr package, running functionwflow_git_config function save information username email linked GitHub account. required allow push changes project. configuration necessary per computer.\ngoing create workflowr directory structure wflow_start function. Just pay attention already main directory project, follow steps everything fine.Obs.:dot . represents working directory. saying workflowr create new folders working directory, new folder.dot . represents working directory. saying workflowr create new folders working directory, new folder.Use name project GitHub repository.Use name project GitHub repository.git existing arguments inform workflowr use git version control folder already exists, respectively.git existing arguments inform workflowr use git version control folder already exists, respectively.wflow_start provide following template sub directories:workflowr also provide template format Rmd files used create GitHub pages websites like one!!!can look ideas customize theme layout project website .","code":"\nlibrary(workflowr)\n\nwflow_git_config(user.name = \"YourGitHubUserName\", user.email = \"YourGitHubEmail\")\nwflow_start(directory = \".\",\n          name = \"YourRepositoryName\",\n          git = TRUE,\n          existing = TRUE)myproject/\n|-- .gitignore\n|-- .Rprofile\n|-- _workflowr.yml\n|-- analysis/ # This is the most important folder,\n|   |            it will store all the your R markdown\n|   |            files with your analysis of this project\n|   |-- about.Rmd\n|   |-- index.Rmd # This Rmd file will generate the homepage of your\n|   |               website. Here you could write more about the \n|   |               project and link it to the your Rmd files with\n|   |               your analysis\n|   |-- license.Rmd\n|   \\-- _site.yml # This file is the does all the magic of your website\n|                   layout, theme, navigation bar, ...\n|-- code/ # This folder you should store all the code that you think\n|   |       that might not be appropriate to include at your Rmd files\n|   |       or that's functions that you created that you will just call\n|   |       for the analysis using a source function.\n|   \\-- README.md\n|-- data/ # Here you will add all your raw data files.\n|   \\-- README.md\n|-- docs/ # This folder will save all the html pages created from your Rmd\n|           files, SHOULD NOT BE EDITED BY THE USER\n|-- myproject.Rproj\n|-- output/ # Here you will save all the output from your analysis,\n|   |         like data, results, figures,...\n|   |         Even pre-process data files should be saved here.\n|   \\-- README.md\n|-- README.md"},{"path":"create_project.html","id":"tidyverse-functions","chapter":"5 Create a project","heading":"5.3 Tidyverse functions","text":"lots great resources online learning basic tidyverse functions.\nfind lot cheat sheets wonderful world tidyverse much .","code":""},{"path":"create_project.html","id":"code-chunks","chapter":"5 Create a project","heading":"5.3.1 Code chunks","text":"R markdown files R code must inside code chunks RStudio understand .\ncode chunk?```also use middle phrase 2 + 2 4, need write code surrounded pair back-ticks letter r like .R markdown allows create chunks several programming languages, like python.\nRStudio +c button menu Rmd file name, try see type languages apply Rmd file.","code":"Here's one\n\n```r\ndim(iris)\n#> [1] 150   5\n# Two plus two equals `r 2 + 2`"},{"path":"create_project.html","id":"hotkeys-1","chapter":"5 Create a project","heading":"5.3.2 Hotkeys","text":"Pretty critical learn , especially :magrittr package several operators useful managing data.","code":""},{"path":"create_project.html","id":"using-rmarkdown","chapter":"5 Create a project","heading":"5.4 Using Rmarkdown","text":"guides improve Rmd writing.\ncan use headers, give emphasis, create tables, call figure, add links useful websites.Markdown Basic SyntaxR Markdown Reference Guide - RStudio.","code":""},{"path":"create_project.html","id":"using-workflowr","chapter":"5 Create a project","heading":"5.5 Using workflowr","text":"open index.Rmd file using wflow_open functionAt file can update title index page, start writing main objectives repository. Like:’s great, still PCA.hmtl file, let’s create wflow_open function.create PCA.Rmd file, looking now.can update name replacing abbreviation Principal Components Analysis, add new intro analysis going R markdown file.can follow example website WorkFlowRExample.already changes project, can update repository GitHub running wflow_status wflow_publish.wflow_status check changes files analysis folder requires create html pages , verify new/delete/modified files repository. Always comparing last version (commit).wflow_status check changes files analysis folder requires create html pages , verify new/delete/modified files repository. Always comparing last version (commit).wflow_publish commit (save, take snapshot) changes Rmd files analysis folder. create update html files figures, commit new html files figures .wflow_publish commit (save, take snapshot) changes Rmd files analysis folder. create update html files figures, commit new html files figures .see something like .publish html website using wflow_publish need provide small message linked git commit function.However, prefer create/update html files using Knit button, commit . strategy reduces number commits repository, makes easier find older version . Also Knit button allows see website configuration expected without requiring commit time recreate website.can ask RStudio create html website pressing button knit, showed .RStudio create/update html file save docs folder. repeat step Rmd files checking expected, can commit changes GitHub. See next section.","code":"\nwflow_open(\"analysis/index.Rmd\")This repository was created to assist my learning experience with GitHub and workflowr.\n\nMy first R code at this project will be at this [git hub page](PCA.html)\nwflow_open(\"analysis/PCA.Rmd\")\nwflow_status()Status of 4 Rmd files\n\nTotals:\n 3 Unpublished\n 1 Scratch\n\nThe following Rmd files require attention:\n\nUnp analysis/about.Rmd\nUnp analysis/index.Rmd\nUnp analysis/license.Rmd\nScr analysis/PCA.Rmd\n\nKey: Unp = Unpublished, Scr = Scratch (Untracked)\n\nThe current Git status is:\n\n    status substatus                                          file\n untracked untracked                                     .DS_Store\n untracked untracked                        2.1 Script Var BLUPs.R\n untracked untracked                Data_Crosses_Density_chart.txt\n untracked untracked                   Parentais selecionados.xlsx\nwflow_publish(files = \"analysis/*.Rmd\", message = \"Test\")Current working directory: /Users/lbd54/Documents/GitHub/CassavaReproductiveBarriers\nBuilding 3 file(s):\nBuilding analysis/about.Rmd\nlog directory created: /var/folders/33/g0c9br3d0rx_bvhf9jsc0t9mcdw1j5/T//RtmphiTKma/workflowr\nBuilding analysis/index.Rmd\nBuilding analysis/license.Rmd\nSummary from wflow_publish\n\n**Step 1: Commit analysis files**\n\nNo files to commit\n\n\n**Step 2: Build HTML files**\n\nSummary from wflow_build\n\nSettings:\n combine: \"or\" clean_fig_files: TRUE\n\nThe following were built externally each in their own fresh R session: \n\ndocs/about.html\ndocs/index.html\ndocs/license.html\n\nLog files saved in /var/folders/33/g0c9br3d0rx_bvhf9jsc0t9mcdw1j5/T//RtmphiTKma/workflowr\n\n**Step 3: Commit HTML files**\n\nSummary from wflow_git_commit\n\nThe following was run: \n\n  $ git add docs/about.html docs/index.html docs/license.html docs/figure/about.Rmd docs/figure/index.Rmd docs/figure/license.Rmd docs/site_libs docs/.nojekyll \n  $ git commit -m \"Build site.\" \n\nThe following file(s) were included in commit 96ce162:\ndocs/about.html\ndocs/index.html\ndocs/license.html"},{"path":"create_project.html","id":"using-git-to-save-your-updates-at-github","chapter":"5 Create a project","heading":"5.6 Using Git to save your updates at GitHub","text":"Git four main functions:clone: copy repository specific directory computer.pull: update cloned repository computer new updates GitHub repository.commit: save version repository new codes, files, outputs. send GitHub.push: send git hub new commits/updates project. pushing repository GitHub can share clone updates computer.good commiting practice, just commit updates finish work part project, reduce number commits project.","code":""},{"path":"create_project.html","id":"git-in-rstudio","chapter":"5 Create a project","heading":"5.6.1 Git in RStudio","text":"commit updates just click commit button menu. open window called Rstudio: Review Changes.\nwindow, allowed stage (confirm) changes made files. can make decision per chunk, just decide stage chunk (keep changes) discard chunk (keep file last commit).FORGET WRITE SHORT MEANINGFUL MESSAGE NEW CHANGES COMMIT.Just click commit push new commit GitHub clicking green arrow.\nfirst time push commit GitHub computer, RStudio ask GitHub user password, password provide personal access token. link provide need generate one.Remember save token safe place, might used another time.","code":""},{"path":"create_project.html","id":"publishing-on-github-pages","chapter":"5 Create a project","heading":"5.7 Publishing on GitHub (Pages)","text":"Ok, project already GitHub, now need give instructions build website GitHub, let’s go GitHub repository. GitHub linkAt repository website, click settings\nselect Pages section sidebar menu\nsee section Source, GitHub need know branch folder inside branch html files. click None button select Branch: main, new windows folder symbol select /docs folder, save.Congratulations website created, just wait minutes. link appear window similar one.Copy link, get back repository website clicking repository name.right side page section called gear, click gear paste website link window Website, save changes.\nNow everyone access repository see project website just clicking link provided section.","code":"®   Your site is ready to be published at\nhttps://YourUserName.github.io/YourRepositoryName/UserName/RepositoryName"},{"path":"download-training-data.html","id":"download-training-data","chapter":"6 Download training data","heading":"6 Download training data","text":"","code":""},{"path":"download-training-data.html","id":"process-map","chapter":"6 Download training data","heading":"6.1 Process Map","text":"","code":""},{"path":"download-training-data.html","id":"cassavabase-login","chapter":"6 Download training data","heading":"6.2 Cassavabase Login","text":"Go Cassavabase favorite alternative BreedBase.Login.Go Search > Wizard","code":""},{"path":"download-training-data.html","id":"example-dataset","chapter":"6 Download training data","heading":"6.3 Example dataset","text":"sake example, choose small, real dataset think exemplify data stored DB. , choose data key features, including pedigree relationship high-proportion genotyped accessions.","code":""},{"path":"download-training-data.html","id":"create-trial-list","chapter":"6 Download training data","heading":"6.3.1 Create trial list","text":"Create list trials using “Wizard”IITA trials Ibadan Ubiaja locations, planted 2019. chose key trial types specific trials seen screenshot.Create list: IITA_ExampleGStrials_2021Dec04","code":""},{"path":"download-training-data.html","id":"download-related-trial-data","chapter":"6 Download training data","heading":"6.3.2 Download related trial data","text":"Clear Wizard panesStart new list trials created: “IITA_ExampleGStrials_2021Dec04”Download “Related Trial Metadata” “Related Trial Phenotypes”Exports .csv files phenotype.csv metadata.csv.Store data/ sub-directory current project.","code":""},{"path":"download-training-data.html","id":"make-an-accession-list","chapter":"6 Download training data","heading":"6.3.3 Make an accession list","text":"\\[NEW + EXPTL\\] Choose:Genotyping Protocol: “IITA DArT-GBS 08 Aug 2021,” thenAccessions: “Select ”Create list “IITA_ExampleGSaccessions_2021Dec05”.","code":""},{"path":"download-training-data.html","id":"validate-lists","chapter":"6 Download training data","heading":"6.3.4 Validate lists","text":"stage, validate lists created avoid problems downloading. critical step opportunity also correct things database.Click “Lists” top navigation bar.Find accession list created.Click list name “IITA_ExampleGSaccessions_2021Dec05” case.Click “Validate” button. waiting period.list fails, guidance provided problem. Correct possible. Seek assistance database administrator others necessary.example, list fail validation.100% know consequences following two choices, :Choose “Replace synonyms corresponding DB name” “List elements matching synonym.”\nbutton didn’t seem anything permanent.\nChoose “Replace synonyms corresponding DB name” “List elements matching synonym.”button didn’t seem anything permanent.decided manually delete three accessions: “Kaleso” “W940102” lastly “ANKRA”.decided manually delete three accessions: “Kaleso” “W940102” lastly “ANKRA”., recheck list passes validation close pop-., recheck list passes validation close pop-.Emphasis aspect requiring attention collaboration data generators / managers!!!","code":""},{"path":"download-training-data.html","id":"download-related-trial-genotype-data","chapter":"6 Download training data","heading":"6.3.5 Download related trial genotype data","text":"Download “Related Trial Genotype Data,” choosing available formats: VCF Dosage Matrix (.tsv).NOTE: probably take usually times . However, Cassavabase complete preparation file even disconnect ready--go return, ready, begin downloading immediately.NOTE ALSO downloads range 700Mb (VCF) 150Mb (Dosage TSV).","code":""},{"path":"download-training-data.html","id":"download-pedigree","chapter":"6 Download training data","heading":"6.3.6 Download Pedigree","text":"Go “Manage > Download > Download Pedigree”","code":""},{"path":"prepare-phenotype-data.html","id":"prepare-phenotype-data","chapter":"7 Prepare phenotype data","heading":"7 Prepare phenotype data","text":"Context Purpose: step, quality control, clean format training data analysis.Upstream: Section 6 - training data downloadDownstream: pretty much everythingInputs: “Raw” field trial dataExpected outputs: “Cleaned” field trial data","code":""},{"path":"prepare-phenotype-data.html","id":"process-map-1","chapter":"7 Prepare phenotype data","heading":"7.1 Process Map","text":"","code":""},{"path":"prepare-phenotype-data.html","id":"read-db-data","chapter":"7 Prepare phenotype data","heading":"7.2 Read DB data","text":"Load phenotype metadata downloads R.built function readDBdata simply wraps around read.csv, reads merges metadata plot-basis data. metadataFile= argument can left NULL.HINT: point manual, reference use custom function genomicMateSelectR, encourage check reference page function, e.g. readDBdata(). look code typing e.g. readDBdata R console heading GitHub repo.","code":"\ndbdata<-readDBdata(phenotypeFile = here::here(\"data\",\"phenotype.csv\"),\n                   metadataFile = here::here(\"data\",\"metadata.csv\"))\n#> Joining, by = c(\"studyYear\", \"programDbId\", \"programName\", \"programDescription\", \"studyDbId\", \"studyName\", \"studyDescription\", \"studyDesign\", \"plotWidth\", \"plotLength\", \"fieldSize\", \"fieldTrialIsPlannedToBeGenotyped\", \"fieldTrialIsPlannedToCross\", \"plantingDate\", \"harvestDate\", \"locationDbId\", \"locationName\")"},{"path":"prepare-phenotype-data.html","id":"detect_designs","chapter":"7 Prepare phenotype data","heading":"7.3 Check experimental designs","text":"Checklist: data plot-basis, plant-basis mixture? plant-basis data present, converted plot-basis analysis?plot-basis case.Checklist: experimental designs present? represented variables dataset? designs consistent expectations, example relative reported “trialType,” “studyName” /“studyDesign?”step, past, certain experimental designs trials downloaded. also certain designs represented column-names. reason, developed ad hoc custom code “detect” designs. built genomicMateSelectR function detectExptDesigns(). See example .RECOMMENDATION: analyst needs use exploratory data anlaysis, making summary statistics plots necessary determine data modelled downstream. missing incorrectly represented trial design variables, get corrected database (contact breeding program data manager, necessary).small example dataset, possible look 9 trials evaluate.Often, many trials part genomic prediction. essential trial designs consistent, clear analyst. may need derive strategy similar detectExptDesigns() function semi-automate process.Summary table shows:trialType studyDesign 100% relied upon, least .trial actually listed studyDesign==\"Augmented\" “check” vs. “test” distinguished “entryType.”trialType==\"Clonal Evaluation\" studyDesign==\"RCBD\" actually 1 replication.Next, ’ll check replicate blockNumber columns reliably distinguish complete incomplete blocks data., notice except 1 trial (19.GS.C1.C2.C3.AYT.42.UB) number reps blocks.question , complete replications experiment indicated replicate incomplete sub-blocks represented blockNumberSo 1 trial, 3 complete blocks, sub-blocks. 6 trials, 2 complete replications nested sub-blocks represented blockNumber variable. 2 trials, incomplete blocks.Next, decided check replicate column definitely means complete blocks. might look bit complicated, basically merge two summaries: (1) overall number accessions per trial, (2) average number accessions per replicate per trial.numbers similar trials, indicating complete blocks.One : look min, mean max number accessions per blockNumber., can see except studyName==\"19.GS.C1.C2.C3.AYT.42.UB\" sub-blocks represented blockNumber subsets total number accessions trial, expected., except studyName==\"19geneticgainUB\" trials pretty consistently sized sub-blocks.Now ad hoc create two variables (CompleteBlocks IncompleteBlocks), indicating (TRUE/FALSE) whether model using replicate /blockNumber variable.also like create explicitly nested design variables (yearInLoc, trialInLocYr, repInTrial, blockInRep).Just check:","code":"\ndbdata %>% count(observationLevel)\n#>   observationLevel    n\n#> 1             plot 1613\n# table(dbdata$observationLevel)\nlibrary(gt)\ndbdata %>% \n     count(studyName,trialType, studyDesign, numberBlocks,numberReps,entryType) %>% \n     spread(entryType,n) %>% \n     gt()  %>% \n     tab_options(table.font.size = pct(75))\ndbdata %>% \n     group_by(studyName) %>% \n     summarize(N_replicate=length(unique(replicate)),\n               N_blockNumber=length(unique(blockNumber))) %>% \n     gt() %>% tab_options(table.font.size = pct(75))\ndbdata %>% \n     group_by(studyName) %>% \n     summarize(N_replicate=length(unique(replicate)),\n               N_blockNumber=length(unique(blockNumber)),\n               doRepsEqualBlocks=all(replicate==blockNumber)) %>% \n     gt() %>% tab_options(table.font.size = pct(75))\n# the overall number of accessions per trial\ndbdata %>% \n     group_by(studyName) %>% \n     summarize(N_accession=length(unique(germplasmName))) %>% \n     # the average number of accessions per replicate per trial\n     left_join(dbdata %>% \n                    group_by(studyName,replicate) %>% \n                    summarize(N_accession=length(unique(germplasmName))) %>% \n                    group_by(studyName) %>% \n                    summarize(avgAccessionsPerReplicate=ceiling(mean(N_accession)))) %>% \n     gt() %>% tab_options(table.font.size = pct(75))\n#> `summarise()` has grouped output by 'studyName'. You can override using the `.groups` argument.\n#> Joining, by = \"studyName\"\n# the overall number of accessions per trial\ndbdata %>% \n     group_by(studyName) %>% \n     summarize(N_accession=length(unique(germplasmName))) %>% \n     left_join(dbdata %>% \n     group_by(studyName,replicate,blockNumber) %>% \n     summarize(N_accession=length(unique(germplasmName))) %>% ungroup() %>% \n     group_by(studyName) %>% \n     summarize(minAccessionsPerBlock=ceiling(min(N_accession)),\n               avgAccessionsPerBlock=ceiling(mean(N_accession)),\n               maxAccessionsPerBlock=ceiling(max(N_accession)))) %>% \n     gt() %>% tab_options(table.font.size = pct(60))\n#> `summarise()` has grouped output by 'studyName', 'replicate'. You can override using the `.groups` argument.\n#> Joining, by = \"studyName\"\ndbdata %<>% \n     group_by(studyName) %>% \n     summarize(N_replicate=length(unique(replicate)),\n               N_blockNumber=length(unique(blockNumber)),\n               doRepsEqualBlocks=all(replicate==blockNumber)) %>% \n     ungroup() %>% \n     mutate(CompleteBlocks=ifelse(N_replicate>1,TRUE,FALSE),\n            IncompleteBlocks=ifelse(N_blockNumber>1 & !doRepsEqualBlocks,TRUE,FALSE)) %>% \n     left_join(dbdata) %>% \n     mutate(yearInLoc=paste0(programName,\"_\",locationName,\"_\",studyYear),\n            trialInLocYr=paste0(yearInLoc,\"_\",studyName),\n            repInTrial=paste0(trialInLocYr,\"_\",replicate),\n            blockInRep=paste0(repInTrial,\"_\",blockNumber))\n#> Joining, by = \"studyName\"\ndbdata %>% \n     count(studyName,CompleteBlocks,IncompleteBlocks) %>% \n     left_join(dbdata %>% \n                    group_by(studyName) %>% \n                    summarize(nRepInTrial=length(unique(repInTrial)),\n                              nBlockInRep=length(unique(blockInRep)))) %>% \n     gt() %>% tab_options(table.font.size = pct(67))\n#> Joining, by = \"studyName\""},{"path":"prepare-phenotype-data.html","id":"traits-and-trait-abbreviations","chapter":"7 Prepare phenotype data","heading":"7.4 Traits and Trait Abbreviations","text":"Cassavabase downloads use long column-names corresponding full trait-ontology name. convenience, replace names abbreviations, documented . eventual upload analysis results, names need restored ontology terms.also use opportunity subselect traits.Run function renameAndSelectCols() rename columns remove unselected traits.","code":"\ntraitabbrevs<-tribble(~TraitAbbrev,~TraitName,\n        \"CMD1S\",\"cassava.mosaic.disease.severity.1.month.evaluation.CO_334.0000191\",\n        \"CMD3S\",\"cassava.mosaic.disease.severity.3.month.evaluation.CO_334.0000192\",\n        \"CMD6S\",\"cassava.mosaic.disease.severity.6.month.evaluation.CO_334.0000194\",\n        \"DM\",\"dry.matter.content.percentage.CO_334.0000092\",\n        \"RTWT\",\"fresh.storage.root.weight.per.plot.CO_334.0000012\",\n        \"NOHAV\",\"plant.stands.harvested.counting.CO_334.0000010\")\ntraitabbrevs %>% gt()#rmarkdown::paged_table()\ndbdata<-renameAndSelectCols(traitabbrevs,\n                            indata=dbdata,\n                            customColsToKeep = c(\"observationUnitName\",\n                                                 \"CompleteBlocks\",\n                                                 \"IncompleteBlocks\",\n                                                 \"yearInLoc\",\n                                                 \"trialInLocYr\",\n                                                 \"repInTrial\",\"blockInRep\"))\n#> Warning in mask$eval_all_mutate(quo): NAs introduced by\n#> coercion\n#> Joining, by = \"TraitName\""},{"path":"prepare-phenotype-data.html","id":"qc-trait-values","chapter":"7 Prepare phenotype data","heading":"7.5 QC Trait Values","text":"point pipeline, check trait values allowable ranges. Different ways approach . Feel free make plots data!database also mechanisms ensure trait values within allowable ranges.Nevertheless, habit, simple ad hoc approach :","code":"\n# comment out the traits not present in this dataset\ndbdata<-dbdata %>% \n     dplyr::mutate(CMD1S=ifelse(CMD1S<1 | CMD1S>5,NA,CMD1S),\n                   CMD3S=ifelse(CMD3S<1 | CMD3S>5,NA,CMD3S),\n                   # CMD6S=ifelse(CMD6S<1 | CMD6S>5,NA,CMD6S), \n                   # CMD9S=ifelse(CMD9S<1 | CMD9S>5,NA,CMD9S),\n                   # CGM=ifelse(CGM<1 | CGM>5,NA,CGM),\n                   # CGMS1=ifelse(CGMS1<1 | CGMS1>5,NA,CGMS1),\n                   # CGMS2=ifelse(CGMS2<1 | CGMS2>5,NA,CGMS2),\n                   DM=ifelse(DM>100 | DM<=0,NA,DM),\n                   RTWT=ifelse(RTWT==0 | NOHAV==0 | is.na(NOHAV),NA,RTWT),\n                   # SHTWT=ifelse(SHTWT==0 | NOHAV==0 | is.na(NOHAV),NA,SHTWT),\n                   # RTNO=ifelse(RTNO==0 | NOHAV==0 | is.na(NOHAV),NA,RTNO),\n                   NOHAV=ifelse(NOHAV==0,NA,NOHAV),\n                   NOHAV=ifelse(NOHAV>42,NA,NOHAV)\n                   # RTNO=ifelse(!RTNO %in% 1:10000,NA,RTNO)\n     )"},{"path":"prepare-phenotype-data.html","id":"post-qc-composite-traits","chapter":"7 Prepare phenotype data","heading":"7.6 Post-QC: composite traits","text":"Now component traits QC’d, ’s time compute composite traits.composite traits, mean traits computed combinations traits.Examples cassava: season-wide mean disease severity, harvest index, fresh root yield.","code":""},{"path":"prepare-phenotype-data.html","id":"season-wide-mean-disease-severity","chapter":"7 Prepare phenotype data","heading":"7.6.1 Season-wide mean disease severity","text":"","code":"\n# [NEW AS OF APRIL 2021]\n## VERSION with vs. without CBSD\n## Impervious to particular timepoints between 1, 3, 6 and 9 scores\n\n# Without CBSD (West Africa)\ndbdata<-dbdata %>% \n  mutate(MCMDS=rowMeans(.[,colnames(.) %in% c(\"CMD1S\",\"CMD3S\",\"CMD6S\",\"CMD9S\")], na.rm = T)) %>% \n  select(-any_of(c(\"CMD1S\",\"CMD3S\",\"CMD6S\",\"CMD9S\")))\n\n# With CBSD (East Africa)\n# dbdata<-dbdata %>% \n#   mutate(MCMDS=rowMeans(.[,colnames(.) %in% c(\"CMD1S\",\"CMD3S\",\"CMD6S\",\"CMD9S\")], na.rm = T),\n#          MCBSDS=rowMeans(.[,colnames(.) %in% c(\"CBSD1S\",\"CBSD3S\",\"CBSD6S\",\"CBSD9S\")], na.rm = T)) %>% \n#   select(-any_of(c(\"CMD1S\",\"CMD3S\",\"CMD6S\",\"CMD9S\",\"CBSD1S\",\"CBSD3S\",\"CBSD6S\",\"CBSD9S\")))"},{"path":"prepare-phenotype-data.html","id":"fresh-root-yield-fyld","chapter":"7 Prepare phenotype data","heading":"7.6.2 Fresh root yield (FYLD)","text":"RTWT (fresh root weight per plot kg) –> FYLD (fresh root yield tons per hectare)\\[FYLD = \\frac{RTWT_{kg / plot}}{MaxHarvestedPlantsPerPlot \\times PlantSpacing}\\times10\\] NOTE: MaxHarvestedPlantsPerPlot formula distinguish plantsPerPlot meta-data field, case net-plot harvest used. words, value total number plants intended harvest plot, assuming missing plants plot.PlantSpacing area \\(m^2\\) per plant.example trial data, plantsPerPlot meta-data field empty. knowledge, meta-data field available BreedBase represent net-plot harvest.RECOMMEND INPUTING plantsPerPlot meta-data cassavabase breeding program!Luckily, since 9 trials tutorial, decisions manually.Firstly noting trial 19geneticgainUB actually phenotypes (trait). excluded downstream. (might find substitute genetic gain trial, earlier year, sake example)decide real MaxHarvestedPlantsPerPlot plantsPerPlot likely , make two plots also compute maximum NOHAV trial.Maybe clearer make boxplot?sake example, ‘ok’ make choices basis just done.data generator, -house breeding program, reason get correct answer repair metadata database!Additional things compute:log-transform yield traits: habit based experience. Linear mixed-models normally distributed homoskedastic residuals, don’t log-transform response variable often helps. FYLD related traits, always log-transform.Debatable whether better. Let’s dwell . Onward!SUGGESTION: individuals working manual, consider making different, transformations see fit, data. Even better, set-direct comparison results - vs. without-transformation.*","code":"\ndbdata %>% \n     count(studyYear,studyName,studyDesign,plotWidth,plotLength,plantsPerPlot) %>% \n     mutate(plotArea=plotWidth*plotLength) %>% \n     gt() %>% tab_options(table.font.size = pct(67))\ndbdata %>% \n     ggplot(.,aes(x=NOHAV, fill=studyName)) + geom_density(alpha=0.75)\n#> Warning: Removed 71 rows containing non-finite values\n#> (stat_density).\ndbdata %>% \n     # plot area in meters squared\n     mutate(plotArea=plotWidth*plotLength) %>% \n     ggplot(.,aes(x=plotArea,y=NOHAV, fill=studyName)) + \n     geom_boxplot() + theme(axis.text.x = element_blank())\n#> Warning: Removed 71 rows containing non-finite values\n#> (stat_boxplot).\nplantsPerPlot_choices<-dbdata %>% \n     distinct(studyYear,studyName,plotWidth,plotLength,plantsPerPlot) %>% \n     left_join(dbdata %>% \n                    group_by(studyName) %>% \n                    summarize(MaxNOHAV=max(NOHAV, na.rm=T))) %>% \n          # plot area in meters squared\n     mutate(plotArea=plotWidth*plotLength,\n            # Number of plants per plot\n            plantsPerPlot=MaxNOHAV,\n            plantsPerPlot=ifelse(studyName==\"19.GS.C2.UYT.36.setA.UB\",20,plantsPerPlot)) %>% \n     # exclude the empty genetic gain trial\n     filter(studyName!=\"19geneticgainUB\") %>% \n     select(studyName,plotArea,MaxNOHAV,plantsPerPlot)\n#> Joining, by = \"studyName\"\nplantsPerPlot_choices %>% gt() #%>% tab_options(table.font.size = pct(67))\ndbdata %<>%\n     # remove the empty genetic gain trial\n     filter(studyName!=\"19geneticgainUB\") %>% \n     select(-plantsPerPlot) %>% \n     # join plantsPerPlot_choices to the trial data\n     left_join(plantsPerPlot_choices) %>% \n     # compute fresh root yield (FYLD) in tons per hectare\n     mutate(PlantSpacing=plotArea/plantsPerPlot,\n            FYLD=RTWT/(plantsPerPlot*PlantSpacing)*10)\n#> Joining, by = \"studyName\"\ndbdata %>% ggplot(.,aes(x=FYLD,fill=studyName)) + geom_density(alpha=0.75)\n#> Warning: Removed 89 rows containing non-finite values\n#> (stat_density).\n# I log transform yield traits \n# to satisfy homoskedastic residuals assumption \n# of linear mixed models\ndbdata %<>% \n     mutate(DYLD=FYLD*(DM/100),\n            logFYLD=log(FYLD),\n            logDYLD=log(DYLD),\n            PropNOHAV=NOHAV/plantsPerPlot) \n# remove non transformed / per-plot (instead of per area) traits\ndbdata %<>% select(-RTWT,-FYLD,-DYLD)\ndbdata %>% ggplot(.,aes(x=logFYLD,fill=studyName)) + geom_density(alpha=0.75)\n#> Warning: Removed 89 rows containing non-finite values\n#> (stat_density)."},{"path":"prepare-phenotype-data.html","id":"save_cleaned_phenos","chapter":"7 Prepare phenotype data","heading":"7.7 Save “cleaned” phenotypes","text":"","code":"\nsaveRDS(dbdata,file=here::here(\"output\",\"phenotypes_cleaned.rds\"))"},{"path":"prepare-genotypic-data.html","id":"prepare-genotypic-data","chapter":"8 Prepare genotypic data","heading":"8 Prepare genotypic data","text":"Context Purpose:\nDepending whether parent- vs. mate-selection intended, several formats --constructed / computed downloaded genotypic data.\nPotentially, exploratory / preliminary assessment population structure, esp. divergence “training” samples selection candidates (“test”).\nContext Purpose:Depending whether parent- vs. mate-selection intended, several formats --constructed / computed downloaded genotypic data.Potentially, exploratory / preliminary assessment population structure, esp. divergence “training” samples selection candidates (“test”).Upstream: Section 7 - quality control steps phenotype dataUpstream: Section 7 - quality control steps phenotype dataDownstream: analyses relying genotypic dataDownstream: analyses relying genotypic dataInputs:\nparent selection: imputed allele-dosage matrix downloaded BreedBase (data/BreedBaseGenotypesDownload.tsv)\nmate selection:\nimputed variant call format (VCF) file downloaded BreedBase (data/BreedBaseGenotypesDownload.vcf)\ncentimorgan-scale genetic map positions reference genome version VCF. Can sourced Cassavabase FTP, FTP archive, another alternative.\n\nInputs:parent selection: imputed allele-dosage matrix downloaded BreedBase (data/BreedBaseGenotypesDownload.tsv)parent selection: imputed allele-dosage matrix downloaded BreedBase (data/BreedBaseGenotypesDownload.tsv)mate selection:\nimputed variant call format (VCF) file downloaded BreedBase (data/BreedBaseGenotypesDownload.vcf)\ncentimorgan-scale genetic map positions reference genome version VCF. Can sourced Cassavabase FTP, FTP archive, another alternative.\nmate selection:imputed variant call format (VCF) file downloaded BreedBase (data/BreedBaseGenotypesDownload.vcf)imputed variant call format (VCF) file downloaded BreedBase (data/BreedBaseGenotypesDownload.vcf)centimorgan-scale genetic map positions reference genome version VCF. Can sourced Cassavabase FTP, FTP archive, another alternative.centimorgan-scale genetic map positions reference genome version VCF. Can sourced Cassavabase FTP, FTP archive, another alternative.Expected outputs:\nparent selection: MAF filtered, dosage matrix, possibly samples removed relative database download.\nmate selection:\nhaplotype matrix extracted VCF\ndosage matrix (computed haplotype matrix)\nfiltered SNP list\nInterpolated genetic map, cM position SNP\n\nparent mate selection: genomic relationship matrices (GRMs, aka kinship matrices), possibly additive dominance relationship matrices, constructed based dosage matrix.\nExpected outputs:parent selection: MAF filtered, dosage matrix, possibly samples removed relative database download.parent selection: MAF filtered, dosage matrix, possibly samples removed relative database download.mate selection:\nhaplotype matrix extracted VCF\ndosage matrix (computed haplotype matrix)\nfiltered SNP list\nInterpolated genetic map, cM position SNP\nmate selection:haplotype matrix extracted VCFa haplotype matrix extracted VCFa dosage matrix (computed haplotype matrix)dosage matrix (computed haplotype matrix)filtered SNP lista filtered SNP listInterpolated genetic map, cM position SNPInterpolated genetic map, cM position SNPFor parent mate selection: genomic relationship matrices (GRMs, aka kinship matrices), possibly additive dominance relationship matrices, constructed based dosage matrix.parent mate selection: genomic relationship matrices (GRMs, aka kinship matrices), possibly additive dominance relationship matrices, constructed based dosage matrix.","code":""},{"path":"prepare-genotypic-data.html","id":"process-map-2","chapter":"8 Prepare genotypic data","heading":"8.1 Process Map","text":"","code":""},{"path":"prepare-genotypic-data.html","id":"parent-vs.-mate-selection","chapter":"8 Prepare genotypic data","heading":"8.2 Parent vs. Mate Selection?","text":"following sections exemplify genomic mate selection opposed somewhat simpler genomic parent selection pathway along process map. chapter can simplified / mostly avoided parent selection sufficient.","code":""},{"path":"prepare-genotypic-data.html","id":"check-the-vcf","chapter":"8 Prepare genotypic data","heading":"8.3 Check the VCF","text":"Check VCF ‘manually.’number samples sites expected?data phased?FORMAT fields present? minimum, include GT field.column-names FORMAT (sample names) look right / make sense?SNP IDs “ID” field make sense?","code":"vcftools --vcf data/BreedBaseGenotypesDownload.vcf\n# VCFtools - 0.1.16\n# (C) Adam Auton and Anthony Marcketta 2009\n# \n# Parameters as interpreted:\n#   --vcf data/BreedBaseGenotypesDownload.vcf\n# \n# After filtering, kept 1207 out of 1207 Individuals\n# After filtering, kept 61239 out of a possible 61239 Sites\n# Run Time = 16.00 seconds# look at the header of the VCF file\n# print the \"top-left\" corner of the file\ncat data/BreedBaseGenotypesDownload.vcf | head -n50 | cut -c1-100"},{"path":"prepare-genotypic-data.html","id":"subset-vcf","chapter":"8 Prepare genotypic data","heading":"8.4 Subset VCF","text":"may multiple imputed DNA samples corresponding single unique ‘germplasmName.’ matching phenotypic observations downstream analyses, single entry VCF file must chosen per ‘germplasmName.’Remove extraneous samples, .example / tutorial purposes : randomly sample subset number SNPs thousand, quick, local computations.","code":""},{"path":"prepare-genotypic-data.html","id":"remove-duplicate-samples","chapter":"8 Prepare genotypic data","heading":"8.4.1 Remove duplicate samples","text":"Cassavabase returned multiple columns VCF file column-name, multiple tissue_samples per germplasmName. prevents using certain tools, e.g. bcftools errors.Manual solution required:Write just column-names VCF disk. ’s one-liner:Read column-names-file R. Exclude first 9 elements standard VCF columns, “germplasmName”Quite duplicates.Next, (1) create unique names sample column VCF file, (2) write “unique_names_for_vcf.txt” disk (3) use replace current sample column names VCF. Finally, (4) subset VCF one unique instance name.First, manipulate names using R.Now command line:bcftools reheader replace sample names VCF unique ones.Now subset VCF single instance “germplasmName” vcftools.","code":"egrep \"^#CHROM\" data/BreedBaseGenotypesDownload.vcf | head -n1 > data/vcf_colnames.txt\n# egrep \"^##SynonymsOfAccessions=\" data/BreedBaseGenotypesDownload.vcf | head -n1 > data/vcf_synonyms.txt\nvcf_sample_names<-readLines(\"data/vcf_colnames.txt\") %>% \n     strsplit(.,\"\\t\") %>% unlist() %>% \n     .[10:length(.)]\n# Check how many sample names are duplicated?\ntable(duplicated(vcf_sample_names))\n#> \n#> FALSE  TRUE \n#>   963   244\n# create unique names for each VCF\nunique_names_for_vcf<-tibble(vcfName=vcf_sample_names) %>% \n     # create an overall index to ensure I can recover the original column order\n     mutate(vcfIndex=1:n()) %>% \n     # now for each vcfName create an sub-index, to distinguish among duplicates\n     group_by(vcfName) %>% \n     # sub-index\n     mutate(vcfNameIndex=1:n(),\n            # For the first (or only) instance of each unique vcfName\n            vcfName_Unique=ifelse(vcfNameIndex==1,\n                                  # return the original name\n                                  vcfName,\n                                  # for all subsequent (duplicate) names, \n                                  #put a unique-ified name by pasting the sub-index\n                                  paste0(vcfName,\".\",vcfNameIndex)))\n# Write the \"unique_names_for_vcf.txt\" to disk\nwrite.table(unique_names_for_vcf$vcfName_Unique,file = \"data/unique_names_for_vcf.txt\",\n            row.names = F, col.names = F, quote = F)\n# Create also a list containing only one instance of each unique name, the first instance \nsubset_unique_names_for_vcf<-unique_names_for_vcf %>% \n     filter(vcfNameIndex==1) %$%\n     vcfName_Unique\n# Write that list to disk for subsetting the VCF downstream\nwrite.table(subset_unique_names_for_vcf,file = \"data/subset_unique_names_for_vcf.txt\",\n            row.names = F, col.names = F, quote = F)# replace sample names in original VCF with unique ones (creates a new VCF)\nbcftools reheader --samples data/unique_names_for_vcf.txt data/BreedBaseGenotypesDownload.vcf > data/BreedBaseGenotypesDownload_1.vcf; \n# overwrite the original VCF with the new  that has unique names\nmv data/BreedBaseGenotypesDownload_1.vcf data/BreedBaseGenotypesDownload.vcf;\n# check that the names are now unique by printing sample list\nbcftools query --list-samples data/BreedBaseGenotypesDownload.vcfvcftools --vcf data/BreedBaseGenotypesDownload.vcf --keep data/subset_unique_names_for_vcf.txt --recode --stdout | bgzip -c > data/BreedBaseGenotypes_subset.vcf.gz\n# uses stdout and bgzip to output a gzipped vcf file; saves disk space!vcftools --gzvcf data/BreedBaseGenotypes_subset.vcf.gz\n#VCFtools - 0.1.16\n#(C) Adam Auton and Anthony Marcketta 2009\n# Parameters as interpreted:\n#   --gzvcf data/BreedBaseGenotypes_subset.vcf.gz\n# \n# Using zlib version: 1.2.11\n# After filtering, kept 963 out of 963 Individuals\n# After filtering, kept 61239 out of a possible 61239 Sites\n# Run Time = 2.00 seconds"},{"path":"prepare-genotypic-data.html","id":"check-genotype-to-phenotype-matches","chapter":"8 Prepare genotypic data","heading":"8.4.2 Check genotype-to-phenotype matches","text":"number unique germplasmName (\\[cleaned phenos previous step\\]\\[save_cleaned_phenos\\]) matching samples VCF make sense? many expected? , need figure .many matches VCF?350 matches. make sense? Yes. ended excluding “genetic gain” trial phenotypes b/c actually trait scores.sure, look names : (1) genotyped phenotyped, (2) genotyped phenotyped, (3) phenotyped genotyped.diagnose phenotyped---genotyped, actually resorted searching Cassavabase verify non-genotyped lines trials downloaded.genotyped---phenotyped, indeed names “genetic gain” population clones.Probably details change go back choose better example trials.checklist approach verifying stay .","code":"\nphenos<-readRDS(here::here(\"output\",\"phenotypes_cleaned.rds\"))\n\n# vector of the unique germplasmName in the field trial data\ngermplasm_with_phenos<-unique(phenos$germplasmName)\nlength(germplasm_with_phenos) \n#> [1] 1428\ntable(germplasm_with_phenos %in% subset_unique_names_for_vcf)\n#> \n#> FALSE  TRUE \n#>   857   571\n# geno and pheno\nsubset_unique_names_for_vcf[subset_unique_names_for_vcf %in% germplasm_with_phenos]\n# pheno not geno\ngermplasm_with_phenos[!germplasm_with_phenos %in% subset_unique_names_for_vcf]\n# geno not pheno\nsubset_unique_names_for_vcf[!subset_unique_names_for_vcf %in% germplasm_with_phenos]"},{"path":"prepare-genotypic-data.html","id":"subset-snps-for-tutorial-purposes","chapter":"8 Prepare genotypic data","heading":"8.4.3 Subset SNPs (for tutorial purposes)","text":"example / tutorial purposes : randomly sample subset number SNPs thousand, quick, local computations.Read R, sample 4000 randomSubset VCF using randomly sampled list positions.","code":"# write the positions list\n# first two columns (chrom. and position) of the VCF \n# ignoring the header rows\ncat data/BreedBaseGenotypesDownload.vcf | grep -v \"^#\" | cut -f1-2 > data/BreedBaseGenotypesDownload.positions\nset.seed(1234)\nread.table(here::here(\"data\",\"BreedBaseGenotypesDownload.positions\"), \n           header = F, stringsAsFactors = F) %>% \n     dplyr::slice_sample(n=4000) %>% \n     arrange(V1,V2) %>% \n     write.table(.,file = \"data/BreedBaseGenotypes_subset.positions\",\n                 row.names = F, col.names = F, quote = F)vcftools --vcf data/BreedBaseGenotypesDownload.vcf \\\n--keep data/subset_unique_names_for_vcf.txt \\\n--positions data/BreedBaseGenotypes_subset.positions \\\n--recode --stdout | bgzip -c > data/BreedBaseGenotypes_subset.vcf.gz\n# VCFtools - 0.1.16\n# (C) Adam Auton and Anthony Marcketta 2009\n# \n# Parameters as interpreted:\n#   --vcf data/BreedBaseGenotypesDownload.vcf\n#   --keep data/subset_unique_names_for_vcf.txt\n#   --positions data/BreedBaseGenotypes_subset.positions\n#   --recode\n#   --stdout\n# \n# Keeping individuals in 'keep' list\n# After filtering, kept 963 out of 1207 Individuals\n# Outputting VCF file...\n# After filtering, kept 4000 out of a possible 61239 Sites\n# Run Time = 8.00 seconds"},{"path":"prepare-genotypic-data.html","id":"ld-prunning-snps-for-computational-savings","chapter":"8 Prepare genotypic data","heading":"8.4.4 LD-prunning SNPs (for computational savings)","text":"DEMONSTRATED , YET. practice, predicting cross-variances, can still computationally intensive large numbers markers. Previously, used plink --indep-pairwise prune markers based linkage disequilibrium. found LD-prunned subset similar accuracy full set, less half markers. Subsequently, used full set predict cross means, LD-pruned marker subset cross variances predictions >250K crosses 719 candidate parents IITA’s 2021 crossing block.","code":""},{"path":"prepare-genotypic-data.html","id":"haplotype-matrix-from-vcf","chapter":"8 Prepare genotypic data","heading":"8.5 Haplotype matrix from VCF","text":"Extract haplotypes VCF bcftools convert --hapsampleRead haps R format .Add sample ID’s.Format, transpose, convert matrix.","code":"bcftools convert --hapsample data/BreedBaseGenotypes_subset data/BreedBaseGenotypes_subset.vcf.gz\n# Hap file: data/BreedBaseGenotypes_subset.hap.gz\n# Sample file: data/BreedBaseGenotypes_subset.samples\n# [W::vcf_parse_format] FORMAT 'NT' at 1:652699 is not defined in the header, assuming Type=String\n# 4000 records written, 0 skipped: 0/0/0 no-ALT/non-biallelic/filtered\nlibrary(data.table)\n#> \n#> Attaching package: 'data.table'\n#> The following objects are masked from 'package:dplyr':\n#> \n#>     between, first, last\n#> The following object is masked from 'package:purrr':\n#> \n#>     transpose\nvcfName<-\"BreedBaseGenotypes_subset\"\nhaps<-fread(paste0(\"data/\",vcfName,\".hap.gz\"),\n            stringsAsFactors = F,header = F) %>% \n  as.data.frame\nsampleids<-fread(paste0(\"data/\",vcfName,\".samples\"),\n                 stringsAsFactors = F,header = F,skip = 2) %>% \n  as.data.frame\nhapids<-sampleids %>% \n     select(V1,V2) %>% \n     mutate(SampleIndex=1:nrow(.)) %>% \n     rename(HapA=V1,HapB=V2) %>% \n     pivot_longer(cols=c(HapA,HapB),\n                  names_to = \"Haplo\",values_to = \"SampleID\") %>% \n     mutate(HapID=paste0(SampleID,\"_\",Haplo)) %>% \n     arrange(SampleIndex)\ncolnames(haps)<-c(\"Chr\",\"HAP_ID\",\"Pos\",\"REF\",\"ALT\",hapids$HapID)\ndim(haps)\n#> [1] 4000 1931\nhaps %<>% \n     mutate(HAP_ID=gsub(\":\",\"_\",HAP_ID)) %>% \n     column_to_rownames(var = \"HAP_ID\") %>% \n     select(-Chr,-Pos,-REF,-ALT) %>% \n     t(.) %>% \n     as.matrix(.)"},{"path":"prepare-genotypic-data.html","id":"dosage-matrix-from-haps","chapter":"8 Prepare genotypic data","heading":"8.6 Dosage matrix from haps","text":"ensure consistency allele counting, create dosage haps manually.counted allele dosage matrix, used downstream construct kinship matrices estimate marker effects, ALT allele. ensure match haplotype matrix, “1” indicates presence ALT allele.BreedBase system currently (Jan. 2022) gives dosages count REF allele need fix .’s tidyverse-based approach, using group_by() plus summarise() sum two haplotypes individual across loci.","code":"\ndosages<-haps %>%\n     as.data.frame(.) %>% \n     rownames_to_column(var = \"GID\") %>% \n     separate(GID,c(\"SampleID\",\"Haplo\"),\"_Hap\",remove = T) %>% \n     select(-Haplo) %>% \n     group_by(SampleID) %>% \n     summarise(across(everything(),~sum(.))) %>% \n     ungroup() %>% \n     column_to_rownames(var = \"SampleID\") %>% \n     as.matrix %>% \n     # preserve same order as in haps\n     .[sampleids$V1,]\ndim(dosages)\n#> [1]  963 4000\n# [1]  963 4000\n\ndosages[1:5,1:5]\n#>                    1_652699_G_C 1_868970_G_T 1_943129_T_A\n#> IITA-TMS-IBA30572             1            0            0\n#> IITA-TMS-IBA940237            0            0            1\n#> IITA-TMS-IBA961642            1            1            0\n#> IITA-TMS-ONN920168            0            0            0\n#> IITA-TMS-WAR4080              1            0            0\n#>                    1_1132830_A_T 1_1310706_A_T\n#> IITA-TMS-IBA30572              1             0\n#> IITA-TMS-IBA940237             1             1\n#> IITA-TMS-IBA961642             2             0\n#> IITA-TMS-ONN920168             0             0\n#> IITA-TMS-WAR4080               1             0\nhaps[1:10,1:5]\n#>                         1_652699_G_C 1_868970_G_T\n#> IITA-TMS-IBA30572_HapA             1            0\n#> IITA-TMS-IBA30572_HapB             0            0\n#> IITA-TMS-IBA940237_HapA            0            0\n#> IITA-TMS-IBA940237_HapB            0            0\n#> IITA-TMS-IBA961642_HapA            1            0\n#> IITA-TMS-IBA961642_HapB            0            1\n#> IITA-TMS-ONN920168_HapA            0            0\n#> IITA-TMS-ONN920168_HapB            0            0\n#> IITA-TMS-WAR4080_HapA              0            0\n#> IITA-TMS-WAR4080_HapB              1            0\n#>                         1_943129_T_A 1_1132830_A_T\n#> IITA-TMS-IBA30572_HapA             0             1\n#> IITA-TMS-IBA30572_HapB             0             0\n#> IITA-TMS-IBA940237_HapA            0             0\n#> IITA-TMS-IBA940237_HapB            1             1\n#> IITA-TMS-IBA961642_HapA            0             1\n#> IITA-TMS-IBA961642_HapB            0             1\n#> IITA-TMS-ONN920168_HapA            0             0\n#> IITA-TMS-ONN920168_HapB            0             0\n#> IITA-TMS-WAR4080_HapA              0             0\n#> IITA-TMS-WAR4080_HapB              0             1\n#>                         1_1310706_A_T\n#> IITA-TMS-IBA30572_HapA              0\n#> IITA-TMS-IBA30572_HapB              0\n#> IITA-TMS-IBA940237_HapA             0\n#> IITA-TMS-IBA940237_HapB             1\n#> IITA-TMS-IBA961642_HapA             0\n#> IITA-TMS-IBA961642_HapB             0\n#> IITA-TMS-ONN920168_HapA             0\n#> IITA-TMS-ONN920168_HapB             0\n#> IITA-TMS-WAR4080_HapA               0\n#> IITA-TMS-WAR4080_HapB               0"},{"path":"prepare-genotypic-data.html","id":"filter-variants","chapter":"8 Prepare genotypic data","heading":"8.7 Variant filters","text":"case, simple: keep positions >1% minor allele frequency.","code":"\n# use function built into genomicMateSelectR\ndosages<-maf_filter(dosages,thresh = 0.01)\ndim(dosages)\n#> [1]  963 3986\n# subset haps to match\nhaps<-haps[,colnames(dosages)]"},{"path":"prepare-genotypic-data.html","id":"save-dosages-and-haps","chapter":"8 Prepare genotypic data","heading":"8.7.1 Save dosages and haps","text":"","code":"\nsaveRDS(dosages,file=here::here(\"data\",\"dosages.rds\"))\nsaveRDS(haps,file=here::here(\"data\",\"haplotypes.rds\"))"},{"path":"prepare-genotypic-data.html","id":"construct-grms","chapter":"8 Prepare genotypic data","heading":"8.8 Genomic Relationship Matrices (GRMs)","text":"example , use genomicMateSelectR function kinship() construct additive () dominance (D) relationship matrices.information models --implemented downstream, see vignette genomicMateSelectR, references cited therein.","code":"\nA<-kinship(dosages,type=\"add\")\nD<-kinship(dosages,type=\"domGenotypic\")\nsaveRDS(A,file=here::here(\"output\",\"kinship_add.rds\"))\nsaveRDS(D,file=here::here(\"output\",\"kinship_dom.rds\"))"},{"path":"prepare-genotypic-data.html","id":"recomb-freq-mat","chapter":"8 Prepare genotypic data","heading":"8.9 Recombination Frequency Matrix","text":"Matrix needed cross-variance predictions.","code":""},{"path":"prepare-genotypic-data.html","id":"source-a-genetic-map","chapter":"8 Prepare genotypic data","heading":"8.9.1 Source a genetic map","text":"Must match reference genome marker set used predictionNot necessarily exact markerset, overlap idealI source single genome-wide file representing ICGMC concensus genetic map V6 Cassava Reference genome. file Cassavabase FTP-archive, .120K positions.","code":"\ngenmap<-read.table(\"https://cassavabase.org/ftp/marnin_datasets/NGC_BigData/CassavaGeneticMap/cassava_cM_pred.v6.allchr.txt\",\n                   header = F, sep=';', stringsAsFactors = F) %>% \n     rename(SNP_ID=V1,Pos=V2,cM=V3) %>% \n  as_tibble\ngenmap %>% dim\n#> [1] 120979      3\ngenmap %>% head\n#> # A tibble: 6 × 3\n#>   SNP_ID     Pos    cM\n#>   <chr>    <int> <dbl>\n#> 1 S1_26576 26576   2.7\n#> 2 S1_26624 26624   2.7\n#> 3 S1_26659 26659   2.7\n#> 4 S1_27720 27720   2.7\n#> 5 S1_27739 27739   2.7\n#> 6 S1_27746 27746   2.7\nsnps_genmap<-tibble(DoseSNP_ID=colnames(dosages)) %>% \n     separate(DoseSNP_ID,c(\"Chr\",\"Pos\",\"Ref\",\"Alt\"),remove = F) %>% \n     mutate(SNP_ID=paste0(\"S\",Chr,\"_\",Pos)) %>% \n     full_join(genmap %>% \n                    separate(SNP_ID,c(\"Chr\",\"POS\"),\"_\",remove = F) %>% \n                    select(-POS) %>% \n                    mutate(Chr=gsub(\"S\",\"\",Chr)) %>% \n                    mutate(across(everything(),as.character)))\n#> Joining, by = c(\"Chr\", \"Pos\", \"SNP_ID\")\nsnps_genmap %>% \n  ggplot(.,aes(x=as.integer(Pos)/1000/1000,y=as.numeric(cM))) +\n  geom_point() +\n  theme_bw() +\n  facet_wrap(~as.integer(Chr))\n#> Warning: Removed 1567 rows containing missing values\n#> (geom_point)."},{"path":"prepare-genotypic-data.html","id":"interpolate-genetic-map","chapter":"8 Prepare genotypic data","heading":"8.9.2 Interpolate genetic map","text":"Save interpolated map, just marker loci --used downstream.","code":"\ninterpolate_genmap<-function(data){\n  # for each chromosome map\n  # find and _decrements_ in the genetic map distance\n  # fix them to the cumulative max to force map to be only increasing\n  # fit a spline for each chromosome\n  # Use it to predict values for positions not previously on the map\n  # fix them AGAIN (in case) to the cumulative max, forcing map to only increase\n  data_forspline<-data %>% \n    filter(!is.na(cM)) %>% \n    mutate(cumMax=cummax(cM),\n           cumIncrement=cM-cumMax) %>% \n    filter(cumIncrement>=0) %>% \n    select(-cumMax,-cumIncrement)\n  \n  spline<-data_forspline %$% smooth.spline(x=Pos,y=cM,spar = 0.75)\n  \n  splinemap<-predict(spline,x = data$Pos) %>% \n    as_tibble(.) %>% \n    rename(Pos=x,cM=y) %>% \n    mutate(cumMax=cummax(cM),\n           cumIncrement=cM-cumMax) %>% \n    mutate(cM=cumMax) %>% \n    select(-cumMax,-cumIncrement)\n  \n  return(splinemap) \n}\nsplined_snps_genmap<-snps_genmap %>% \n  select(-cM) %>% \n  mutate(Pos=as.numeric(Pos)) %>% \n  left_join(snps_genmap %>% \n              mutate(across(c(Pos,cM),as.numeric)) %>% \n              arrange(Chr,Pos) %>% \n              nest(-Chr) %>% \n              mutate(data=map(data,interpolate_genmap)) %>% \n              unnest(data)) %>% \n  distinct\n#> Warning: All elements of `...` must be named.\n#> Did you want `data = c(DoseSNP_ID, Pos, Ref, Alt, SNP_ID, cM)`?\n#> Joining, by = c(\"Chr\", \"Pos\")\nall(colnames(dosages) %in% splined_snps_genmap$DoseSNP_ID)\n#> [1] TRUE\nsplined_snps_genmap %>% \n     filter(DoseSNP_ID %in% colnames(dosages)) %>% \n     mutate(Map=\"Spline\") %>% \n     bind_rows(snps_genmap %>% \n                    filter(DoseSNP_ID %in% colnames(dosages),\n                           !is.na(cM)) %>% \n                    mutate(across(c(Pos,cM),as.numeric)) %>% \n                    arrange(Chr,Pos) %>% mutate(Map=\"Data\")) %>% \n  ggplot(.,aes(x=Pos/1000/1000,y=cM,color=Map, shape=Map),alpha=0.3,size=0.75) + \n  geom_point() + \n  theme_bw() + facet_wrap(~as.integer(Chr), scales='free_x')\nsplined_snps_genmap %>% \n     filter(DoseSNP_ID %in% colnames(dosages)) %>% \n     saveRDS(.,file=here::here(\"output\",\"interpolated_genmap.rds\"))"},{"path":"prepare-genotypic-data.html","id":"recomb.-freq.-matrix","chapter":"8 Prepare genotypic data","heading":"8.9.3 Recomb. freq. matrix","text":"See also, genomicMateSelectR vignette.","code":"\ngenmap<-readRDS(file=here::here(\"output\",\"interpolated_genmap.rds\"))\nm<-genmap$cM;\nnames(m)<-genmap$DoseSNP_ID\nrecombFreqMat<-1-(2*genmap2recombfreq(m,nChr = 18))\nsaveRDS(recombFreqMat,file=here::here(\"output\",\"recombFreqMat_1minus2c.rds\"))"},{"path":"preliminary-field-trial-analysis.html","id":"preliminary-field-trial-analysis","chapter":"9 Preliminary field trial analysis","heading":"9 Preliminary field trial analysis","text":"Context Purpose:Context Purpose:Upstream: Section 8 - quality control steps genotypic dataUpstream: Section 8 - quality control steps genotypic dataDownstream: Genomic prediction related analyses.Downstream: Genomic prediction related analyses.Inputs:Inputs:Expected outputs:Expected outputs:","code":""},{"path":"preliminary-field-trial-analysis.html","id":"process-map-3","chapter":"9 Preliminary field trial analysis","heading":"9.1 Process Map","text":"","code":""},{"path":"preliminary-field-trial-analysis.html","id":"one-stage-or-multi-stage","chapter":"9 Preliminary field trial analysis","heading":"9.2 One-stage or multi-stage?","text":"often large, multi-year, multi-location, multi-trial-type (MET) datasets use train genomic prediction models. number plots can range 10- even 100,000 plots many thousands unique genotypes observed unbalanced fashion across heterogenous experimental designs. say, computational burden level expertise required execute genomic prediction analyses directly data great.sake semi-automation computational efficiency, standard genomic prediction pipeline implemented NextGen Cassava, demonstrate two-stage weighted genomic prediction:Stage 1. Get BLUPsConduct preliminary analysis trial data without genomic relatedeness / marker-information.\nIdentify best-fitting model data potentially curate raw data, removing outliers.Conduct preliminary analysis trial data without genomic relatedeness / marker-information.Identify best-fitting model data potentially curate raw data, removing outliers.Fit mixed-model MET data. Extract BLUPs, PEVs variance components (VarComps). Compute de-regressed BLUPs (drgBLUPs) weights (WTS) “Stage 2.”Fit mixed-model MET data. Extract BLUPs, PEVs variance components (VarComps). Compute de-regressed BLUPs (drgBLUPs) weights (WTS) “Stage 2.”Stage 2. Cross-validation genomic predictionConduct weighted cross-validation genomic prediction analyses using de-regressed BLUPs (alternative BLUEs) response variable weights Stage 1. effectively reduces number “observations” analysis number unique genotypes (.e. clones, inbred lines, etc.), leading lower computational burden.Note advice single-stage analyses: strongly recommend conducting preliminary analysis trial data without genomic relatedeness / marker-information. Ensure model converge, residuals look acceptable otherwise assess best fitting model committing lengthy computationally intensive analyses. :)","code":""},{"path":"preliminary-field-trial-analysis.html","id":"set-up-training-datasets","chapter":"9 Preliminary field trial analysis","heading":"9.3 Set-up training datasets","text":"pipeline version analysis use TRUE/FALSE values CompleteBlocks IncompleteBlocks (Preliminary analysis trial data ).Convert data “long format” . Remove missing values. “Nest” data Trait.previously one row per plot large number columns, now things simple tidy.One row per trait. actual plot-basis data now contained within METdata, list-type column, element containing tibble.demonstrate, check contents row 1 METdata column:","code":"\nphenos<-readRDS(here::here(\"output\",\"phenotypes_cleaned.rds\"))\nphenos %>% \n     count(CompleteBlocks,IncompleteBlocks,locationName) %>% \n     spread(locationName,n)\n#> # A tibble: 1 × 3\n#>   CompleteBlocks IncompleteBlocks Ibadan\n#>   <lgl>          <lgl>             <int>\n#> 1 FALSE          FALSE              1613\ntraits<-c(\"DM\",\"MCMDS\",\"logFYLD\",\"logDYLD\")\nphenos<-phenos %>% \n     # Convert the data to \"long format\" \n     pivot_longer(cols = all_of(traits), \n                  names_to = \"Trait\", values_to = \"Value\") %>%\n     # Remove missing values\n     filter(!is.na(Value)) %>%\n     # Nest the MultiEnvironmentTrial data by trait\n     nest(METdata=c(-Trait))\nphenos %>% \n     mutate(N_plots=map_dbl(METdata,nrow))\n#> # A tibble: 4 × 3\n#>   Trait   METdata               N_plots\n#>   <chr>   <list>                  <dbl>\n#> 1 DM      <tibble [1,344 × 35]>    1344\n#> 2 MCMDS   <tibble [1,582 × 35]>    1582\n#> 3 logFYLD <tibble [1,524 × 35]>    1524\n#> 4 logDYLD <tibble [1,343 × 35]>    1343\nphenos$METdata[[1]] %>% head %>% rmarkdown::paged_table()"},{"path":"preliminary-field-trial-analysis.html","id":"considerations-before-modeling","chapter":"9 Preliminary field trial analysis","heading":"9.4 Considerations before modeling","text":"“standard” model deployed reliably Cassava MET data GS pipeline.sake demonstration, want pick one trait, model comparisons illustrate basics selecting best-fitting model., considerations.","code":""},{"path":"preliminary-field-trial-analysis.html","id":"mixed-model-software","chapter":"9 Preliminary field trial analysis","heading":"9.4.1 Mixed-model software","text":"past, used lmer() (lme4 R package) asreml() (R package interface asreml software) sort analysis. lmer() limited homogeneous error variance structures certain design models / variance structures. asreml() fast, flexible industry standard proprietary.sommer package fully open-source. sommer::mmer() function designed fit almost model asreml can, using similar syntax… much memory intensive relatively slow. sommer uses direct-inversion matrices, held -memory R., ’ll use sommer::mmer().Later, address ways speed analyses, e.g. linking R multi-threaded matrix algebra library like OpenBLAS.","code":""},{"path":"preliminary-field-trial-analysis.html","id":"learning-about-mixed-models","chapter":"9 Preliminary field trial analysis","heading":"9.4.1.1 Learning about mixed-models","text":"PLACEHOLDER LINKS, REFERENCES, ETC.","code":""},{"path":"preliminary-field-trial-analysis.html","id":"sources-of-variability","chapter":"9 Preliminary field trial analysis","heading":"9.4.2 Sources of variability","text":"Fixed Factors:yearInLoc: fixed-effect year-location combinationRandom Factors:germplasmName: random genetic effect, primary aim compute BLUPs termrepInTrial: complete block replicate effects levels uniquely nested within trials (studyName's)blockInRep: incomplete blocks, levels unique nested within replicates (within repInTrial's)Error Variance:studyName: heterogeneous error variances trial?Another option might use plotArea, plantsPerPlot, trialType“Bonus” points: extra time, plantingDate harvestDate information may provide important covariates: example correct yield dry matter trial--trial differences developmental stage (age) harvest…","code":""},{"path":"preliminary-field-trial-analysis.html","id":"parallel-process-with-future","chapter":"9 Preliminary field trial analysis","heading":"9.4.3 Parallel process with future","text":", wanted fit 4 different models data. initial tests, felt inpatient.decided demonstrate version parallel processing laptops able . used package future run model time.See quick overview library(future) learn ., choose plan(multisession) (activates parallel future processing), opposed default, plan(sequential).get models run background, time, substitute %<-%{ } <- code .","code":""},{"path":"preliminary-field-trial-analysis.html","id":"comparison-of-models","chapter":"9 Preliminary field trial analysis","heading":"9.5 Comparison of models","text":"follows demonstration, complete evaluation options, shows strategy compare models.Pick first chunk METdata.trials (studyNames) complete /incomplete blocking structures. reason, “standard” model ’ve implemented NextGen Cassava predictions last several years :yearInLoc: fixed factorrepInTrial blockInRep random using () variance structure model trials CompleteBlocks==\"TRUE\".phenotype plot-basis yield component, e.g. logFYLD, include PropNOHAV additional fixed-effect covariate.","code":"\n# grab just one chunk of the data to \"experiment\" on\nMETdata<-phenos$METdata[[1]] %>% \n     # sommer doesn't recognize logical T/F variables\n     mutate(CompleteBlocks=as.character(CompleteBlocks), \n            IncompleteBlocks=as.character(IncompleteBlocks))"},{"path":"preliminary-field-trial-analysis.html","id":"fit-models","chapter":"9 Preliminary field trial analysis","heading":"9.5.1 Fit models","text":"following code block implements 4 different models, execute background time.","code":"\nlibrary(future);\nplan(multisession)\n\n# the model I've applied to NextGen predictions the last several years\nconv_model %<-%{ mmer(Value~yearInLoc,\n                 random=~germplasmName + \n                      vs(at(CompleteBlocks,\"TRUE\"),repInTrial) + \n                      vs(at(IncompleteBlocks,\"TRUE\"),blockInRep),\n                 data=METdata, \n                 verbose = FALSE) }\n# add heterogeneous-error variance for each trial (studyName)\nconv_het_error_model %<-% { mmer(Value~yearInLoc,\n                                 random=~germplasmName + \n                                      vs(at(CompleteBlocks,\"TRUE\"),repInTrial) + \n                                      vs(at(IncompleteBlocks,\"TRUE\"),blockInRep),\n                                 rcov=~vs(ds(studyName),units),\n                                 data=METdata, \n                                 verbose = FALSE) }\n# simplify: no het. error, no at() variance structure\nsimple_model %<-% { mmer(Value~yearInLoc,\n                         random=~germplasmName + repInTrial + blockInRep,\n                         data=METdata, \n                         verbose = FALSE) }\n# no at() variance structure, include het. error variance by trial\nsimple_het_error_model %<-% { mmer(Value~yearInLoc,\n                                   random=~germplasmName + repInTrial + blockInRep,\n                                   rcov=~vs(ds(studyName),units),\n                                   data=METdata, \n                                   verbose = FALSE) }\n# Save output of above so the above models don't need to be re-run\n## if and when I reformat or otherwise re-knit this doc to HTML\nsave(conv_model,conv_het_error_model,simple_model,simple_het_error_model,\n     file=here::here(\"output\",\"models_compared.Rdata\"))"},{"path":"preliminary-field-trial-analysis.html","id":"model-comparisons","chapter":"9 Preliminary field trial analysis","heading":"9.5.2 Model comparisons","text":"model fits best? compare?sommer provides anova() pairwise comparisons models using likelihood ratio test AIC, BIC.’s -pretty -high-throughput way set-table comparing AIC 4 models.“simple” heterogeneous error model fits data best, ’ll go ahead use demonstration.addition, plot-basis yield traits, proportion stands harvested (PropNOHAV) fixed-effect covariate.","code":"\n# load the output from the models from where I stored it\nload(here::here(\"output\",\"models_compared.Rdata\"))\nanova(conv_model,conv_het_error_model)\n#> Likelihood ratio test for mixed models\n#> ==============================================================\n#>      Df      AIC      BIC     loLik    Chisq ChiDf\n#> mod2 17 652.6920 663.2478 -324.3460               \n#> mod1 10 701.9414 712.4973 -348.9707 49.24947     7\n#>                      PrChisq\n#> mod2                        \n#> mod1 2.0273987089018e-08 ***\n#> ==============================================================\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#>      Df      AIC      BIC     loLik    Chisq ChiDf\n#> mod2 17 652.6920 663.2478 -324.3460               \n#> mod1 10 701.9414 712.4973 -348.9707 49.24947     7\n#>                      PrChisq\n#> mod2                        \n#> mod1 2.0273987089018e-08 ***\ntibble(Model=c(\"conv_model\",\"conv_het_error_model\",\"simple_model\",\"simple_het_error_model\"),\n       AIC=c(conv_model$AIC,conv_het_error_model$AIC,simple_model$AIC,simple_het_error_model$AIC)) %>% \n     arrange(AIC) %>% gt::gt()"},{"path":"preliminary-field-trial-analysis.html","id":"learn-functions-and-iteration","chapter":"9 Preliminary field trial analysis","heading":"9.6 Learn functions and iteration","text":"point, taking moment familiarize R packages programming concepts might adviseable.Learn read write functions RLearn iterate procedures R","code":""},{"path":"preliminary-field-trial-analysis.html","id":"write-functions-in-r","chapter":"9 Preliminary field trial analysis","heading":"9.6.1 Write functions in R","text":"https://swcarpentry.github.io/r-novice-inflammation/02-func-R/https://r4ds..co.nz/functions.html","code":""},{"path":"preliminary-field-trial-analysis.html","id":"iteration-in-the-tidyverse","chapter":"9 Preliminary field trial analysis","heading":"9.6.2 Iteration in the tidyverse","text":"Packages purrr (parallel processing) furrr.https://r4ds..co.nz/iteration.htmlhttps://www.r-bloggers.com/2021/09/tidy-parallel-processing--r--furrr/https://purrr.tidyverse.org/https://dcl-prog.stanford.edu/purrr-mutate.htmlhttps://dcl-prog.stanford.edu/purrr-parallel.htmlhttps://furrr.futureverse.org/","code":""},{"path":"preliminary-field-trial-analysis.html","id":"analyze-all-traits","chapter":"9 Preliminary field trial analysis","heading":"9.7 Analyze all traits","text":"Next, fit “best” model previous step, traits., ’ll take time illustrate tidy way set-execute model, processing traits parallel.short, four data chunks set-tibble phenosLet’s go step--step build good understanding programming workflow. ’ll use similar procedures many analyses data processes downstream.write function take data chunk (tibbles stored phenos$METdata) input argument.’ll execute function (thus analysis) simultaneously (parallel) across data chunks using furrr package.","code":"\nphenos\n#> # A tibble: 4 × 2\n#>   Trait   METdata              \n#>   <chr>   <list>               \n#> 1 DM      <tibble [1,344 × 35]>\n#> 2 MCMDS   <tibble [1,582 × 35]>\n#> 3 logFYLD <tibble [1,524 × 35]>\n#> 4 logDYLD <tibble [1,343 × 35]>"},{"path":"preliminary-field-trial-analysis.html","id":"test-code-for-function","chapter":"9 Preliminary field trial analysis","heading":"9.7.1 Test code for function","text":"’s want call mmer() fit mixed-model look like:build function around , want able input different values ofthe arguments mmer(), namely: data=, fixed=, random= rcov=.Note case, actual difference among traits example going added fixed effect yield traits, PropNOHAV.’s can call mmer() inside another function, using variables code chunk input arguments:Took 5 whole minutes fit , yikes.Outlier Detection Removal: standard pipeline includes outlier detection removal. (1) Fit model. (2) Define outliers observations absolute-value standardized residuals >3.3. (3) Remove outliers re-fit model. (4) Check remove residuals . (5) residuals detected removed, re-fit final time.sake simple, quick example, demonstration , just one round removing outliers.Next extract format outputs want mixed-model; combined list passed return() statement function building.chunk , extract compute number things:Model fit stats like AIC, log likelihood number grouping factors, mostly stored posterityModel fit stats like AIC, log likelihood number grouping factors, mostly stored posterityVariance component estimatesVariance component estimatesA broad-sense heritability value H2A broad-sense heritability value H2Extract BLUPs corresponding PEVs (prediction error variance) genotype-factor (“germplasmName”)Extract BLUPs corresponding PEVs (prediction error variance) genotype-factor (“germplasmName”)Compute\nreliabilities (REL) BLUP\nde-regressed BLUPs (drgBLUP)\nWeighting factor (WT) BLUP, used downstream analyses drgBLUP supplied response variable.\nComputereliabilities (REL) BLUPreliabilities (REL) BLUPde-regressed BLUPs (drgBLUP)de-regressed BLUPs (drgBLUP)Weighting factor (WT) BLUP, used downstream analyses drgBLUP supplied response variable.Weighting factor (WT) BLUP, used downstream analyses drgBLUP supplied response variable.sections (see ), ’ll break used.","code":"\n# DON\"T RUN\nsimple_het_error_model<-mmer(fixed = Value~yearInLoc,\n                             random=~germplasmName + repInTrial + blockInRep,\n                             rcov=~vs(ds(studyName),units),\n                             data=METdata, getPEV = T)\n# Input arguments for the function:\nTrait<-phenos$Trait[[1]] \n# input for \"data=\"\nMETdata<-phenos$METdata[[1]]\n# input for \"fixed=\"\nfixedFormula<-ifelse(Trait %in% c(\"logDYLD\",\"logFYLD\",\"logRTNO\",\"logTOPYLD\"),\n                     \"Value ~ yearInLoc + PropNOHAV\",\n                     \"Value ~ yearInLoc\")\n# input for \"random=\"\nrandFormula<-\"~germplasmName + repInTrial + blockInRep\";\n# input for \"rcov=\"\nrcovFormula=\"~vs(ds(studyName),units)\"\nstarttime<-proc.time()[3]\nmmer_output<-mmer(fixed = as.formula(fixedFormula),\n                  random = as.formula(randFormula),\n                  rcov = as.formula(rcovFormula),\n                  data=METdata, \n                  getPEV = T)\nstoptime<-proc.time()[3]; elapsed<-stoptime-starttime; elapsed/60\n# iteration    LogLik     wall    cpu(sec)   restrained\n#     1      -367.006   10:18:35      31           0\n#     2      -338.545   10:19:5      61           0\n#     3      -325.9   10:19:38      94           0\n#     4      -321.988   10:20:8      124           0\n#     5      -321.2   10:20:37      153           0\n#     6      -321.017   10:21:4      180           0\n#     7      -320.971   10:21:29      205           0\n#     8      -320.959   10:21:55      231           0\n#     9      -320.956   10:22:20      256           0\n#     10      -320.955   10:22:46      282           0\n#  elapsed \n# 4.775417 \n# index observations that are defined as outliers\noutliers<-which(abs(scale(mmer_output$residuals))>3.3)\nlength(outliers) # How many?\n# [1] 6\n# remove outliers, if any\nif(length(outliers)>0){ \n     x<-METdata[-outliers,] \n     # Refit the model\n     starttime<-proc.time()[3]\n     mmer_output<-mmer(fixed = as.formula(fixedFormula),\n                              random = as.formula(randFormula),\n                              rcov= as.formula(rcovFormula),\n                              data=x, \n                              getPEV = T)\n     stoptime<-proc.time()[3]; elapsed<-stoptime-starttime; elapsed/60\n}\nif(length(outliers)==0){ outliers<-NULL }\n\nsave(mmer_output,outliers,\n     file=here::here(\"output\",\"mmer_output_example_during_stage1.Rdata\"))\nload(here::here(\"output\",\"mmer_output_example_during_stage1.Rdata\"))\n\n# summary(mmer_output)\n\n# log likelihood of the model, AIC, convergence T/F\nmodelfit<-summary(mmer_output)$logo\n# number of groups for factors, could be used to compute DF \ngroups<-summary(mmer_output)$groups\n# variance components\nvarcomp<-summary(mmer_output)$varcomp\n\n# genotypic variance\nVg<-mmer_output$sigma$germplasmName %>% as.vector()\n# Mean error-variance across trials \n## across heterogeneous error variance estimates\nmeanHetVarE<-mmer_output$sigma %>% \n     .[names(.) %>% grep(\":units\",.,value=T)] %>% \n     unlist() %>% \n     mean()\n# Mean number of reps per accession\nmeanNreps<-METdata %>%\n     count(germplasmName) %$% mean(n)\n# Broad-sense heritability\nH2<-Vg/(Vg+(meanHetVarE/meanNreps))\n\n# Extract the BLUPs and PEVs, compute Reliability (REL), \n# de-regressed BLUPs and weights for downstream analysis\nblups<-mmer_output$U$germplasmName$Value %>% \n     tibble(germplasmName=names(.),BLUP=.) %>% \n     mutate(germplasmName=gsub(\"germplasmName\",\"\",germplasmName),\n            # prediction error variance\n            PEV=diag(mmer_output$PevU$germplasmName$Value), \n            REL=1-PEV/Vg, # Reliability\n            drgBLUP=BLUP/REL, # De-regressed BLUP\n            WT=(1-H2)/((0.1 + (1-REL)/REL)*H2) # weight for downstream\n            )\n\n# Combine all outputs into one object the function can return() \nout<-tibble(H2=H2,meanHetVarE=meanHetVarE,meanNreps=meanNreps,\n            modelfit=list(modelfit),\n            groups=list(groups),\n            blups=list(blups),\n            varcomp=list(varcomp),\n            outliers=list(outliers))"},{"path":"preliminary-field-trial-analysis.html","id":"set-up-the-function","chapter":"9 Preliminary field trial analysis","heading":"9.7.2 Set-up the function","text":"combined code chunks function get_blups(). spare duplication code , function R script: code/get_blups.R.NOTE DEBUGGING: Building executing analyses way often iterative process. first run function get_blups(), noticed results . case, leftout argument function() call. Details important. SUGGESTION: put code actual function(), test single code chunk, especially analysis run long time use large resources.","code":""},{"path":"preliminary-field-trial-analysis.html","id":"run-the-full-analysis","chapter":"9 Preliminary field trial analysis","heading":"9.7.3 Run the full analysis","text":"Finally, ready source function built execute full analysis traits .next chunk uses function future_pmap() furrr package exectute get_blups() function across four traits parallel.Took 17 minutes run laptop :(","code":"\nsource(here::here(\"code\",\"get_blups.R\"))\nphenos %<>% \n     mutate(fixedFormula=ifelse(Trait %in% c(\"logDYLD\",\"logFYLD\",\"logRTNO\",\"logTOPYLD\"),\n                                \"Value ~ yearInLoc + PropNOHAV\",\n                                \"Value ~ yearInLoc\"),\n            randFormula=\"~germplasmName + repInTrial + blockInRep\",\n            rcovFormula=\"~vs(ds(studyName),units)\")\nstarttime<-proc.time()[3]\nrequire(furrr); plan(multisession, workers = 4)\nblups<-phenos %>%\n     mutate(modelOut=future_pmap(.,get_blups)) %>% \n     unnest(modelOut)\nstoptime<-proc.time()[3]; elapsed<-stoptime-starttime; elapsed/60\n#  elapsed \n# 17.25957 \n# Save\nsaveRDS(blups,file = here::here(\"output\",\"blups.rds\"))"},{"path":"preliminary-field-trial-analysis.html","id":"why-is-mcmds-heritability-0","chapter":"9 Preliminary field trial analysis","heading":"9.7.4 Why is MCMDS heritability 0?","text":"H2 MCMDS 0? Aside unfortunate result, knowing unusual / atypical requires knowledge cassava genetic architecture.heritablity DM, logFYLD logDYLD pretty much line “typical” results, MCMDS cassava populations pretty heritable trait.notice 33 outliers MCMDS.Let’s look distribution MCMDS raw data:actually often MCMDS scores look like.observations removed outliers?exclusively high scores.wonder removing mistake:find , let’s re-run analysis just MCMDS, time turning outlier removal . actually added removeOutliers=T/F argument lines code get_blups() function make happen:DECLARING MCMDS LOSS can see summary, MCMDS dataset essentially genetic variance / reliability. sake moving example, exclude MCMDS consideration.breeding program critical experiment, stop . alternative trials draw data , non-normally distributed, pseudo-count distributed MCMDS data can modeled .","code":"\nblups<-readRDS(here::here(\"output\",\"blups.rds\"))\n# blups %>% rmarkdown::paged_table()\nblups %>% \n     dplyr::select(Trait,H2,meanHetVarE,meanNreps,outliers) %>% \n     mutate(H2=round(H2,3),\n            meanNreps=round(meanNreps,3),\n            outliers=map_dbl(outliers,length)) %>% \n     rmarkdown::paged_table()\nblups$METdata[[2]] %>% ggplot(.,aes(x=Value)) + \n     geom_density()\nblups$METdata[[2]][blups$outliers[[2]],] %$% summary(Value)\n#>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#>    3.50    4.00    4.00    4.03    4.00    5.00\nsource(here::here(\"code\",\"get_blups.R\"))\nblups_mcmds_noRemoveOut<-phenos %>%\n     filter(Trait==\"MCMDS\") %>% \n     mutate(modelOut=pmap(.,get_blups,removeOutliers = FALSE)) %>% \n     unnest(modelOut)\nsave(blups_mcmds_noRemoveOut,\n     file=here::here(\"output\",\"blups_mcmds_noRemoveOut.Rdata\"))\nload(here::here(\"output\",\"blups_mcmds_noRemoveOut.Rdata\"))\nblups_mcmds_noRemoveOut %>% \n     dplyr::select(Trait,H2,meanHetVarE,meanNreps,outliers) %>% \n     mutate(H2=round(H2,3),\n            meanNreps=round(meanNreps,3),\n            outliers=map_dbl(outliers,length)) %>% \n     rmarkdown::paged_table()\nblups_mcmds_noRemoveOut$blups[[1]] %>% \n     summary(across(~summary(.)))\n#>  germplasmName           BLUP           \n#>  Length:945         Min.   :-3.112e-26  \n#>  Class :character   1st Qu.:-1.212e-27  \n#>  Mode  :character   Median :-8.745e-28  \n#>                     Mean   : 2.747e-29  \n#>                     3rd Qu.:-3.398e-28  \n#>                     Max.   : 1.143e-25  \n#>       PEV                 REL           \n#>  Min.   :2.301e-27   Min.   :0.000e+00  \n#>  1st Qu.:2.301e-27   1st Qu.:0.000e+00  \n#>  Median :2.301e-27   Median :0.000e+00  \n#>  Mean   :2.301e-27   Mean   :1.096e-11  \n#>  3rd Qu.:2.301e-27   3rd Qu.:0.000e+00  \n#>  Max.   :2.301e-27   Max.   :4.742e-10  \n#>     drgBLUP                 WT           \n#>  Min.   :      -Inf   Min.   :0.000e+00  \n#>  1st Qu.:      -Inf   1st Qu.:0.000e+00  \n#>  Median :      -Inf   Median :0.000e+00  \n#>  Mean   :       NaN   Mean   :2.426e+15  \n#>  3rd Qu.:-6.563e-17   3rd Qu.:0.000e+00  \n#>  Max.   :       Inf   Max.   :1.050e+17"},{"path":"preliminary-field-trial-analysis.html","id":"de-regression-explained","chapter":"9 Preliminary field trial analysis","heading":"9.8 De-regressed BLUPs and weighted two-stage prediction","text":"BLUP represents single performance prediction unique germplasmName without accounting genomic relatedness using marker data accounting potentially unbalanced original trial data’s experimental design factors. BLUPs units original trait centered population mean.BLUPs shrunken, .e. regressed towards mean.Downstream genomic predictions fit germplasmName random effect mixed-model. reasion, using BLUPs directly response variable doubly shrink data. Instead, advised called “de-regression” BLUPs Garrick et al. (2009).de-regressed BLUP (drgBLUP) simply BLUP divided quantity called reliability \\(r^{2}\\).reliability defined : \\(r^{2} = 1 - \\frac{PEV}{\\sigma^{2}_{g}}\\)PEV: = prediction error variance, measure exactly sounds like, error variance associated individual prediction, may different among predictions, depending data. ran sommer::mmer() set getPEV=TRUE later extracted diagonal-values resulting PEV matrix (PEV=diag(mmer_output$PevU$germplasmName$Value)).\\(\\sigma^{2}_{g}\\) = genetic variance estimated Step 1. PEV always fraction total genetic variance.Thus reliability ranges 0 1 measures certainty surrounding BLUP value; rather, probability BLUP change anothe experiment (data point) added. \\(r^{2}=1\\), essentially zero expected error BLUP. example, check varieties often many observations dataset high reliability.de-regressed BLUP defined \\(\\frac{BLUP}{r^{2}}\\) can see clones high reliability, BLUP stay essentially , reliability low, BLUP un-shrink de-regress strongly. going happen genotypes observations thus low reliability strongly shrunken zero first step.density plot showing distribution original data compared BLUP drgBLUP. meant show shrinkage unshrinkage effect data. Since BLUPs drgBLUPs centered mean, added back grand mean comparison original data.Next, grab blups germplasmName two highest two lowest REL. cases, de-regressed BLUP shift away mean, proportional reliability. , devised plot show :de-regressed BLUP used response variable downstream genomic prediction.can account differential reliability among genotypes downstream using weighted analysis. compute weights according Garrick et al. (2009). Using sommer::mmer(), weights can supplied weights= argument (see sommer::mmer documentation details). values supplied weight error term proportional \\(\\frac{1}{\\sqrt{WT}}\\), meaning drgBLUP higher WT smaller error; effect prediction.Garrick et al. (2009)’s recommended weight :\\[WT = \\frac{1-H^{2}}{0.1+\\frac{1-r^{2}}{r^{r}} \\times H^{2}}\\]\\(H^{2}\\) broad-sense heritability (H2).\\(r^{2}\\) reliability (REL).made plot showing WT varies across range H2 REL. show weighting behaves. see, WT scales REL H2. H2 conditions overall variability among individuals weight analysis. works heritability low, greater relative premium (weight) placed individuals high quality data (high REL), usually high numbers observations, e.g. check-genotypes. heritability high, WTs low isn’t much difference low high REL.’s plot shows actual blups, WT scales number observations-per-genotype.Next, plot BLUPs de-regressed BLUPs scale point-size (WT) color (REL). red line slope 1. can see clearly high reliability predictions don’t change much (close red line). can also see farther BLUP mean, de-regression (original shrinkage).","code":"\npopMean<-mean(blups$METdata[[1]]$Value)\nblups$METdata[[1]] %>% \n     dplyr::select(observationUnitDbId,Value) %>% \n     mutate(Data=\"Original Data\") %>% \n     bind_rows(blups$blups[[1]] %>% \n                    dplyr::select(germplasmName,BLUP,drgBLUP) %>% \n                    pivot_longer(cols=c(\"BLUP\",\"drgBLUP\"),\n                                 names_to = \"Data\", values_to = \"Value\") %>% \n                    mutate(Value=Value+popMean)) %>% \n     ggplot(.,aes(x=Value,fill=Data)) + geom_density(alpha=0.75) + theme_bw() +\n     geom_vline(xintercept = popMean)\nlibrary(ggrepel)\nblups$blups[[1]] %>% \n     slice_max(order_by = REL,n = 2) %>%\n     bind_rows(blups$blups[[1]] %>% \n                    slice_min(order_by = REL,n = 2)) %>% \n     dplyr::select(germplasmName,REL,BLUP,drgBLUP) %>% \n     pivot_longer(cols = c(\"BLUP\",\"drgBLUP\"),\n                  names_to = \"Data\",values_to = \"Value\") %>% \n     ggplot(.,aes(x=Value,y=germplasmName,\n                  color=REL,group=germplasmName)) + \n     geom_line() + \n     geom_point(aes(shape=Data)) + \n     geom_text_repel(aes(label=Data)) + \n     geom_vline(xintercept = 0) \nREL<-H2<-seq(from=0.1,to=0.9,by=0.05)\nexpand.grid(REL=REL,H2=H2) %>% \n     mutate(WT=(1-H2)/((0.1 + (1-REL)/REL)*H2)) %>% \n     ggplot(.,aes(x=REL,y=WT,color=H2, group=H2)) + geom_line() \nblups$blups[[1]] %>% \n     # Count the number of plots per clone in the raw data and merge to the BlUPs\n     left_join(blups$METdata[[1]] %>% count(germplasmName,name = \"Nplots\")) %>% \n     ggplot(.,aes(x=Nplots,y=WT)) + geom_point()\n#> Joining, by = \"germplasmName\"\nblups$blups[[1]] %>% \n     # Count the number of plots per clone in the raw data and merge to the BlUPs\n     left_join(blups$METdata[[1]] %>% count(germplasmName,name = \"Nplots\")) %>% \n     ggplot(.,aes(x=BLUP,y=drgBLUP,color=REL,size=WT)) + \n     geom_point() + geom_vline(xintercept = 0) + geom_hline(yintercept = 0) +\n     geom_abline(slope=1, color='darkred')\n#> Joining, by = \"germplasmName\""},{"path":"preliminary-field-trial-analysis.html","id":"computing-h2-for-weights","chapter":"9 Preliminary field trial analysis","heading":"9.8.1 Computing H2 for weights","text":"Quick note computing \\(H^2\\) WTs . Heterogeneneous error variance model lend standard compute \\(H^2\\) across trials.need \\(H^2\\) reflects overall dataset. analysis used heterogenoeous error variances. Therefore, decided use following \\(H^2\\):\\[H^2 = \\frac{\\sigma^2_g}{\\sigma^2_g+\\bar{\\sigma^2_{e}}/\\bar{n}_{reps}}\\]\\(\\sigma^2_g\\) mixed-model estimate.\\(\\bar{\\sigma^2_{e}}\\) average error-variance estimate across trials.\\(\\bar{n}_{reps}\\) mean number reps per genotype dataset.\\(H^2\\) definition reflect average trial average number replicates per line.Alternatives definitely possible users encouraged question experiment!","code":""},{"path":"preliminary-field-trial-analysis.html","id":"mixed-models-in-brief","chapter":"9 Preliminary field trial analysis","heading":"9.9 Mixed models in brief","text":"often factors effect experiments don’t specifically care . example, might replicate experiment within site planting two different fields design. can easily imagine small variations soil, slope aspect, elevation planting date might influence outcome least extent. time, aren’t effect field planting date. want learn general location whole.can make assumption universe possible outcomes given part field station, example, might observed. Every replicate / experiment just shows us one manifestation .makes replication, field planting date random variable.addition, data often complex messy. Sample sizes individual grouping variables often leave something desired , especially trying fit complicated models many parameters. top data points might truly independent - instance, spatial autocorrelation plots blocks similar similar location. , case genomic selection, might information genetic relatedness germplasm growing, can measure want account .mixed models developed, deal messy data allow us use data, even low sample sizes, structured data, many covariates fit. Oh, top mixed models allow us save degrees freedom compared running standard linear models! Sounds good, doesn’t ?broad terms, fixed effects variables expect effect dependent/response variable. time, random effects usually grouping factors trying control. lot time specifically interested impact response variable. Additionally, data random effect just sample possibilities.three paragraphs paraphrased (https://ourcodingclub.github.io/2017/03/15/mixed-models.html).major exception statement using random-effects control e.g. replication variance: genotypes.primary objective obtain correct rankings genetic- heritable-economic value accession, order determine cross advance.","code":""},{"path":"preliminary-field-trial-analysis.html","id":"links-for-learning","chapter":"9 Preliminary field trial analysis","heading":"9.9.1 Links for learning","text":"https://si.biostat.washington.edu/sites/default/files/modules/Seattle-SISG-18-IntroQG-Lecture08.pdfhttps://towardsdatascience.com/-linear-mixed-model-works-350950a82911https://stats.oarc.ucla.edu//mult-pkg/introduction--linear-mixed-models/Excellence Breeding - Basics GS - 2021 YouTube Video Series Eduardo Covarrubias","code":""},{"path":"intro-to-genomic-prediction.html","id":"intro-to-genomic-prediction","chapter":"10 Intro to Genomic Prediction","heading":"10 Intro to Genomic Prediction","text":"previous sections, processed prepared genotype data downstream analyses. also gathered prepared phenotypic data, ultimately summarizing plot-basis data BLUP values individual training population.data ready genomic predictions.process map indicates next step use cross-validation check prediction accuracy, completing prediction genomic estimated breeding values (GEBV) selections.proceeding applied pipeline, work section introduction genomic prediction R.training quantitative genetics, mixed-models genomic prediction, consider jumping bottom section chapter recommended literature learning resources.","code":""},{"path":"intro-to-genomic-prediction.html","id":"librarygenomicmateselectr","chapter":"10 Intro to Genomic Prediction","heading":"10.1 library(genomicMateSelectR)","text":"facilitate genomic selection pipeline, built R package, genomicMateSelectR, can cross-validation, predictions using functions. already encountered functions package previously, filtered variants, constructed kinship matrices also recombination frequency matrix.previous steps, focused simply applying functions creating inputs process map indicates need. didn’t spend much time previously discussing inputs wanted .functions genomicMateSelectR, using functions library(sommer). Rather simply applying functions instructed, ’ll dig --hood understand happening.also recommended check-work vignettes genomicMateSelectR, also help.bottom chapter, ’ll provide links references learning . highly recommend reading learning multiple sources, single author explains everything perfectly everyone.","code":""},{"path":"intro-to-genomic-prediction.html","id":"genomic-blup","chapter":"10 Intro to Genomic Prediction","heading":"10.2 Genomic BLUP","text":"previous section, learned use mmer() function library(sommer) fit mixed-models without including genomic information.modeled germplasmName variable, distinguishes unique genotypes (.e. cassava clones) random-effect extracted predicted BLUP clone measure performance. model, unique germpasmName modeled default independent identically distributed (..d.). words, lacking additional information input model, assumed clone unrelated clone. situation, can obtain performance predictions clones phenotypes.simple, mixed-model notation, ignoring fixed-effects simplicity:\\[\\boldsymbol{y} =\\mu + \\boldsymbol{g} +\\boldsymbol{\\epsilon}\\] first equation says phenotype \\(y\\) predicted overall population mean \\(\\mu\\) + genetic values individual germplasmName (\\(g\\), basically genotype clone mean) plus unexplained residual values (\\(\\epsilon\\)).\\[g \\sim N(0,\\sigma^2_{g})\\]second notation says term \\(g\\) modeled random effect, drawn normal distribution (indicated N) mean zero, variance parameter \\(\\sigma^2_{g}\\) covariance \\(\\boldsymbol{}\\). Since \\(\\boldsymbol{}\\) stands identity matrix, zeros -diagonal, 1’s diagonal, clones modeled unrelated; words, independent identically distributed (..d.).know assumption incorrect. individuals population expected related level.make genomic prediction model, primarily use mixed-model approach known “genomic BLUP” GBLUP short.GBLUP model, instead using identity matrix \\(\\) say clones unrelated, directly measure degree relatedness individuals using SNP markers distributed genome-wide. create called “genomic relatedness matrix” (GRM), also called often called kinship matrix often notated \\(\\boldsymbol{K}\\).make mixed-model used previous section get BLUPs genomic prediction model, “simply” replace \\(\\boldsymbol{}\\) \\(\\boldsymbol{K}\\) mixed-model equations:\\[g \\sim N(0,K\\sigma^2_{g})\\] assuming relative similarity dissimilarity performance clones proportional degree relatedness.model germplasmName variable covariance, GRM mixed-model obtain BLUPs, can call GBLUPs, conditioned resemblance relatives. long GRM constructed using particular formula, predicted breeding values, thus term ’ve heard: genomic estimated breeding values (GEBVs).mixed-model equations can accommodate prediction individuals genotypes kinship matrix, even phenotypes. words, can predict performance individuals basis (ideally close) relatives.","code":""},{"path":"intro-to-genomic-prediction.html","id":"getting-started","chapter":"10 Intro to Genomic Prediction","heading":"10.2.1 Getting started","text":"Start BLUPs previous step.","code":"\nblups<-readRDS(here::here(\"output\",\"blups.rds\"))"},{"path":"intro-to-genomic-prediction.html","id":"kinship-matrix","chapter":"10 Intro to Genomic Prediction","heading":"10.2.2 Kinship matrix","text":"chapter preparing genotypic data, used database-sourced genotype data genomicMateSelectR function kinship() create additive genomic relationship matrix.Let’s take look contents matrix:Notice square (number rows columns) symmetrix around diagonal values.-diagonals express genomic relatedness different individuals dataset.formulation mean-value zero, >0 kinship means “average population level relatedness” <0 values mean “greater average.”diagonal values express relatedness individual , interpreted level inbreeding (homozygosity).matrix constructed using formula implemented “classic” rrBLUP function .mat(): VanRaden (2008), Method 1.find paper Vitezica et al. 2013 particularly helpful understanding additive (non-additive) genomic relationships: Vitezica et al. (2013).understand :http://nce.ads.uga.edu/wiki/lib/exe/fetch.php?media=uga_3_relationship.pdfhttps://colloque.inrae.fr/iufro2016/content/download/5576/73493/version/1/file/Legarra_IUFROArcachon_2016.pdfhttps://plant-breeding-genomics.extension.org/genomic-relationships--gblup/","code":"\nA<-readRDS(file=here::here(\"output\",\"kinship_add.rds\"))\nA[1:5,1:5]\n#>                    IITA-TMS-IBA30572 IITA-TMS-IBA940237\n#> IITA-TMS-IBA30572         0.86194941        -0.09134081\n#> IITA-TMS-IBA940237       -0.09134081         0.95954799\n#> IITA-TMS-IBA961642       -0.20180585         0.04458302\n#> IITA-TMS-ONN920168        0.15812456        -0.09358516\n#> IITA-TMS-WAR4080          0.82642409        -0.09229778\n#>                    IITA-TMS-IBA961642 IITA-TMS-ONN920168\n#> IITA-TMS-IBA30572         -0.20180585         0.15812456\n#> IITA-TMS-IBA940237         0.04458302        -0.09358516\n#> IITA-TMS-IBA961642         1.00259446        -0.16869620\n#> IITA-TMS-ONN920168        -0.16869620         0.95173805\n#> IITA-TMS-WAR4080          -0.19569202         0.15481065\n#>                    IITA-TMS-WAR4080\n#> IITA-TMS-IBA30572        0.82642409\n#> IITA-TMS-IBA940237      -0.09229778\n#> IITA-TMS-IBA961642      -0.19569202\n#> IITA-TMS-ONN920168       0.15481065\n#> IITA-TMS-WAR4080         0.85217903\ndim(A)\n#> [1] 963 963\nhist(A[lower.tri(A)], main='Off-diagonal values (lower-triangle) of the kinship matrix')\nhist(diag(A), main='Diagonals of the kinship', breaks=20)"},{"path":"intro-to-genomic-prediction.html","id":"genomic-prediction","chapter":"10 Intro to Genomic Prediction","heading":"10.2.3 Genomic prediction","text":"Now need implement GBLUP model using mmer().One thing note:go back chapter preparing genotypic data recall dataset, phenotyped---genotyped lines.also genotyped---phenotyped lines.always important check verify result getting makes sense. accessions appearing genotyped (phenotyped), expecting? , need trace . may names didn’t match, require fixing preferably database ensure long-term improvement ease correctness analyses.Phenotyped---genotyped lines need excluded analysis. Genotyped---phenotyped lines, discussed accepted can predicted.time, de-regressed BLUPs (drgBLUP) previous step response data. use weights (WT) computed previously weights= argument mmer().’s get GEBV mmer() output:Things notice:346 phenotyped lines included. 963 genotyped lines kinship matrix. 963 GEBV predicted!GEBV centered zero.","code":"\n# pull out one trait (DM) BLUPs\ndm_blups<-blups$blups[[1]]\ndm_blups %>% head\n#> # A tibble: 6 × 6\n#>   germplasmName        BLUP   PEV   REL drgBLUP    WT\n#>   <chr>               <dbl> <dbl> <dbl>   <dbl> <dbl>\n#> 1 IITA-TMS-IBA000070 -0.776 0.172 0.963  -0.806  5.27\n#> 2 IITA-TMS-IBA070593 -4.38  0.389 0.917  -4.78   3.82\n#> 3 IITA-TMS-IBA30572  -0.690 0.162 0.965  -0.715  5.37\n#> 4 IITA-TMS-IBA980581 -1.17  0.173 0.963  -1.21   5.26\n#> 5 IITA-TMS-IBA982101 -1.94  0.467 0.900  -2.15   3.45\n#> 6 TMEB419             1.59  0.240 0.949   1.68   4.73\ntable(dm_blups$germplasmName %in% rownames(A))\n#> \n#> FALSE  TRUE \n#>   463   346\ntable(rownames(A) %in% dm_blups$germplasmName)\n#> \n#> FALSE  TRUE \n#>   617   346\ndm_blups %<>% \n     filter(germplasmName %in% rownames(A))\ngblup_all<-mmer(fixed = drgBLUP~1,\n                # here we specify a random-effect for the \"germplasmName\" variable\n                # and supply the kinship matrix \"A\" as follows:\n                random = ~vs(germplasmName,Gu=A),\n                weights = WT,\n                data=dm_blups)\n#> Adding additional levels of Gu in the model matrix of 'germplasmName' \n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -187.325   13:43:38      0           0\n#>     2      -187.167   13:43:38      0           0\n#>     3      -187.095   13:43:39      1           0\n#>     4      -187.077   13:43:39      1           0\n#>     5      -187.075   13:43:39      1           0\n#>     6      -187.075   13:43:39      1           0\ngebv<-gblup_all$U$`u:germplasmName`$drgBLUP\n# Notice the \"germplasmName\" and \"drgBLUP\" references in this call \n## are specific to the analysis/dataset in question. \n## See the sommer manual on CRAN. \nlength(gebv)\n#> [1] 963\nsummary(gebv)\n#>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#> -2.9475 -0.3902  0.0270  0.0000  0.4331  1.6265"},{"path":"intro-to-genomic-prediction.html","id":"prediction-accuracy","chapter":"10 Intro to Genomic Prediction","heading":"10.2.4 Prediction accuracy","text":"Now can move potentially complicated arena: evaluating prediction accuracy.many scenarios styles .Let’s start super simple.346 phenotyped lines, randomly sample approx. 1/5 (20%) 70 lines.Remove lines chosen (test_set) training dataset:Fit prediction model:, 963 lines kinship matrix get GEBV output.Now can compare (correlate) GEBV predicted held-test_set lines BLUPs lines.considered estimate “prediction accuracy”.Correlate GEBV BLUP test_set.correlation represents estimate accuracy predicting lines aren’t phenotyped, based genetic relatedness phenotypes relatives.Sure, low values. ’s small dataset using small sample markers make compute fast example purposes.","code":"\nset.seed(1212)\ntest_set<-sample(dm_blups$germplasmName,size = ceiling(346/5), replace = F)\ntraining_blups<-dm_blups %>% \n     filter(!germplasmName %in% test_set)\ngblup_train<-mmer(fixed = drgBLUP~1,\n                  # here we specify a random-effect for the \"germplasmName\" variable\n                  # and supply the kinship matrix \"A\" as follows:\n                  random = ~vs(germplasmName,Gu=A),\n                  weights = WT,\n                  data=training_blups)\n#> Adding additional levels of Gu in the model matrix of 'germplasmName' \n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -151.68   13:43:40      0           0\n#>     2      -151.327   13:43:40      0           0\n#>     3      -151.132   13:43:40      0           0\n#>     4      -151.062   13:43:40      0           0\n#>     5      -151.049   13:43:40      0           0\n#>     6      -151.046   13:43:40      0           0\n#>     7      -151.046   13:43:40      0           0\n# grab the gebv only for the test_set lines\ngebv_test<-gblup_train$U$`u:germplasmName`$drgBLUP[test_set]\n# merge the original BLUPs (for the test set only) to the corresponding GEBV\n# I use a left_join() or merge() to be absolutely sure there are no mix-ups\ngebv_vs_blups_testset<-dm_blups %>% \n     filter(germplasmName %in% test_set) %>% \n     left_join(tibble(germplasmName=names(gebv_test),GEBV=as.numeric(gebv_test)))\n#> Joining, by = \"germplasmName\"\ngebv_vs_blups_testset %$% cor(BLUP,GEBV)\n#> [1] 0.09310568"},{"path":"intro-to-genomic-prediction.html","id":"cross-validation","chapter":"10 Intro to Genomic Prediction","heading":"10.3 Cross-validation","text":"’s simplest, cross-validation involves assessing expected accuracy predicting untested lines procedure multiple times across multiple random samples.’s nice graphic illustrate:Click original, animated version.quick google search “k-fold cross validation” find plenty good graphical explanations.Cross-validation functions get complicated quickly loops within loops. built function runCrossVal() fits several different models, handles multiple traits, can run -parallel across mutiple compute-cores even accepts selection index weights compute selection index accuracy. runCrossVal() included genomicMateSelectR package., use 1 trait, additive-model.NOTES: - doesn’t work properly unless gid=\"GID\". - also requires remove phenotyped lines aren’t genotyped.Following chunk :NOTE: Ignore NcompleteTestPairs variable. ’s broken, unimportant haven’t time yet fix . checked carefully actual prediction accuracy correct.","code":"\nblups_forRunCrossValFunc<-blups %>% \n     # just one trait\n     slice(1) %>% \n     # need to rename the \"blups\" list to comply with the runCrossVal function\n     rename(TrainingData=blups) %>% \n     dplyr::select(Trait,TrainingData) %>% \n     # need also to remove phenotyped-but-not-genotyped lines\n     # couldn't hurt to also subset the kinship to only phenotyped lines... would save RAM\n     mutate(TrainingData=map(TrainingData,\n                             ~filter(.,germplasmName %in% rownames(A)) %>% \n                                  # rename the germplasmName column to GID\n                                  rename(GID=germplasmName)))\nstandardCV<-runCrossVal(blups=blups_forRunCrossValFunc,\n                        modelType=\"A\",\n                        selInd=FALSE,\n                        grms=list(A=A),\n                        nrepeats=2,nfolds=5,\n                        gid=\"GID\",seed=424242,\n                        ncores=5)\n#> Loading required package: rsample\n#> Loading required package: furrr\n#> Loading required package: future\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -144.984   13:43:43      0           0\n#>     2      -144.923   13:43:43      0           0\n#>     3      -144.908   13:43:44      1           0\n#>     4      -144.907   13:43:44      1           0\n#>     5      -144.907   13:43:44      1           0\n#> [1] \"GBLUP model complete - one trait\"\n#> [1] \"Genomic predictions done for all traits in one repeat-fold\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -153.227   13:43:44      0           0\n#>     2      -152.232   13:43:44      0           0\n#>     3      -151.805   13:43:45      1           0\n#>     4      -151.687   13:43:45      1           0\n#>     5      -151.669   13:43:45      1           0\n#>     6      -151.666   13:43:45      1           0\n#>     7      -151.666   13:43:45      1           0\n#> [1] \"GBLUP model complete - one trait\"\n#> [1] \"Genomic predictions done for all traits in one repeat-fold\"\n#> Joining, by = \"GID\"\n#> Joining, by = \"GID\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -151.026   13:43:44      0           0\n#>     2      -150.948   13:43:44      0           0\n#>     3      -150.911   13:43:44      0           0\n#>     4      -150.901   13:43:44      0           0\n#>     5      -150.899   13:43:44      0           0\n#>     6      -150.899   13:43:44      0           0\n#> [1] \"GBLUP model complete - one trait\"\n#> [1] \"Genomic predictions done for all traits in one repeat-fold\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -149.818   13:43:45      0           0\n#>     2      -149.812   13:43:45      0           0\n#>     3      -149.809   13:43:45      0           0\n#>     4      -149.808   13:43:45      0           0\n#> [1] \"GBLUP model complete - one trait\"\n#> [1] \"Genomic predictions done for all traits in one repeat-fold\"\n#> Joining, by = \"GID\"\n#> Joining, by = \"GID\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -151.038   13:43:45      1           0\n#>     2      -150.851   13:43:45      1           0\n#>     3      -150.757   13:43:45      1           0\n#>     4      -150.728   13:43:45      1           0\n#>     5      -150.723   13:43:45      1           0\n#>     6      -150.722   13:43:45      1           0\n#> [1] \"GBLUP model complete - one trait\"\n#> [1] \"Genomic predictions done for all traits in one repeat-fold\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -151.393   13:43:46      1           0\n#>     2      -151.304   13:43:46      1           0\n#>     3      -151.258   13:43:46      1           0\n#>     4      -151.245   13:43:46      1           0\n#>     5      -151.243   13:43:46      1           0\n#>     6      -151.243   13:43:46      1           0\n#> [1] \"GBLUP model complete - one trait\"\n#> [1] \"Genomic predictions done for all traits in one repeat-fold\"\n#> Joining, by = \"GID\"\n#> Joining, by = \"GID\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -151.902   13:43:45      0           0\n#>     2      -151.609   13:43:45      0           0\n#>     3      -151.464   13:43:45      0           0\n#>     4      -151.417   13:43:45      0           0\n#>     5      -151.409   13:43:45      0           0\n#>     6      -151.407   13:43:45      0           0\n#>     7      -151.407   13:43:46      1           0\n#> [1] \"GBLUP model complete - one trait\"\n#> [1] \"Genomic predictions done for all traits in one repeat-fold\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -149.63   13:43:46      0           0\n#>     2      -149.534   13:43:46      0           0\n#>     3      -149.48   13:43:46      0           0\n#>     4      -149.46   13:43:46      0           0\n#>     5      -149.457   13:43:46      0           0\n#>     6      -149.456   13:43:46      0           0\n#> [1] \"GBLUP model complete - one trait\"\n#> [1] \"Genomic predictions done for all traits in one repeat-fold\"\n#> Joining, by = \"GID\"\n#> Joining, by = \"GID\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -150.381   13:43:46      0           0\n#>     2      -150.129   13:43:46      0           0\n#>     3      -150.014   13:43:46      0           0\n#>     4      -149.984   13:43:46      0           0\n#>     5      -149.98   13:43:46      0           0\n#>     6      -149.98   13:43:46      0           0\n#> [1] \"GBLUP model complete - one trait\"\n#> [1] \"Genomic predictions done for all traits in one repeat-fold\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -144.924   13:43:47      1           0\n#>     2      -144.405   13:43:47      1           0\n#>     3      -144.256   13:43:47      1           0\n#>     4      -144.235   13:43:47      1           0\n#>     5      -144.234   13:43:47      1           0\n#> [1] \"GBLUP model complete - one trait\"\n#> [1] \"Genomic predictions done for all traits in one repeat-fold\"\n#> Joining, by = \"GID\"\n#> Joining, by = \"GID\"\nstandardCV %>% unnest(accuracyEstOut) \n#> # A tibble: 10 × 9\n#>    repeats  seeds splits     id    Trait predOf predVSobs   \n#>      <int>  <int> <list>     <chr> <chr> <chr>  <list>      \n#>  1       1 395601 <split [2… Fold1 DM    GEBV   <tibble [96…\n#>  2       1 395601 <split [2… Fold2 DM    GEBV   <tibble [96…\n#>  3       1 395601 <split [2… Fold3 DM    GEBV   <tibble [96…\n#>  4       1 395601 <split [2… Fold4 DM    GEBV   <tibble [96…\n#>  5       1 395601 <split [2… Fold5 DM    GEBV   <tibble [96…\n#>  6       2 215870 <split [2… Fold1 DM    GEBV   <tibble [96…\n#>  7       2 215870 <split [2… Fold2 DM    GEBV   <tibble [96…\n#>  8       2 215870 <split [2… Fold3 DM    GEBV   <tibble [96…\n#>  9       2 215870 <split [2… Fold4 DM    GEBV   <tibble [96…\n#> 10       2 215870 <split [2… Fold5 DM    GEBV   <tibble [96…\n#> # … with 2 more variables: Accuracy <dbl>,\n#> #   NcompleteTestPairs <dbl>\n# Run this code to prove it, if you are interested :)\n# just checking the number of paired GEBV-BLUPs per test-set:\n# standardCV %>% \n#      unnest(accuracyEstOut) %>% \n#      mutate(NcompleteTestPairs=map_dbl(predVSobs,~na.omit(.) %>% nrow(.)))"},{"path":"intro-to-genomic-prediction.html","id":"rrblup-and-equivalency-to-gblup","chapter":"10 Intro to Genomic Prediction","heading":"10.4 rrBLUP and equivalency to GBLUP","text":"","code":""},{"path":"intro-to-genomic-prediction.html","id":"rr-blup-aka-snp-blup","chapter":"10 Intro to Genomic Prediction","heading":"10.4.1 RR-BLUP aka SNP-BLUP","text":"want briefly cover demonstrate alternative, right circumstances, equivalent model genomic prediction: ridge-regression BLUP, aka SNP-BLUP. rrBLUP model genome-wide marker regression model. many styles , especially Bayesian arena.marker-regression models, SNPs used directly predictors regression model, instead using create relatedness matrix. RRBLUP GBLUP use mixed-model approach.GBLUP :\\[\\boldsymbol{y} =\\mu + \\boldsymbol{g} +\\boldsymbol{\\epsilon}\\] random-effect predictor simply clone identity (germplasmName) covariance identities input kinship matrix.RR-BLUP, instead:\\[\\boldsymbol{y} =\\mu + \\boldsymbol{Zu} +\\boldsymbol{\\epsilon}\\]\\[u \\sim N(0,\\sigma^2_{u})\\]\\(\\boldsymbol{Z}\\) matrix dimension N-individuals P-SNPs. vector \\(\\boldsymbol{u}\\) dimension P-SNP 1 contains BLUPs, case represent SNP-effect predictions (SNP-BLUPs), mean-effect 0, drawn ..d. normal distribution variance \\(\\sigma^2_{u}\\). Note variance parameter variance among SNP-effects, variance among GEBV clones.GEBV obtainable model : \\(\\boldsymbol{g} = \\boldsymbol{Zu}\\).equivalence RRBLUP GBLUP come matrix predictors, \\(\\boldsymbol{Z}\\) centered way genomic relationshp matrix.Click go section 1.2.1 “VanRaden’s first genomic relationship matrix” explanation formula used kinship matrix., ’ll demonstrate:Fit GBLUP modelNow fit RRBLUP model","code":"\n# load the dosage matrix\nM<-readRDS(file=here::here(\"data\",\"dosages.rds\"))\n# re-load and extract the blups for just 1 trait\nblups<-readRDS(file=here::here(\"output\",\"blups.rds\"))\ndm_blups<-blups$blups[[1]]\n# remove phenotyped-but-not-genoypted blups\ndm_blups %<>% \n     filter(germplasmName %in% rownames(M))\n# remove genotyped-but-not-phenoypted (not strictly necessary)\nM<-M[rownames(M) %in% dm_blups$germplasmName,]\n# Create a kinship matrix \"K\"\nK<-kinship(M,\"add\")\n# Now create a centered dosage matrix, to use as predictors for rr-BLUP\nZ<-centerDosage(M)\ngblup<-mmer(fixed = drgBLUP~1,\n            random = ~vs(germplasmName,Gu = K),\n            weights = WT,\n            data=dm_blups)\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -187.324   13:43:48      1           0\n#>     2      -187.166   13:43:48      1           0\n#>     3      -187.095   13:43:48      1           0\n#>     4      -187.077   13:43:48      1           0\n#>     5      -187.075   13:43:48      1           0\n#>     6      -187.075   13:43:48      1           0\n# one catch\n# the rows of the centered dosage matrix must be matched\n## to the rows of data.frame with the blups\n## one way to do this is by creating and incidence matrix\n## use the model.matrix() function as follows:\nZincMat=model.matrix(~factor(germplasmName,levels=rownames(Z))-1,data=dm_blups) # -1 because we don't want an intercept here\ndim(ZincMat) # [1] 346 346 \n#> [1] 346 346\n# relates the rows of the BLUPs to the rows the marker matrix\n\n# now fit the RRBLUP model\nrrblup<-mmer(fixed = drgBLUP~1,\n             random = ~vs(list(ZincMat%*%Z),buildGu = FALSE),\n             weights = WT,\n             data=dm_blups)\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -269.814   13:43:50      2           0\n#>     2      -195.427   13:43:51      3           0\n#>     3      -190.328   13:43:51      3           0\n#>     4      -187.801   13:43:51      3           0\n#>     5      -187.201   13:43:51      3           0\n#>     6      -187.093   13:43:51      3           0\n#>     7      -187.077   13:43:51      3           0\n#>     8      -187.075   13:43:51      3           0\n#>     9      -187.075   13:43:51      3           0\n# extract the SNP-BLUPs\nu<-as.matrix(rrblup$U$`u:Z`$drgBLUP)\nall(rownames(u)==colnames(Z))\n#> [1] TRUE\nsummary(u)\n#>        V1            \n#>  Min.   :-0.0163276  \n#>  1st Qu.:-0.0024412  \n#>  Median :-0.0001831  \n#>  Mean   :-0.0002119  \n#>  3rd Qu.: 0.0020687  \n#>  Max.   : 0.0151979\nhist(u,breaks=20,main = 'Distribution of SNP effects')\n# extract the G-BLUPs (GEBVs)\ng<-gblup$U$`u:germplasmName`$drgBLUP\nall(names(g) %in% rownames(Z))\n#> [1] TRUE\n# calculate the GEBVs using the SNP-effects (SNP-BLUPs)\ng_rr<-Z[names(g),]%*%u\nall(rownames(g_rr)==names(g))\n#> [1] TRUE\ng_rr[1:5,]\n#> IITA-TMS-IBA000070 IITA-TMS-IBA070593  IITA-TMS-IBA30572 \n#>         -0.1260352         -2.0363146         -0.7000067 \n#> IITA-TMS-IBA980581 IITA-TMS-IBA982101 \n#>         -0.9159732         -1.5152420\ng[1:5]\n#> IITA-TMS-IBA000070 IITA-TMS-IBA070593  IITA-TMS-IBA30572 \n#>         -0.1254919         -2.0334329         -0.6996188 \n#> IITA-TMS-IBA980581 IITA-TMS-IBA982101 \n#>         -0.9151958         -1.5134661\n# cor(g,g_rr) # [1,] 0.9999997\nplot(x=g,y=g_rr, main = 'Proof that GEBV from GBLUP and RRBLUP are the equal!'); abline(a=0,b=1,col='red')"},{"path":"intro-to-genomic-prediction.html","id":"recommended-literature","chapter":"10 Intro to Genomic Prediction","heading":"10.5 Recommended Literature","text":"Check open-source 3-section short-course:\n“Survey Breeding Tools (Genomic Selection) Methods” Particio Munoz Felipe Ferrao U. Florida. best short space cover (1) introductory quantitative genetic models, (2) Statistical learning whole-genome regression models, esp. rrBLUP GBLUP models, (3) theoretical practical aspects genomic selection.haven’t looked details, also offer open-source plant breeding focused “Quantitative Genetics” course!list borrowed credit Felipe Ferrão’s course:","code":""},{"path":"intro-to-genomic-prediction.html","id":"quantitative-genetics","chapter":"10 Intro to Genomic Prediction","heading":"10.5.1 Quantitative Genetics","text":"Bernardo, 2010. Breeding Quantitative Traits Plant Breeding. Book linkFalconer Mackay, 1996. Introduction Quantitative Genetics. Book linkLynch Walsh, 1998. Genetics Analysis Quantitative Traits. Book link","code":""},{"path":"intro-to-genomic-prediction.html","id":"genomic-selection","chapter":"10 Intro to Genomic Prediction","heading":"10.5.2 Genomic Selection","text":"Wolfe 2016. Genomic Selection: Prediction Methodology & Practical Application. Lecture Slides (gSlides) presented “Regional Southeast Asian Cassava Breeder’s Network Training” November 2016. gSlides LinkMrode, 2014. Linear Models Prediction Animal Breeding Values. Book linkIsik et al., 2017. Genetic Data Analysis Plant Animal Breeding. Book link","code":""},{"path":"intro-to-genomic-prediction.html","id":"additional-free-learning-resources","chapter":"10 Intro to Genomic Prediction","heading":"10.5.3 Additional (free) learning resources","text":"Learn genomic predictionSlides Bruce Walsh BLUP Genomic SelectionSlides Bruce Walsh BLUP Genomic SelectionMixed Models Quantitative Genetics Bruce WalshMixed Models Quantitative Genetics Bruce WalshLecture 5: BLUP (Best Linear Unbiased Predictors) genetic values - Bruce WalshLecture 5: BLUP (Best Linear Unbiased Predictors) genetic values - Bruce WalshExcellence Breeding - Basics GS - 2021 YouTube Video Series Eduardo CovarrubiasExcellence Breeding - Basics GS - 2021 YouTube Video Series Eduardo Covarrubias","code":""},{"path":"standard-k-fold-cross-validation.html","id":"standard-k-fold-cross-validation","chapter":"11 Standard K-fold Cross-validation","heading":"11 Standard K-fold Cross-validation","text":"Context Purpose:Context Purpose:Upstream: Section @ref() -Upstream: Section @ref() -Downstream:Downstream:Inputs:Inputs:Expected outputs:Expected outputs:section run K-fold cross-validation evaluate accuracy predicting performance candidate parents (GEBV) phenotyped.always recommended, alternative kinds predictions set-measure .Important distinction analyses downstream assess accuracy predicting performance crosses (.e. mates).use runCrossVal() function.demonstrate additional features provides process:Support multiple traitsComputing selection index accuracyFinally, ’ll make simple plot results.","code":""},{"path":"standard-k-fold-cross-validation.html","id":"process-map-4","chapter":"11 Standard K-fold Cross-validation","heading":"11.1 Process Map","text":"","code":""},{"path":"standard-k-fold-cross-validation.html","id":"set-up-for-the-cross-validation","chapter":"11 Standard K-fold Cross-validation","heading":"11.2 Set-up for the cross-validation","text":"steps set-us almost way.","code":"\nblups<-readRDS(here::here(\"output\",\"blups.rds\"))\nA<-readRDS(file=here::here(\"output\",\"kinship_add.rds\"))\nblups %<>% \n     # need to rename the \"blups\" list to comply with the runCrossVal function\n     rename(TrainingData=blups) %>% \n     dplyr::select(Trait,TrainingData) %>% \n     # need also to remove phenotyped-but-not-genotyped lines\n     # couldn't hurt to also subset the kinship to only phenotyped lines... would save RAM\n     mutate(TrainingData=map(TrainingData,\n                             ~filter(.,germplasmName %in% rownames(A)) %>% \n                                  # rename the germplasmName column to GID\n                                  rename(GID=germplasmName)))\n\nblups\n#> # A tibble: 4 × 2\n#>   Trait   TrainingData      \n#>   <chr>   <list>            \n#> 1 DM      <tibble [346 × 6]>\n#> 2 MCMDS   <tibble [292 × 6]>\n#> 3 logFYLD <tibble [350 × 6]>\n#> 4 logDYLD <tibble [348 × 6]>\n# For fastest, lightest compute of accuracy, remove non-phenotyped from kinship\n\ngids<-blups %>% \n     unnest(TrainingData) %$% unique(GID)\n# dim(A) [1] 963 963\n\nA<-A[gids,gids]"},{"path":"standard-k-fold-cross-validation.html","id":"selection-indices","chapter":"11 Standard K-fold Cross-validation","heading":"11.3 Selection indices","text":"Last thing: Let’s include selection index weights. can find excellent, detailed, open-source chapter Walsh & Lynch Selection Index Theory clicking .\\[SI = WT_1 \\times Trait_1 + \\dots + WT_t \\times Trait_t\\] vector form:\\[SI = \\boldsymbol{\\hat{g}b}\\]\\(SI\\) selection index, dimension \\([n \\times 1]\\). \\(b\\) \\([t \\times 1]\\) vector selection index “economic weights” designed value trait relative impact economic potential changing corresponding trait one unit. Finally, \\(\\boldsymbol{\\hat{g}\\) matrix \\([n \\times t]\\) (case) GEBV trait columns.runCrossVal() accept named vector selection index weights names must match “Trait” variable blups using SIwts= argument setting selInd=TRUE.example weights, ’ll use. taken canonical. Weights determined target population environments product profile!’ll run meager 2 repetitions 5-fold cross-validation, means 10 predictions per trait overall. ’ve got 16-core laptop can use ncores=10 10 predictions per trait time. runCrossVal() process four traits compute selection index accuracy end.","code":"\n# I chose to remove MCMDS \n## our preliminary analysis showed it to have ~0 heritability in this dataset\n## initial test of cross-val. showed the models do not fit\nSIwts<-c(DM=15,\n         #MCMDS=-10,\n         logFYLD=20,\n         logDYLD=20)\nSIwts\n#>      DM logFYLD logDYLD \n#>      15      20      20"},{"path":"standard-k-fold-cross-validation.html","id":"execute-cross-validation","chapter":"11 Standard K-fold Cross-validation","heading":"11.4 Execute cross-validation","text":"Save results","code":"\nstarttime<-proc.time()[3]\nstandardCV<-runCrossVal(blups=blups %>% filter(Trait != \"MCMDS\"),\n                        modelType=\"A\",\n                        selInd=TRUE,SIwts=SIwts,\n                        grms=list(A=A),\n                        nrepeats=2,nfolds=5,\n                        gid=\"GID\",seed=424242,\n                        ncores=10)\n#> Loading required package: rsample\n#> Loading required package: furrr\n#> Loading required package: future\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -150.932   13:44:1      0           0\n#>     2      -150.587   13:44:1      0           0\n#>     3      -150.456   13:44:2      1           0\n#>     4      -150.431   13:44:2      1           0\n#>     5      -150.429   13:44:2      1           0\n#>     6      -150.429   13:44:2      1           0\n#> [1] \"GBLUP model complete - one trait\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -109.584   13:44:2      0           0\n#>     2      -109.57   13:44:2      0           0\n#>     3      -109.562   13:44:2      0           0\n#>     4      -109.56   13:44:2      0           0\n#>     5      -109.559   13:44:2      0           0\n#> [1] \"GBLUP model complete - one trait\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -115.829   13:44:2      0           0\n#>     2      -115.829   13:44:3      1           0\n#>     3      -115.828   13:44:3      1           0\n#>     4      -115.828   13:44:3      1           0\n#> [1] \"GBLUP model complete - one trait\"\n#> [1] \"Genomic predictions done for all traits in one repeat-fold\"\n#> Joining, by = \"GID\"\n#> Joining, by = \"GID\"\n#> Joining, by = \"GID\"\n#> Joining, by = \"GID\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -153.247   13:44:2      0           0\n#>     2      -153.244   13:44:2      0           0\n#>     3      -153.243   13:44:2      0           0\n#>     4      -153.243   13:44:2      0           0\n#> [1] \"GBLUP model complete - one trait\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -108.226   13:44:2      0           0\n#>     2      -108.147   13:44:2      0           0\n#>     3      -108.101   13:44:3      1           0\n#>     4      -108.087   13:44:3      1           0\n#>     5      -108.085   13:44:3      1           0\n#>     6      -108.085   13:44:3      1           0\n#> [1] \"GBLUP model complete - one trait\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -117.592   13:44:3      0           0\n#>     2      -117.537   13:44:3      0           0\n#>     3      -117.513   13:44:3      0           0\n#>     4      -117.509   13:44:3      0           0\n#>     5      -117.508   13:44:3      0           0\n#> [1] \"GBLUP model complete - one trait\"\n#> [1] \"Genomic predictions done for all traits in one repeat-fold\"\n#> Joining, by = \"GID\"\n#> Joining, by = \"GID\"\n#> Joining, by = \"GID\"\n#> Joining, by = \"GID\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -150.198   13:44:2      0           0\n#>     2      -149.363   13:44:3      1           0\n#>     3      -148.987   13:44:3      1           0\n#>     4      -148.881   13:44:3      1           0\n#>     5      -148.865   13:44:3      1           0\n#>     6      -148.863   13:44:3      1           0\n#>     7      -148.862   13:44:3      1           0\n#> [1] \"GBLUP model complete - one trait\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -106.107   13:44:3      0           0\n#>     2      -105.581   13:44:3      0           0\n#>     3      -105.152   13:44:3      0           0\n#>     4      -104.92   13:44:3      0           0\n#>     5      -104.852   13:44:3      0           0\n#>     6      -104.832   13:44:3      0           0\n#>     7      -104.827   13:44:4      1           0\n#>     8      -104.825   13:44:4      1           0\n#>     9      -104.825   13:44:4      1           0\n#> [1] \"GBLUP model complete - one trait\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -118.481   13:44:4      0           0\n#>     2      -118.255   13:44:4      0           0\n#>     3      -118.106   13:44:4      0           0\n#>     4      -118.047   13:44:4      0           0\n#>     5      -118.035   13:44:4      0           0\n#>     6      -118.032   13:44:4      0           0\n#>     7      -118.032   13:44:4      0           0\n#> [1] \"GBLUP model complete - one trait\"\n#> [1] \"Genomic predictions done for all traits in one repeat-fold\"\n#> Joining, by = \"GID\"\n#> Joining, by = \"GID\"\n#> Joining, by = \"GID\"\n#> Joining, by = \"GID\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -144.958   13:44:3      0           0\n#>     2      -144.946   13:44:3      0           0\n#>     3      -144.94   13:44:3      0           0\n#>     4      -144.939   13:44:3      0           0\n#>     5      -144.939   13:44:3      0           0\n#> [1] \"GBLUP model complete - one trait\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -107.241   13:44:3      0           0\n#>     2      -107.24   13:44:4      1           0\n#>     3      -107.24   13:44:4      1           0\n#>     4      -107.24   13:44:4      1           0\n#> [1] \"GBLUP model complete - one trait\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -114.776   13:44:4      0           0\n#>     2      -114.775   13:44:4      0           0\n#>     3      -114.775   13:44:4      0           0\n#>     4      -114.775   13:44:4      0           0\n#> [1] \"GBLUP model complete - one trait\"\n#> [1] \"Genomic predictions done for all traits in one repeat-fold\"\n#> Joining, by = \"GID\"\n#> Joining, by = \"GID\"\n#> Joining, by = \"GID\"\n#> Joining, by = \"GID\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -150.502   13:44:3      0           0\n#>     2      -150.404   13:44:4      1           0\n#>     3      -150.354   13:44:4      1           0\n#>     4      -150.339   13:44:4      1           0\n#>     5      -150.336   13:44:4      1           0\n#>     6      -150.336   13:44:4      1           0\n#> [1] \"GBLUP model complete - one trait\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -112.48   13:44:4      0           0\n#>     2      -112.42   13:44:4      0           0\n#>     3      -112.38   13:44:4      0           0\n#>     4      -112.364   13:44:4      0           0\n#>     5      -112.36   13:44:4      0           0\n#>     6      -112.358   13:44:4      0           0\n#>     7      -112.358   13:44:4      0           0\n#> [1] \"GBLUP model complete - one trait\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -118.347   13:44:5      0           0\n#>     2      -118.041   13:44:5      0           0\n#>     3      -117.869   13:44:5      0           0\n#>     4      -117.803   13:44:5      0           0\n#>     5      -117.787   13:44:5      0           0\n#>     6      -117.784   13:44:5      0           0\n#>     7      -117.783   13:44:5      0           0\n#> [1] \"GBLUP model complete - one trait\"\n#> [1] \"Genomic predictions done for all traits in one repeat-fold\"\n#> Joining, by = \"GID\"\n#> Joining, by = \"GID\"\n#> Joining, by = \"GID\"\n#> Joining, by = \"GID\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -150.226   13:44:4      0           0\n#>     2      -149.466   13:44:4      0           0\n#>     3      -149.138   13:44:4      0           0\n#>     4      -149.063   13:44:4      0           0\n#>     5      -149.056   13:44:4      0           0\n#>     6      -149.055   13:44:4      0           0\n#> [1] \"GBLUP model complete - one trait\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -111.205   13:44:5      1           0\n#>     2      -111.2   13:44:5      1           0\n#>     3      -111.196   13:44:5      1           0\n#>     4      -111.193   13:44:5      1           0\n#>     5      -111.193   13:44:5      1           0\n#> [1] \"GBLUP model complete - one trait\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -115.15   13:44:5      0           0\n#>     2      -115.132   13:44:5      0           0\n#>     3      -115.119   13:44:5      0           0\n#>     4      -115.114   13:44:6      1           0\n#>     5      -115.113   13:44:6      1           0\n#>     6      -115.112   13:44:6      1           0\n#> [1] \"GBLUP model complete - one trait\"\n#> [1] \"Genomic predictions done for all traits in one repeat-fold\"\n#> Joining, by = \"GID\"\n#> Joining, by = \"GID\"\n#> Joining, by = \"GID\"\n#> Joining, by = \"GID\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -150.983   13:44:4      0           0\n#>     2      -150.511   13:44:5      1           0\n#>     3      -150.265   13:44:5      1           0\n#>     4      -150.179   13:44:5      1           0\n#>     5      -150.162   13:44:5      1           0\n#>     6      -150.158   13:44:5      1           0\n#>     7      -150.157   13:44:5      1           0\n#> [1] \"GBLUP model complete - one trait\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -109.264   13:44:5      0           0\n#>     2      -109.264   13:44:5      0           0\n#>     3      -109.264   13:44:6      1           0\n#>     4      -109.263   13:44:6      1           0\n#> [1] \"GBLUP model complete - one trait\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -116.271   13:44:6      0           0\n#>     2      -116.238   13:44:6      0           0\n#>     3      -116.225   13:44:6      0           0\n#>     4      -116.223   13:44:6      0           0\n#>     5      -116.223   13:44:6      0           0\n#> [1] \"GBLUP model complete - one trait\"\n#> [1] \"Genomic predictions done for all traits in one repeat-fold\"\n#> Joining, by = \"GID\"\n#> Joining, by = \"GID\"\n#> Joining, by = \"GID\"\n#> Joining, by = \"GID\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -146.729   13:44:5      0           0\n#>     2      -146.707   13:44:5      0           0\n#>     3      -146.695   13:44:5      0           0\n#>     4      -146.691   13:44:5      0           0\n#>     5      -146.691   13:44:6      1           0\n#> [1] \"GBLUP model complete - one trait\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -105.14   13:44:6      0           0\n#>     2      -105.116   13:44:6      0           0\n#>     3      -105.101   13:44:6      0           0\n#>     4      -105.095   13:44:6      0           0\n#>     5      -105.095   13:44:6      0           0\n#> [1] \"GBLUP model complete - one trait\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -116.469   13:44:6      0           0\n#>     2      -116.439   13:44:6      0           0\n#>     3      -116.428   13:44:6      0           0\n#>     4      -116.426   13:44:6      0           0\n#>     5      -116.426   13:44:6      0           0\n#> [1] \"GBLUP model complete - one trait\"\n#> [1] \"Genomic predictions done for all traits in one repeat-fold\"\n#> Joining, by = \"GID\"\n#> Joining, by = \"GID\"\n#> Joining, by = \"GID\"\n#> Joining, by = \"GID\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -146.167   13:44:6      0           0\n#>     2      -145.784   13:44:6      0           0\n#>     3      -145.645   13:44:6      0           0\n#>     4      -145.618   13:44:6      0           0\n#>     5      -145.616   13:44:6      0           0\n#>     6      -145.616   13:44:6      0           0\n#> [1] \"GBLUP model complete - one trait\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -108.335   13:44:6      0           0\n#>     2      -108.255   13:44:6      0           0\n#>     3      -108.205   13:44:6      0           0\n#>     4      -108.187   13:44:7      1           0\n#>     5      -108.184   13:44:7      1           0\n#>     6      -108.184   13:44:7      1           0\n#> [1] \"GBLUP model complete - one trait\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -115.606   13:44:7      0           0\n#>     2      -115.563   13:44:7      0           0\n#>     3      -115.541   13:44:7      0           0\n#>     4      -115.535   13:44:7      0           0\n#>     5      -115.534   13:44:7      0           0\n#> [1] \"GBLUP model complete - one trait\"\n#> [1] \"Genomic predictions done for all traits in one repeat-fold\"\n#> Joining, by = \"GID\"\n#> Joining, by = \"GID\"\n#> Joining, by = \"GID\"\n#> Joining, by = \"GID\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -152   13:44:6      0           0\n#>     2      -151.698   13:44:6      0           0\n#>     3      -151.579   13:44:6      0           0\n#>     4      -151.555   13:44:6      0           0\n#>     5      -151.554   13:44:6      0           0\n#>     6      -151.553   13:44:7      1           0\n#> [1] \"GBLUP model complete - one trait\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -107.98   13:44:7      0           0\n#>     2      -107.972   13:44:7      0           0\n#>     3      -107.968   13:44:7      0           0\n#>     4      -107.967   13:44:7      0           0\n#> [1] \"GBLUP model complete - one trait\"\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -119.501   13:44:7      0           0\n#>     2      -119.452   13:44:7      0           0\n#>     3      -119.431   13:44:7      0           0\n#>     4      -119.426   13:44:7      0           0\n#>     5      -119.425   13:44:7      0           0\n#> [1] \"GBLUP model complete - one trait\"\n#> [1] \"Genomic predictions done for all traits in one repeat-fold\"\n#> Joining, by = \"GID\"\n#> Joining, by = \"GID\"\n#> Joining, by = \"GID\"\n#> Joining, by = \"GID\"\ntimeelapsed<-proc.time()[3]-starttime; \ntimeelapsed/60\n#>   elapsed \n#> 0.1467333\nsaveRDS(standardCV,file = here::here(\"output\",\"standardCV.rds\"))"},{"path":"standard-k-fold-cross-validation.html","id":"plot-results","chapter":"11 Standard K-fold Cross-validation","heading":"11.5 Plot results","text":"result expect. SELIND similar individual trait accuracies.Best guess: SELIND requires BLUPs trait observed, clones complete data included.results different choose different dataset, hopefully better.","code":"\nstandardCV %>% \n     unnest(accuracyEstOut) %>% \n     dplyr::select(repeats,id,predOf,Trait,Accuracy) %>% \n     ggplot(.,aes(x=Trait,y=Accuracy,fill=Trait)) + \n     geom_boxplot() + theme_bw()"},{"path":"predict-parental-breeding-values.html","id":"predict-parental-breeding-values","chapter":"12 Predict parental breeding values","heading":"12 Predict parental breeding values","text":"Now tested genomic prediction accuracy using cross-validation, can run genomic predictions.previous section introduced genomic prediction, learned use mmer() function library(sommer) run GBLUP models also rrBLUP models.actual predictions, can use function build library(genomicMateSelectR), runGenomicPredictions(). can find documentation function clicking .runGenomicPredictions() wrapper uses mmer() --hood. expects de-regressed BLUPs weights input.","code":""},{"path":"predict-parental-breeding-values.html","id":"process-map-5","chapter":"12 Predict parental breeding values","heading":"12.1 Process Map","text":"","code":""},{"path":"predict-parental-breeding-values.html","id":"set-up-for-the-predictions","chapter":"12 Predict parental breeding values","heading":"12.2 Set-up for the predictions","text":"Similar set-cross-validation.Load BLUps kinship matrix.Selection index:difference: subset kinship matrix. precisely, keep genotypes meant either training set (phenotyped--genotyped) selection candidates (-necessarily-genotyped).example, simply leave lines kinship matrix.","code":"\nblups<-readRDS(here::here(\"output\",\"blups.rds\"))\nA<-readRDS(file=here::here(\"output\",\"kinship_add.rds\"))\nblups %<>% \n     # based on cross-validation, decided to exclude MCMDS from this analysis\n     filter(Trait != \"MCMDS\") %>% \n     # need to rename the \"blups\" list to comply with the runCrossVal function\n     rename(TrainingData=blups) %>% \n     dplyr::select(Trait,TrainingData) %>% \n     # need also to remove phenotyped-but-not-genotyped lines\n     mutate(TrainingData=map(TrainingData,\n                             ~filter(.,germplasmName %in% rownames(A)) %>% \n                                  # rename the germplasmName column to GID\n                                  rename(GID=germplasmName)))\n\nblups\n#> # A tibble: 3 × 2\n#>   Trait   TrainingData      \n#>   <chr>   <list>            \n#> 1 DM      <tibble [346 × 6]>\n#> 2 logFYLD <tibble [350 × 6]>\n#> 3 logDYLD <tibble [348 × 6]>\nSIwts<-c(DM=15,\n         #MCMDS=-10,\n         logFYLD=20,\n         logDYLD=20)\nSIwts\n#>      DM logFYLD logDYLD \n#>      15      20      20"},{"path":"predict-parental-breeding-values.html","id":"run-genomic-predictions","chapter":"12 Predict parental breeding values","heading":"12.3 Run genomic predictions","text":"","code":"\ngpreds<-runGenomicPredictions(modelType=\"A\",\n                              selInd=TRUE, SIwts=SIwts,\n                              blups=blups,\n                              grms=list(A=A),\n                              ncores=3)\n#> Loading required package: furrr\n#> Loading required package: future\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -187.325   13:44:13      0           0\n#>     2      -187.167   13:44:14      1           0\n#>     3      -187.095   13:44:14      1           0\n#>     4      -187.077   13:44:14      1           0\n#>     5      -187.075   13:44:14      1           0\n#>     6      -187.075   13:44:14      1           0\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -135.425   13:44:14      0           0\n#>     2      -135.406   13:44:14      0           0\n#>     3      -135.395   13:44:14      0           0\n#>     4      -135.391   13:44:14      0           0\n#>     5      -135.39   13:44:15      1           0\n#> iteration    LogLik     wall    cpu(sec)   restrained\n#>     1      -146.037   13:44:14      0           0\n#>     2      -146.031   13:44:15      1           0\n#>     3      -146.028   13:44:15      1           0\n#>     4      -146.027   13:44:15      1           0"},{"path":"predict-parental-breeding-values.html","id":"extract-gebv","chapter":"12 Predict parental breeding values","heading":"12.4 Extract GEBV","text":"Let’s look output.single-row tibble.access simple table listing GEBV trait selection index:point, can use SELIND predictions directly rank select parents.Example: sort SELIND pick top 10…detailed output, including variance component estimates:","code":"\ngpreds\n#> # A tibble: 1 × 2\n#>   gblups             genomicPredOut  \n#>   <list>             <list>          \n#> 1 <tibble [963 × 6]> <tibble [3 × 4]>\ngpreds$gblups[[1]]\n#> # A tibble: 963 × 6\n#>    GID                predOf SELIND      DM logFYLD  logDYLD\n#>    <chr>              <chr>   <dbl>   <dbl>   <dbl>    <dbl>\n#>  1 IITA-TMS-IBA30572  GEBV    -7.85 -0.610   0.0303  0.0348 \n#>  2 IITA-TMS-IBA940237 GEBV     1.04  0.0983 -0.0124 -0.00961\n#>  3 IITA-TMS-IBA961642 GEBV    15.0   0.808   0.0741  0.0713 \n#>  4 IITA-TMS-ONN920168 GEBV     3.65  0.284  -0.0129 -0.0172 \n#>  5 IITA-TMS-WAR4080   GEBV    -6.53 -0.529   0.0313  0.0391 \n#>  6 IITA-TMS-WAR4092   GEBV    -6.28 -0.513   0.0305  0.0404 \n#>  7 IITA-TMS-WAR820249 GEBV     3.33  0.0289  0.0752  0.0699 \n#>  8 IITA-TMS-WAR820422 GEBV     4.11  0.0639  0.0831  0.0746 \n#>  9 IITA-TMS-WAR940009 GEBV    13.2   0.749   0.0482  0.0480 \n#> 10 IITA-TMS-WAR940017 GEBV   -15.3  -1.12    0.0463  0.0240 \n#> # … with 953 more rows\ngpreds$gblups[[1]] %>% \n     arrange(desc(SELIND)) %>% \n     slice(1:10)\n#> # A tibble: 10 × 6\n#>    GID                predOf SELIND    DM  logFYLD  logDYLD\n#>    <chr>              <chr>   <dbl> <dbl>    <dbl>    <dbl>\n#>  1 TMS13F1307P0008    GEBV     26.7  1.59  0.0540   0.0880 \n#>  2 TMS14F1035P0004    GEBV     26.5  1.63  0.0264   0.0774 \n#>  3 TMS14F1262P0002    GEBV     24.3  1.35  0.0877   0.110  \n#>  4 TMS19F1091P0065    GEBV     22.4  1.25  0.0742   0.105  \n#>  5 TMS14F1303P0012    GEBV     22.2  1.44  0.00866  0.0197 \n#>  6 TMS14F1312P0003    GEBV     22.0  1.38  0.0258   0.0413 \n#>  7 TMS19F1041P0112    GEBV     20.5  1.05  0.104    0.134  \n#>  8 TMS19F1050P0056    GEBV     20.3  1.25  0.0175   0.0615 \n#>  9 TMS14F1284P0019    GEBV     20.2  1.39 -0.0310  -0.00172\n#> 10 IITA-TMS-ZAR000120 GEBV     19.9  1.32 -0.0156   0.0209\ngpreds$genomicPredOut[[1]]\n#> # A tibble: 3 × 4\n#>   Trait   gblups             varcomps     fixeffs     \n#>   <chr>   <list>             <list>       <list>      \n#> 1 DM      <tibble [963 × 2]> <df [2 × 4]> <df [1 × 5]>\n#> 2 logFYLD <tibble [963 × 2]> <df [2 × 4]> <df [1 × 5]>\n#> 3 logDYLD <tibble [963 × 2]> <df [2 × 4]> <df [1 × 5]>\ngpreds$genomicPredOut[[1]]$varcomps[[1]]\n#>                         VarComp VarCompSE   Zratio\n#> u:GIDa.drgBLUP-drgBLUP 1.427019 0.5677452 2.513485\n#> units.drgBLUP-drgBLUP  4.766819 0.4955154 9.619921\n#>                        Constraint\n#> u:GIDa.drgBLUP-drgBLUP   Positive\n#> units.drgBLUP-drgBLUP    Positive"},{"path":"predict-parental-breeding-values.html","id":"save-the-results","chapter":"12 Predict parental breeding values","heading":"12.5 Save the results","text":"","code":"\nsaveRDS(gpreds,file = here::here(\"output\",\"genomicPredictions.rds\"))"},{"path":"intro-to-genomic-cross-prediction.html","id":"intro-to-genomic-cross-prediction","chapter":"13 Intro to Genomic Cross Prediction","heading":"13 Intro to Genomic Cross Prediction","text":"Genomic prediction mean, variance usefulness crosses can accomplished genomicMateSelectR functions.","code":""},{"path":"intro-to-genomic-cross-prediction.html","id":"understanding-mate-selection","chapter":"13 Intro to Genomic Cross Prediction","heading":"13.1 Understanding mate selection","text":"Click google slides presentation entitled “Genomic mate selection outbred species: predicting cross usefulness additive total genetic covariance matrices” introduce concepts.theory / formulae summarized part genomicMateSelectR vignette","code":""},{"path":"intro-to-genomic-cross-prediction.html","id":"literature","chapter":"13 Intro to Genomic Cross Prediction","heading":"13.1.1 Literature","text":"recommended articles read regarding genomic mate selection (full citations bottom): (Bonk et al. 2016; Lehermeier et al. 2017; Neyhart Smith 2019; Neyhart et al. 2019; Bijma et al. 2020; Werner et al. 2020; Wolfe et al. 2021)particular, read :Wolfe et . 2021.Genomic mating outbred species: predicting cross usefulness additive total genetic covariance matrices. https://doi.org/10.1093/genetics/iyab122.Werner et al. 2020. Genomic selection strategies clonally propagated crops. https://doi.org/10.1101/2020.06.15.152017.may well need/want read literature referenced articles. , ’ll solid foundation understanding prediction cross performance.","code":""},{"path":"intro-to-genomic-cross-prediction.html","id":"tutorial","chapter":"13 Intro to Genomic Cross Prediction","heading":"13.1.2 Tutorial","text":"tutorial execute predictions using genomicMateSelectR functions, see “Getting started predicting crosses vignette”.","code":""},{"path":"intro-to-genomic-cross-prediction.html","id":"non-additive-effects","chapter":"13 Intro to Genomic Cross Prediction","heading":"13.2 Non-additive effects","text":"now, used additive-effects model (modelType=\"\"), gives us access predictions GEBV.addition, genomicMateSelectR enables two types non-additive effects models implemented: additive plus dominance model (modelType=\"AD\") directional dominance model allows inbreeding depression (heterotic) effect (modelType=\"DirDom\").","code":""},{"path":"intro-to-genomic-cross-prediction.html","id":"literature-1","chapter":"13 Intro to Genomic Cross Prediction","heading":"13.2.1 Literature","text":"basic quantitative genetics concepts additive dominance effects:\nIntro Quantitative Genetics, part Felipe Ferrão’s “Survey Breeding Tools (Genomic Selection) Methods.”\nSee also list Recommended Literature provided previous chapter Intro Genomic Prediction\nbasic quantitative genetics concepts additive dominance effects:Intro Quantitative Genetics, part Felipe Ferrão’s “Survey Breeding Tools (Genomic Selection) Methods.”See also list Recommended Literature provided previous chapter Intro Genomic PredictionSee summary additive non-additive “genomic prediction models implemented” part 2nd genomicMateSelectR vignette. See also references literature, cited .See summary additive non-additive “genomic prediction models implemented” part 2nd genomicMateSelectR vignette. See also references literature, cited .Two good papers start studying genomic prediction non-additive effects :\nVitezica et al. 2013. “Additive Dominant Variance Covariance Individuals Within Genomic Selection Scope.” Genetics 195 (4): 1223–30. https://doi.org/10.1534/genetics.113.155176\nVarona et al. 2013. “Non-Additive Effects Genomic Selection.” Frontiers Genetics 9 (March). https://doi.org/10.3389/fgene.2018.00078\nTwo good papers start studying genomic prediction non-additive effects :Vitezica et al. 2013. “Additive Dominant Variance Covariance Individuals Within Genomic Selection Scope.” Genetics 195 (4): 1223–30. https://doi.org/10.1534/genetics.113.155176Vitezica et al. 2013. “Additive Dominant Variance Covariance Individuals Within Genomic Selection Scope.” Genetics 195 (4): 1223–30. https://doi.org/10.1534/genetics.113.155176Varona et al. 2013. “Non-Additive Effects Genomic Selection.” Frontiers Genetics 9 (March). https://doi.org/10.3389/fgene.2018.00078Varona et al. 2013. “Non-Additive Effects Genomic Selection.” Frontiers Genetics 9 (March). https://doi.org/10.3389/fgene.2018.00078","code":""},{"path":"intro-to-genomic-cross-prediction.html","id":"tutorial-1","chapter":"13 Intro to Genomic Cross Prediction","heading":"13.2.2 Tutorial","text":"vignette genomicMateSelectR entitled “Genomic prediction non-additive effects”provides complete tutorial execute models predicting cross-performance .","code":""},{"path":"intro-to-genomic-cross-prediction.html","id":"parent-wise-cross-validation","chapter":"13 Intro to Genomic Cross Prediction","heading":"13.3 Parent-wise Cross-validation","text":"can estimate accuracy predicting previously untested crosses?mate selection article, Wolfe et al. (2021) devised cross-validation strategy uses pedigree -based approach, called “parent-wise cross-validation.” approach described detail manuscript. illustrated starting Slide 50 gSlides presentation.genomicMateSelectR provides function runParentWiseCrossVal() (see documentation / details) implement kind cross-validation.example ’s implementation -practice part IITA 2021 Genomic Selection documentation .next section, attempt smaller example using data working manual.","code":""},{"path":"parentwise_cross_val.html","id":"parentwise_cross_val","chapter":"14 Accuracy of cross prediction?","heading":"14 Accuracy of cross prediction?","text":"Context Purpose:Context Purpose:Upstream: Section @ref() -Upstream: Section @ref() -Downstream:Downstream:Inputs:Inputs:Expected outputs:Expected outputs:proceeding, one note: steps may hard breeding programs, especially open-pollination used, families small, parents genotyped. case, attempt implement steps fail, despair. k-fold cross-validation accuracy (hopefully) related accuracy predicting cross-variances. Therefore, steps 100% necessary implementing mate selection. Furthermore, mate selection can done simply basis predicted family-means, whose prediction accuracy definitely forecast based k-fold cross-validation accuracy. Predicting usefulness crosses (remember \\(\\hat{UC} = \\hat{\\mu} + \\times \\hat{\\sigma}\\)) requires prediction cross-variance (\\(\\hat{\\sigma}\\) part), requires accurate phasing information non-inbred lines.","code":""},{"path":"parentwise_cross_val.html","id":"pedigree","chapter":"14 Accuracy of cross prediction?","heading":"14.1 Pedigree","text":"downloaded pedigree last section “download training data” chapter.","code":""},{"path":"parentwise_cross_val.html","id":"read-pedigree","chapter":"14 Accuracy of cross prediction?","heading":"14.1.1 Read pedigree","text":"Filter: Keep complete pedigree records.Number full-sib families?462 set.Summarize distribution full-sib family sizesLess 1/3 families 1 member. need >>2 members analysis.","code":"\n# read.table() throws an error, some aspect of the formatting from the database download\n## read.table(here::here(\"data\",\"pedigree.txt\"), \n##            stringsAsFactors = F, header = T)\n\n# use read_delim instead\nped<-read_delim(here::here(\"data\",\"pedigree.txt\"),delim = \"\\t\")\n#> Rows: 963 Columns: 4\n#> ── Column specification ────────────────────────────────────\n#> Delimiter: \"\\t\"\n#> chr (4): Accession, Female_Parent, Male_Parent, Cross_Type\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nped %<>% \n     dplyr::select(-Cross_Type) %>% \n     filter(!is.na(Female_Parent),\n            !is.na(Male_Parent),\n            Female_Parent!=\"?\",\n            Male_Parent!=\"?\") %>% \n     distinct\nped %>% distinct(Female_Parent,Male_Parent) %>% nrow()\n#> [1] 462\nped %>%   \n  count(Female_Parent,Male_Parent) %>% arrange(desc(n))  %>%  summary(.$n)\n#>  Female_Parent      Male_Parent              n        \n#>  Length:462         Length:462         Min.   :1.000  \n#>  Class :character   Class :character   1st Qu.:1.000  \n#>  Mode  :character   Mode  :character   Median :1.000  \n#>                                        Mean   :1.294  \n#>                                        3rd Qu.:1.000  \n#>                                        Max.   :7.000"},{"path":"parentwise_cross_val.html","id":"fully-genotyped-trios","chapter":"14 Accuracy of cross prediction?","heading":"14.1.2 Fully genotyped trios?","text":"parent-wise cross-validation, need pedigree entrees 2 parents accession genotyped dataset. don’t need necessarily phenotyped though.entrees genotyped?Yes. pretty much assured way set-download originally.guarantee parents though…Indeed, portions parents present SNP data.leaves us small set complete trios (accession + male parent + female parent).Looks like 104 full-sib families.many families >1 offspring?end, small example dataset 18 families >1 offspring.Remember : (1) small, example dataset, (2) goal estimate accuracy predicting genetic-variance family.reference sake: previous analysis IITA’s large training population, ~6200 entries pedigree, 196 full-sib families >=10 members, average family size ~5.unlikely sufficient good estimate, ’s possible won’t even work analysis, try!","code":"\ndosages<-readRDS(here::here(\"data\",\"dosages.rds\"))\ngenotyped_gids<-rownames(dosages)\nall(ped$Accession %in% genotyped_gids)\n#> [1] TRUE\nall(ped$Female_Parent %in% genotyped_gids)\n#> [1] FALSE\ntable(ped$Female_Parent %in% genotyped_gids)\n#> \n#> FALSE  TRUE \n#>   367   231\ntable(ped$Male_Parent %in% genotyped_gids)\n#> \n#> FALSE  TRUE \n#>   333   265\ngenotyped_ped<-ped %>% \n     filter(Accession %in% genotyped_gids,\n            Female_Parent %in% genotyped_gids,\n            Male_Parent %in% genotyped_gids)\ngenotyped_ped %>% nrow()\n#> [1] 135\ngenotyped_ped %>% \n     count(Female_Parent,Male_Parent) %>% arrange(desc(n))  %>%  summary(.$n)\n#>  Female_Parent      Male_Parent              n        \n#>  Length:104         Length:104         Min.   :1.000  \n#>  Class :character   Class :character   1st Qu.:1.000  \n#>  Mode  :character   Mode  :character   Median :1.000  \n#>                                        Mean   :1.298  \n#>                                        3rd Qu.:1.000  \n#>                                        Max.   :7.000\ngenotyped_ped %>% \n     count(Female_Parent,Male_Parent) %>% \n     filter(n>1)\n#> # A tibble: 18 × 3\n#>    Female_Parent        Male_Parent             n\n#>    <chr>                <chr>               <int>\n#>  1 IITA-TMS-IBA011371   IITA-TMS-IBA011371      4\n#>  2 IITA-TMS-IBA020431   IITA-TMS-IBA030055A     2\n#>  3 IITA-TMS-IBA030060   IITA-TMS-IBA010903      2\n#>  4 IITA-TMS-IBA030060   IITA-TMS-MM970043       3\n#>  5 IITA-TMS-IBA30555    TMEB1                   2\n#>  6 IITA-TMS-IBA4(2)1425 TMEB1                   2\n#>  7 IITA-TMS-IBA8902195  IITA-TMS-IBA950379      2\n#>  8 IITA-TMS-IBA9001554  IITA-TMS-IBA011659      2\n#>  9 IITA-TMS-IBA91934    TMEB1                   7\n#> 10 IITA-TMS-IBA940330   IITA-TMS-IBA011224      3\n#> 11 IITA-TMS-IBA961089A  IITA-TMS-IBA961089A     2\n#> 12 IITA-TMS-IBA961632   IITA-TMS-IBA000070      2\n#> 13 IITA-TMS-IBA961632   IITA-TMS-IBA030055A     3\n#> 14 IITA-TMS-IBA972205   TMEB1937                5\n#> 15 IITA-TMS-ZAR930151   IITA-TMS-MM970043       2\n#> 16 TMS13F1307P0004      TMS13F1343P0044         2\n#> 17 TMS14F1016P0006      TMS14F1035P0004         2\n#> 18 TMS14F1255P0005      TMS13F1343P0044         2"},{"path":"parentwise_cross_val.html","id":"verify-pedigree-relationships","chapter":"14 Accuracy of cross prediction?","heading":"14.2 Verify pedigree relationships","text":"one additional step highly recommend demonstrate .Plant breeding pedigrees can often errors, esp. male (pollen) parent. reason, recommend using genomic data check pedigree. want estimate family-genetic variance prediction accuracy detrimated presence incorrect pedigree entrees.various software options , probably R package two.approach uses --genome IBD calculator command-line program PLINK v1.9, click PLINK1.9 manual download/install program.See example implementation done 2021 : https://wolfemd.github.io/IITA_2021GS/03-validatePedigree.htmlPLINK1.9 pipeline use:Convert VCF file binary plink formatConvert VCF file binary plink formatFor full dataset / “official anlaysis”:\n2a: Subset whole-pop. binary plink files lines pedigree.\n2b: LD-prune --indep-pairwise 100 25 0.25 stringent, somewhat arbitrary\nSkip step example dataset: population small already randomly sampled small number markers make compute faster example meaning LD probably low.\nfull dataset / “official anlaysis”:2a: Subset whole-pop. binary plink files lines pedigree.2b: LD-prune --indep-pairwise 100 25 0.25 stringent, somewhat arbitrarySkip step example dataset: population small already randomly sampled small number markers make compute faster example meaning LD probably low.Compute IBD-relationships --genomeCompute IBD-relationships --genomeParent-offspring relationships determination (see )Parent-offspring relationships determination (see )Determine parent-offspring relationship status based plink IBD:kinship \\(\\hat{\\pi} \\approx 0.5\\).kinship \\(\\hat{\\pi} \\approx 0.5\\).Three standard IBD probabilities defined pair; probability sharing zero (Z0), one (Z1) two (Z2) alleles randomly chosen locus IBD.Three standard IBD probabilities defined pair; probability sharing zero (Z0), one (Z1) two (Z2) alleles randomly chosen locus IBD.expectation siblings terms probabilities Z0=0.25, Z1=0.5 Z2=0.25.expectation siblings terms probabilities Z0=0.25, Z1=0.5 Z2=0.25.expectation parent-offspring pairs Z0=0, Z1=1 Z2=0.expectation parent-offspring pairs Z0=0, Z1=1 Z2=0.Based work 2016 (never published), declare parent-offspring pair : Z0<0.313 Z1>0.668.Based work 2016 (never published), declare parent-offspring pair : Z0<0.313 Z1>0.668.","code":""},{"path":"parentwise_cross_val.html","id":"process-map-6","chapter":"14 Accuracy of cross prediction?","heading":"14.2.1 Process Map","text":"","code":""},{"path":"parentwise_cross_val.html","id":"install-plink1.9-mac","chapter":"14 Accuracy of cross prediction?","heading":"14.2.2 Install plink1.9 (Mac)","text":"results vary. got installed mac laptop.Downloaded ~/Downloads/ folder unzipped (double-click .zip file)terminal: cd ~/Downloads/plink_mac_20220305Move binary file (plink) command-line path: cp ~/Downloads/plink_mac_20220305/plink /usr/local/bin/Now typing plink command line always engage programHowever, convince MacOS safe following instruction: https://zaiste.net/os/macos/howtos/resolve-macos---opened---developer---verified-error/","code":""},{"path":"parentwise_cross_val.html","id":"make-binary-plink-from-vcf","chapter":"14 Accuracy of cross prediction?","heading":"14.2.3 Make binary plink from VCF","text":"","code":"# in the terminal change directory\n# go to the data/ directory where the VCF file is located\nplink --vcf BreedBaseGenotypes_subset.vcf.gz \\\n     --make-bed --const-fid --keep-allele-order \\\n     --out BreedBaseGenotypes_subset"},{"path":"parentwise_cross_val.html","id":"run-plink-ibd","chapter":"14 Accuracy of cross prediction?","heading":"14.2.4 Run plink IBD","text":"creates output file extension *.genome output directory. 963 individual dataset, file size 60M… beware, get huge many samples.See plink1.9 manual : https://www.cog-genomics.org/plink/1.9/ibd details output means.","code":"plink --bfile BreedBaseGenotypes_subset \\\n  --genome \\\n  --out ../output/BreedBaseGenotypes_subset;"},{"path":"parentwise_cross_val.html","id":"verify-parent-offspring-relationships","chapter":"14 Accuracy of cross prediction?","heading":"14.2.5 Verify parent-offspring relationships","text":", well supported pedigree relationships according approach?78% Accessions parents correct.7% female male correct.4% male female","code":"\ngenome<-read.table(here::here(\"output/\",\"BreedBaseGenotypes_subset.genome\"),\n                   stringsAsFactors = F,header = T) %>% \n     as_tibble\ngenome %>% head\n#> # A tibble: 6 × 14\n#>    FID1 IID1     FID2 IID2    RT       EZ    Z0     Z1    Z2\n#>   <int> <chr>   <int> <chr>   <chr> <int> <dbl>  <dbl> <dbl>\n#> 1     0 IITA-T…     0 IITA-T… OT        0 0.616 0.384  0    \n#> 2     0 IITA-T…     0 IITA-T… OT        0 0.663 0.337  0    \n#> 3     0 IITA-T…     0 IITA-T… OT        0 0.607 0.283  0.110\n#> 4     0 IITA-T…     0 IITA-T… OT        0 0     0.0612 0.939\n#> 5     0 IITA-T…     0 IITA-T… OT        0 0     0.0526 0.947\n#> 6     0 IITA-T…     0 IITA-T… OT        0 0     1      0    \n#> # … with 5 more variables: PI_HAT <dbl>, PHE <int>,\n#> #   DST <dbl>, PPC <dbl>, RATIO <dbl>\ndim(genome)\n#> [1] 463203     14\nped %>% \n     semi_join(genome %>% rename(Accession=IID1,Female_Parent=IID2)) %>% \n     left_join(genome %>% rename(Accession=IID1,Female_Parent=IID2))\n#> Joining, by = c(\"Accession\", \"Female_Parent\")\n#> Joining, by = c(\"Accession\", \"Female_Parent\")\n#> # A tibble: 4 × 15\n#>   Accession   Female_Parent   Male_Parent   FID1  FID2 RT   \n#>   <chr>       <chr>           <chr>        <int> <int> <chr>\n#> 1 IITA-TMS-B… TMEB1           IITA-TMS-IB…     0     0 OT   \n#> 2 IITA-TMS-I… IITA-TMS-IBA90… IITA-TMS-IB…     0     0 OT   \n#> 3 IITA-TMS-I… TMEB1           IITA-TMS-IB…     0     0 OT   \n#> 4 IITA-TMS-I… IITA-TMS-IBA91… IITA-TMS-IB…     0     0 OT   \n#> # … with 9 more variables: EZ <int>, Z0 <dbl>, Z1 <dbl>,\n#> #   Z2 <dbl>, PI_HAT <dbl>, PHE <int>, DST <dbl>,\n#> #   PPC <dbl>, RATIO <dbl>\n# Confirm Female_Parent - Offspring Relationship\n## In the plink genome file\n## IID1 or IID2 could be the Accession or the Female_Parent\nconf_female_ped<-genotyped_ped %>% \n     inner_join(genome %>% \n                     rename(Accession=IID1,Female_Parent=IID2)) %>% \n     bind_rows(genotyped_ped %>% \n                    inner_join(genome %>% \n                                    rename(Accession=IID2,Female_Parent=IID1))) %>% \n     # Declare confirm-reject Accession-Female_Parent\n     mutate(ConfirmFemaleParent=case_when(Z0<0.32 & Z1>0.67~\"Confirm\", \n                                          # Relatedness coeff differ if the Accession is the result of a self-cross\n                                          Male_Parent==Female_Parent & PI_HAT>0.6 & Z0<0.3 & Z2>0.32~\"Confirm\",\n                                          TRUE~\"Reject\")) %>% \n     dplyr::select(Accession,Female_Parent,ConfirmFemaleParent)\n#> Joining, by = c(\"Accession\", \"Female_Parent\")\n#> Joining, by = c(\"Accession\", \"Female_Parent\")\n## Now do the same for the Accession-Male_Parent relationships\nconf_male_ped<-genotyped_ped %>% \n     inner_join(genome %>% \n                     rename(Accession=IID1,Male_Parent=IID2)) %>% \n     bind_rows(genotyped_ped %>% \n                    inner_join(genome %>% \n                                    rename(Accession=IID2,Male_Parent=IID1))) %>% \n     # Declare confirm-reject Accession-Female_Parent\n     mutate(ConfirmMaleParent=case_when(Z0<0.32 & Z1>0.67~\"Confirm\", \n                                          # Relatedness coeff differ if the Accession is the result of a self-cross\n                                          Male_Parent==Female_Parent & PI_HAT>0.6 & Z0<0.3 & Z2>0.32~\"Confirm\",\n                                          TRUE~\"Reject\")) %>% \n     dplyr::select(Accession,Male_Parent,ConfirmMaleParent)\n#> Joining, by = c(\"Accession\", \"Male_Parent\")\n#> Joining, by = c(\"Accession\", \"Male_Parent\")\n# Now join the confirmed female and male relationships\n# This regenerates the original \"genotyped_ped\" with two added columns\nconfirmed_ped<-conf_female_ped %>% \n     left_join(conf_male_ped) %>% \n     relocate(Male_Parent,.before = \"ConfirmFemaleParent\")\n#> Joining, by = \"Accession\"\nconfirmed_ped %>% \n     count(ConfirmFemaleParent,ConfirmMaleParent) %>% \n     mutate(Prop=round(n/sum(n),2))\n#> # A tibble: 4 × 4\n#>   ConfirmFemaleParent ConfirmMaleParent     n  Prop\n#>   <chr>               <chr>             <int> <dbl>\n#> 1 Confirm             Confirm             105  0.78\n#> 2 Confirm             Reject               10  0.07\n#> 3 Reject              Confirm               5  0.04\n#> 4 Reject              Reject               15  0.11"},{"path":"parentwise_cross_val.html","id":"subset-to-fully-validated-trios","chapter":"14 Accuracy of cross prediction?","heading":"14.2.6 Subset to fully-validated trios","text":"can run cross-validation using pedigree full trio (Accession’s relationship parents) validated.Remove without parents confirmed.Leaves us 105 validated entries pedigreeLuckily, 16 18 full-sib families >1 entry still .Though 5 families 2…","code":"\nvalid_ped<-confirmed_ped %>% \n     filter(ConfirmFemaleParent==\"Confirm\",\n         ConfirmMaleParent==\"Confirm\") %>% \n     dplyr::select(-contains(\"Confirm\"))\nvalid_ped %>% nrow()\n#> [1] 105\nvalid_ped %>% \n     count(Female_Parent,Male_Parent) %>% \n     filter(n>1)\n#> # A tibble: 16 × 3\n#>    Female_Parent        Male_Parent             n\n#>    <chr>                <chr>               <int>\n#>  1 IITA-TMS-IBA011371   IITA-TMS-IBA011371      4\n#>  2 IITA-TMS-IBA020431   IITA-TMS-IBA030055A     2\n#>  3 IITA-TMS-IBA030060   IITA-TMS-IBA010903      2\n#>  4 IITA-TMS-IBA030060   IITA-TMS-MM970043       3\n#>  5 IITA-TMS-IBA4(2)1425 TMEB1                   2\n#>  6 IITA-TMS-IBA8902195  IITA-TMS-IBA950379      2\n#>  7 IITA-TMS-IBA9001554  IITA-TMS-IBA011659      2\n#>  8 IITA-TMS-IBA91934    TMEB1                   6\n#>  9 IITA-TMS-IBA961089A  IITA-TMS-IBA961089A     2\n#> 10 IITA-TMS-IBA961632   IITA-TMS-IBA000070      2\n#> 11 IITA-TMS-IBA961632   IITA-TMS-IBA030055A     3\n#> 12 IITA-TMS-IBA972205   TMEB1937                5\n#> 13 IITA-TMS-ZAR930151   IITA-TMS-MM970043       2\n#> 14 TMS13F1307P0004      TMS13F1343P0044         2\n#> 15 TMS14F1016P0006      TMS14F1035P0004         2\n#> 16 TMS14F1255P0005      TMS13F1343P0044         2\nvalid_ped %>% \n     count(Female_Parent,Male_Parent) %>% \n     filter(n>2)\n#> # A tibble: 5 × 3\n#>   Female_Parent      Male_Parent             n\n#>   <chr>              <chr>               <int>\n#> 1 IITA-TMS-IBA011371 IITA-TMS-IBA011371      4\n#> 2 IITA-TMS-IBA030060 IITA-TMS-MM970043       3\n#> 3 IITA-TMS-IBA91934  TMEB1                   6\n#> 4 IITA-TMS-IBA961632 IITA-TMS-IBA030055A     3\n#> 5 IITA-TMS-IBA972205 TMEB1937                5"},{"path":"parentwise_cross_val.html","id":"write-validated-pedigree","chapter":"14 Accuracy of cross prediction?","heading":"14.2.7 Write validated pedigree","text":"","code":"\nsaveRDS(valid_ped,here::here(\"output\",\"verified_ped.rds\"))"},{"path":"parentwise_cross_val.html","id":"parent-wise-cross-validation-1","chapter":"14 Accuracy of cross prediction?","heading":"14.3 Parent-wise cross-validation","text":"Refer following:genomicMateSelectR::runParentWiseCrossVal() documentationExample IITA_2021GS Cross-validation","code":""},{"path":"parentwise_cross_val.html","id":"process-map-7","chapter":"14 Accuracy of cross prediction?","heading":"14.3.1 Process Map","text":"","code":""},{"path":"parentwise_cross_val.html","id":"load-inputs-and-set-up","chapter":"14 Accuracy of cross prediction?","heading":"14.3.2 Load inputs and set-up","text":"genotype data processing stage, specifically one last steps, created recombination frequency matrix. , accessed genetic map, interpolated markers dataset used helper functions provided genomicMateSelectR. finally need matrix.","code":"\n# Load verified ped\nped<-readRDS(here::here(\"output\",\"verified_ped.rds\")) %>% \n     # Rename things to match genomicMateSelectR::runParentWiseCrossVal()\n     rename(GID=Accession,\n            sireID=Male_Parent,\n            damID=Female_Parent)\n# Keep only families with _at least_ 2 offspring\nped %<>% \n     semi_join(ped %>% count(sireID,damID) %>% filter(n>1) %>% ungroup())\n\n# GENOMIC RELATIONSHIP MATRIX\ngrms<-list(A=readRDS(file=here::here(\"output\",\"kinship_add.rds\")))\n\n# BLUPs\nblups<-readRDS(here::here(\"output\",\"blups.rds\")) %>% \n     # based on cross-validation, decided to exclude MCMDS from this analysis\n     filter(Trait != \"MCMDS\") %>% \n     # need to rename the \"blups\" list to comply with the runCrossVal function\n     rename(TrainingData=blups) %>% \n     dplyr::select(Trait,TrainingData) %>% \n     # need also to remove phenotyped-but-not-genotyped lines\n     mutate(TrainingData=map(TrainingData,\n                             ~filter(.,germplasmName %in% rownames(grms$A)) %>% \n                                  # rename the germplasmName column to GID\n                                  rename(GID=germplasmName))) %>% \n     # It seems actually that runParentWiseCrossVal() wnats this column named \"blups\"\n     rename(blups=TrainingData)\n\n# DOSAGE MATRIX\n## Dosages are also needed inside the runParentWiseCrossVal() function\n## Reason is that they are used to extra SNP effects from GBLUP models\ndosages<-readRDS(here::here(\"data\",\"dosages.rds\"))\n\n# HAPLOTYPE MATRIX\n## keep only haplos for parents-in-the-pedigree\n## those which will be used in prediction, saves memory\nhaploMat<-readRDS(file=here::here(\"data\",\"haplotypes.rds\"))\nparents<-union(ped$sireID,ped$damID) \nparenthaps<-sort(c(paste0(parents,\"_HapA\"),\n                   paste0(parents,\"_HapB\")))\nhaploMat<-haploMat[parenthaps,]\n\n# SELECTION INDEX\nSIwts<-c(DM=15,\n         logFYLD=20,\n         logDYLD=20)\n# RECOMBINATION FREQUENCY MATRIX\nrecombFreqMat<-readRDS(file=here::here(\"output\",\"recombFreqMat_1minus2c.rds\"))"},{"path":"parentwise_cross_val.html","id":"run-cross-validation","chapter":"14 Accuracy of cross prediction?","heading":"14.3.3 Run cross-validation","text":"Took 3.5 minutes using 10 cores 16 core - 64 GB RAM machine. Memory usagage wasn’t bad.","code":"\nstarttime<-proc.time()[3]\nparentWiseCV<-runParentWiseCrossVal(nrepeats=2,nfolds=5,seed=121212,\n                                    modelType=\"A\",\n                                    ncores=10,\n                                    ped=ped,\n                                    blups=blups,\n                                    dosages=dosages,\n                                    haploMat=haploMat,\n                                    grms=grms,\n                                    recombFreqMat = recombFreqMat,\n                                    selInd = TRUE, SIwts = SIwts)\nelapsed<-proc.time()[3]-starttime; elapsed/60"},{"path":"parentwise_cross_val.html","id":"save-results","chapter":"14 Accuracy of cross prediction?","heading":"14.3.4 Save results","text":"","code":"\nsaveRDS(parentWiseCV,file = here::here(\"output\",\"parentWiseCV.rds\"))"},{"path":"parentwise_cross_val.html","id":"plot-results-1","chapter":"14 Accuracy of cross prediction?","heading":"14.3.5 Plot results","text":"find output runParentWiseCrossVal list two elements: “meanPredAccuracy” “varPredAccuracy”Take peak see ’s formatted:Obviously good result, must tiny dataset training prediction models (get marker effects) terms small number family-members small number families available.Surprising variance accuracy actually appears much better mean accuracy… definitely take equal skepticism result mean, reasons!","code":"\nparentWiseCV<-readRDS(here::here(\"output\",\"parentWiseCV.rds\"))\nparentWiseCV$meanPredAccuracy %>% head\n#> # A tibble: 6 × 7\n#>   Repeat  Fold  modelType predOf Trait predVSobs AccuracyEst\n#>   <chr>   <chr> <chr>     <chr>  <chr> <list>          <dbl>\n#> 1 Repeat1 Fold1 A         MeanBV SELI… <tibble …      -0.229\n#> 2 Repeat1 Fold1 A         MeanBV DM    <tibble …      -0.385\n#> 3 Repeat1 Fold1 A         MeanBV logD… <tibble …     NaN    \n#> 4 Repeat1 Fold1 A         MeanBV logF… <tibble …      -0.771\n#> 5 Repeat1 Fold2 A         MeanBV SELI… <tibble …     NaN    \n#> 6 Repeat1 Fold2 A         MeanBV DM    <tibble …     NaN\nparentWiseCV$varPredAccuracy %>% head\n#> # A tibble: 6 × 8\n#>   Repeat  Fold  modelType predOf Trait1  Trait2  predVSobs  \n#>   <chr>   <chr> <chr>     <chr>  <chr>   <chr>   <list>     \n#> 1 Repeat1 Fold1 A         VarBV  SELIND  SELIND  <tibble [6…\n#> 2 Repeat1 Fold1 A         VarBV  DM      DM      <tibble [6…\n#> 3 Repeat1 Fold1 A         VarBV  DM      logDYLD <tibble [6…\n#> 4 Repeat1 Fold1 A         VarBV  DM      logFYLD <tibble [6…\n#> 5 Repeat1 Fold1 A         VarBV  logDYLD logDYLD <tibble [6…\n#> 6 Repeat1 Fold1 A         VarBV  logDYLD logFYLD <tibble [6…\n#> # … with 1 more variable: AccuracyEst <dbl>\nparentWiseCV$meanPredAccuracy %>% \n     ggplot(.,aes(x=Trait,y=AccuracyEst,fill=Trait)) + geom_boxplot() + \n     labs(title=\"Accuracy Predicting Family Means\")\n#> Warning: Removed 29 rows containing non-finite values\n#> (stat_boxplot).\nparentWiseCV$varPredAccuracy %>% \n     # this will format the two column information \n     # indicating variances and covariances\n     # into a single variable for the plot\n     mutate(VarParam=paste0(Trait1,\"\\n\",Trait2)) %>% \n     ggplot(.,aes(x=VarParam,y=AccuracyEst,fill=VarParam)) + geom_boxplot()\n#> Warning: Removed 57 rows containing non-finite values\n#> (stat_boxplot)."},{"path":"predict-crosses.html","id":"predict-crosses","chapter":"15 Predict crosses","heading":"15 Predict crosses","text":"Context Purpose:Context Purpose:Upstream: Section @ref() -Upstream: Section @ref() -Downstream:Downstream:Inputs:Inputs:Expected outputs:Expected outputs:finally (almost) ready predict performance potential crosses. inputs set-.","code":""},{"path":"predict-crosses.html","id":"process-map-8","chapter":"15 Predict crosses","heading":"15.1 Process Map","text":"","code":""},{"path":"predict-crosses.html","id":"load-inputs-and-set-up-1","chapter":"15 Predict crosses","heading":"15.2 Load inputs and set-up","text":"Much section parent-wise cross-validation.","code":"\n# GENOMIC RELATIONSHIP MATRIX\ngrms<-list(A=readRDS(file=here::here(\"output\",\"kinship_add.rds\")))\n\n# BLUPs\nblups<-readRDS(here::here(\"output\",\"blups.rds\")) %>% \n     # based on cross-validation, decided to exclude MCMDS from this analysis\n     filter(Trait != \"MCMDS\") %>% \n     # need to rename the \"blups\" list to comply with the runCrossVal function\n     rename(TrainingData=blups) %>% \n     dplyr::select(Trait,TrainingData) %>% \n     # need also to remove phenotyped-but-not-genotyped lines\n     mutate(TrainingData=map(TrainingData,\n                             ~filter(.,germplasmName %in% rownames(grms$A)) %>% \n                                  # rename the germplasmName column to GID\n                                  rename(GID=germplasmName)))\n\n# DOSAGE MATRIX\n## Dosages are also needed for runGenomicPredictions() when getMarkEffs=TRUE\n## Reason is that they are used to extra SNP effects from GBLUP models\ndosages<-readRDS(here::here(\"data\",\"dosages.rds\"))\n\n# SELECTION INDEX\nSIwts<-c(DM=15,\n         logFYLD=20,\n         logDYLD=20)"},{"path":"predict-crosses.html","id":"get-marker-effects","chapter":"15 Predict crosses","heading":"15.3 Get marker effects","text":"First, chapter predicted GEBV, used runGenomicPredictions() function, implements GBLUP model, predict GEBV.need re-run runGenomicPredictions(), time using getMarkEffs=TRUE option, “backsolve” RR-BLUP marker effect solutions GBLUP solutions, using backsolveSNPeff() function --hood.Refer runGenomicPredictions() documentation section vignette details.output SNP-effects formatted ready input predictCrosses() function.Save resultsNotice now additional list-type column label “allelesubsnpeff” indicating , ran additive-model, SNP-effects represent predictions allele substitution effects.Just show, single column matrix rownames labelling marker.","code":"\ngpreds_withMarkEffs<-runGenomicPredictions(modelType = \"A\", \n                                           selInd = T, SIwts = SIwts,\n                                           getMarkEffs = TRUE,\n                                           dosages = dosages,\n                                           blups = blups, \n                                           grms = grms,\n                                           ncores=3)\nsaveRDS(gpreds_withMarkEffs,file = here::here(\"output\",\"genomicPredictions_withMarkEffs.rds\"))\ngpreds_withMarkEffs<-readRDS(here::here(\"output\",\"genomicPredictions_withMarkEffs.rds\"))\ngpreds_withMarkEffs$genomicPredOut[[1]]\n#> # A tibble: 3 × 5\n#>   Trait   gblups       varcomps   fixeffs    allelesubsnpeff\n#>   <chr>   <list>       <list>     <list>     <list>         \n#> 1 DM      <tibble [96… <df [2 × … <df [1 × … <dbl [3,986 × …\n#> 2 logFYLD <tibble [96… <df [2 × … <df [1 × … <dbl [3,986 × …\n#> 3 logDYLD <tibble [96… <df [2 × … <df [1 × … <dbl [3,986 × …\ngpreds_withMarkEffs$genomicPredOut[[1]]$allelesubsnpeff[[1]][1:5,]\n#>  1_652699_G_C  1_868970_G_T  1_943129_T_A 1_1132830_A_T \n#> -0.0019610837 -0.0016106918 -0.0008841766 -0.0017600501 \n#> 1_1310706_A_T \n#> -0.0012963110"},{"path":"predict-crosses.html","id":"crosses-to-predict","chapter":"15 Predict crosses","heading":"15.4 Crosses-to-predict","text":"predictCrosses() function also need data.frame indicating pairs parents want predict crosses .convenience, can use crosses2predict() function make data.frame vector genotype ID’s.realistic approach, choose set parents based GEBV, ’d actually like actually make crosses .still somewhat computationally intensive predict variances covariances traits cross, can’t quite predict possible pairwise crosses… definitely laptops example., example, picking top 10 candidate parents:55 crosses top 10 parents make predictions .","code":"\n# Access the predicted GEBV\ntop10parents<-gpreds_withMarkEffs$gblups[[1]] %>% \n     # Arrange in descending order based on the SELIND\n     arrange(desc(SELIND)) %>% \n     # I'll pick the top 10 parents\n     slice(1:10) %$%\n     # And extract their GID to a vector\n     GID\nCrossesToPredict<-crosses2predict(top10parents)\nCrossesToPredict %>% head\n#> # A tibble: 6 × 2\n#>   sireID          damID          \n#>   <chr>           <chr>          \n#> 1 TMS13F1307P0008 TMS13F1307P0008\n#> 2 TMS13F1307P0008 TMS14F1035P0004\n#> 3 TMS13F1307P0008 TMS14F1262P0002\n#> 4 TMS13F1307P0008 TMS19F1091P0065\n#> 5 TMS13F1307P0008 TMS14F1303P0012\n#> 6 TMS13F1307P0008 TMS14F1312P0003\nCrossesToPredict %>% nrow()\n#> [1] 55"},{"path":"predict-crosses.html","id":"run-predictcrosses","chapter":"15 Predict crosses","heading":"15.5 Run predictCrosses()","text":"Additional inputs need: “haplotype matrix” “recombination frequency matrix.”Let’s go!","code":"\n# HAPLOTYPE MATRIX\n## keep only haplos for candidate parents we want to predict crosses for\n## those which will be used in prediction, saves memory\nhaploMat<-readRDS(file=here::here(\"data\",\"haplotypes.rds\"))\nparenthaps<-sort(c(paste0(top10parents,\"_HapA\"),\n                   paste0(top10parents,\"_HapB\")))\nhaploMat<-haploMat[parenthaps,]\n\n# RECOMBINATION FREQUENCY MATRIX\nrecombFreqMat<-readRDS(file=here::here(\"output\",\"recombFreqMat_1minus2c.rds\"))\nstarttime<-proc.time()[3]\ncrossPreds<-predictCrosses(modelType=\"A\",\n                           selInd = T, SIwts = SIwts,\n                           CrossesToPredict=CrossesToPredict,\n                           snpeffs=gpreds_withMarkEffs$genomicPredOut[[1]], \n                           haploMat=haploMat,\n                           dosages = dosages[top10parents,],\n                           recombFreqMat=recombFreqMat,\n                           ncores=10)\nelapsed<-proc.time()[3]-starttime; elapsed/60"},{"path":"predict-crosses.html","id":"save-results-1","chapter":"15 Predict crosses","heading":"15.5.1 Save results","text":"","code":"\nsaveRDS(crossPreds,file = here::here(\"output\",\"predictedCrosses.rds\"))"},{"path":"predict-crosses.html","id":"select-crosses-to-make","chapter":"15 Predict crosses","heading":"15.6 Select crosses to make","text":"Output predictCrosses() tibble. Two columns, 1 row. Column 1 (tidyPreds) cleaned-“tidy” predictions. Column 2 (rawPreds) detailed output.Remember “usefulness” (predUsefulness) , UC short, equal prediction expected mean top fraction progeny cross \\(\\hat{UC} = \\hat{\\mu} + \\times \\hat{\\sigma}\\). also called “superior progeny mean” literature. Actually, user option modify expected, standardized selection intensity (\\(\\boldsymbol{}\\)) either advance stdSelInt= argument predictCrosses() --fact; default value 2.67, corresponding selecting top 1% offspring cross making.let’s say want make top 10 55 predicted crosses:thus crossing plan! Congratulations!","code":"\ncrossPreds<-readRDS(here::here(\"output\",\"predictedCrosses.rds\"))\ncrossPreds\n#> # A tibble: 1 × 2\n#>   tidyPreds          rawPreds        \n#>   <list>             <list>          \n#> 1 <tibble [220 × 9]> <named list [2]>\ncrossPreds$tidyPreds[[1]] %>% str\n#> tibble [220 × 9] (S3: tbl_df/tbl/data.frame)\n#>  $ sireID        : chr [1:220] \"TMS13F1307P0008\" \"TMS13F1307P0008\" \"TMS13F1307P0008\" \"TMS13F1307P0008\" ...\n#>  $ damID         : chr [1:220] \"TMS13F1307P0008\" \"TMS13F1307P0008\" \"TMS13F1307P0008\" \"TMS13F1307P0008\" ...\n#>  $ Nsegsnps      : int [1:220] 1281 1281 1281 1281 2048 2048 2048 2048 1762 1762 ...\n#>  $ predOf        : chr [1:220] \"BV\" \"BV\" \"BV\" \"BV\" ...\n#>  $ Trait         : chr [1:220] \"SELIND\" \"DM\" \"logFYLD\" \"logDYLD\" ...\n#>  $ predMean      : num [1:220] 16.48943 1.04623 -0.00208 0.04188 16.39717 ...\n#>  $ predVar       : num [1:220] 6.732467 0.025773 0.000276 0.000279 8.111941 ...\n#>  $ predSD        : num [1:220] 2.5947 0.1605 0.0166 0.0167 2.8481 ...\n#>  $ predUsefulness: num [1:220] 23.4173 1.4749 0.0423 0.0864 24.0017 ...\ntop10crosses<-crossPreds$tidyPreds[[1]] %>% \n     filter(Trait==\"SELIND\") %>% \n     dplyr::select(-predVar) %>% \n     arrange(desc(predUsefulness)) %>% \n     slice(1:10)\ntop10crosses\n#> # A tibble: 10 × 8\n#>    sireID     damID    Nsegsnps predOf Trait predMean predSD\n#>    <chr>      <chr>       <int> <chr>  <chr>    <dbl>  <dbl>\n#>  1 TMS14F103… TMS14F1…     1429 BV     SELI…     16.3   3.08\n#>  2 TMS13F130… TMS14F1…     2048 BV     SELI…     16.4   2.85\n#>  3 TMS13F130… TMS13F1…     1281 BV     SELI…     16.5   2.59\n#>  4 TMS14F103… TMS14F1…     2099 BV     SELI…     15.2   2.87\n#>  5 TMS13F130… TMS14F1…     1762 BV     SELI…     15.3   2.62\n#>  6 TMS14F103… TMS19F1…     2013 BV     SELI…     14.3   2.86\n#>  7 TMS14F103… TMS14F1…     2260 BV     SELI…     14.2   2.83\n#>  8 TMS13F130… TMS19F1…     1934 BV     SELI…     14.4   2.60\n#>  9 TMS13F130… TMS14F1…     2136 BV     SELI…     14.3   2.57\n#> 10 TMS14F126… TMS14F1…     1118 BV     SELI…     14.1   2.65\n#> # … with 1 more variable: predUsefulness <dbl>"},{"path":"predict-crosses.html","id":"non-additive-effects-models","chapter":"15 Predict crosses","heading":"15.7 Non-additive effects models","text":"Links information models provided previous section introducing genomic mate selection.vignette genomicMateSelectR entitled “Genomic prediction non-additive effects”provides complete tutorial execute models predicting cross-performance .","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""},{"path":"workflowr-example.html","id":"workflowr-example","chapter":"16 WorkflowR example","heading":"16 WorkflowR example","text":"example open index.Rmd file using wflow_open functionAt file can update title index page, start writing main objectives repository. Like:’s great, still PCA.html file, let’s create wflow_open function.create PCA.Rmd file, looking now.can update name replacing abbreviation Principal Components Analysis, add new intro analysis going R markdown file.PCA.Rmd make Principal components analysis famous iris data Ronald Fisher. fell free start R markdown file.","code":"\nwflow_open(\"analysis/index.Rmd\")This repository was created to assist my learning experience with Git Hub and workflowr.\n\nMy first R code at this project will be at this [git hub page](PCA.html)\nwflow_open(\"analysis/PCA.Rmd\")"},{"path":"workflowr-example.html","id":"principal-components-analysis-with-iris-data","chapter":"16 WorkflowR example","heading":"16.1 Principal Components analysis with Iris data","text":"","code":""},{"path":"workflowr-example.html","id":"collecting-data","chapter":"16 WorkflowR example","heading":"16.1.1 Collecting data","text":"","code":"\ndata <- iris"},{"path":"workflowr-example.html","id":"preparing-data-for-the-principal-components-analysis-pca","chapter":"16 WorkflowR example","heading":"16.2 Preparing data for the principal components analysis (PCA)","text":"let’s prepare prepare data plot boxplot four traits, need function melt reshape2 package tidyverse package.great, now data format make boxplot traits code line. lets keep moving. use ggplot2 package.Great data, can see lot differences Species traits.\nseems may correlation Petal Length Width. also different amplitude traits certainly results different phenotypic variance traits, need scale traits PCA.","code":"\ninstall.packages(\"reshape2\", repos = \"https://cloud.r-project.org\")\n#> \n#> The downloaded binary packages are in\n#>  /var/folders/65/v_glyd192hj9hmnr5118vy0m0000gp/T//RtmpyBASwH/downloaded_packages\nlibrary(reshape2); library(tidyverse)\n#> ── Attaching packages ─────────────────── tidyverse 1.3.1 ──\n#> ✓ ggplot2 3.3.5     ✓ purrr   0.3.4\n#> ✓ tibble  3.1.6     ✓ dplyr   1.0.7\n#> ✓ tidyr   1.1.4     ✓ stringr 1.4.0\n#> ✓ readr   2.1.1     ✓ forcats 0.5.1\n#> ── Conflicts ────────────────────── tidyverse_conflicts() ──\n#> x dplyr::filter() masks stats::filter()\n#> x dplyr::lag()    masks stats::lag()\n\ndataMelted <- data %>% reshape2::melt(data = .,\n                                      id.vars = \"Species\",\n                                      variable.name = \"trait\",\n                                      value.name = \"y\")\nhead(dataMelted)\n#>   Species        trait   y\n#> 1  setosa Sepal.Length 5.1\n#> 2  setosa Sepal.Length 4.9\n#> 3  setosa Sepal.Length 4.7\n#> 4  setosa Sepal.Length 4.6\n#> 5  setosa Sepal.Length 5.0\n#> 6  setosa Sepal.Length 5.4\ndataMelted %>% ggplot(aes(x = Species, y = y, fill = Species)) +\n     geom_boxplot() + facet_wrap(~trait, scales = \"free_y\") +\n     theme(legend.position = \"none\")\nDataSc <- data %>% select(-Species) %>%\n     scale(x = ., center = TRUE, scale = TRUE) %>%\n     as.data.frame() %>% \n     mutate(Species = data$Species)\nhead(DataSc)\n#>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n#> 1   -0.8976739  1.01560199    -1.335752   -1.311052  setosa\n#> 2   -1.1392005 -0.13153881    -1.335752   -1.311052  setosa\n#> 3   -1.3807271  0.32731751    -1.392399   -1.311052  setosa\n#> 4   -1.5014904  0.09788935    -1.279104   -1.311052  setosa\n#> 5   -1.0184372  1.24503015    -1.335752   -1.311052  setosa\n#> 6   -0.5353840  1.93331463    -1.165809   -1.048667  setosa"},{"path":"workflowr-example.html","id":"principal-component-analysis-pca","chapter":"16 WorkflowR example","heading":"16.2.1 Principal Component Analysis (PCA)","text":"let’s proceed PCA analysis, use prcomp function R status package, need call package.","code":"\nPCA <- prcomp(DataSc %>% select(-Species))"},{"path":"workflowr-example.html","id":"saving-results","chapter":"16 WorkflowR example","heading":"16.2.2 Saving results","text":"Let’s save important results objects, make graphs .1. Accumulate percent total phenotypic variance explained principal components (PC)Oh data high correlated.2. Correlations traits principal components (PC)3. Individuals scores principal components (PC)Great got need create figures.","code":"\nPerc <- 100 * PCA$sdev^2 / sum(PCA$sdev^2)\n\nPercAc <- as.vector(rep(NA, times = length(Perc)))\nfor(i in 1:length(Perc)) {\n  PercAc[i] <- sum(Perc[1:i])\n  names(PercAc)[i] <- i\n}\nnames(PercAc) <- c(\"PC1\", \"PC2\", \"PC3\", \"PC4\")\nPercAc\n#>       PC1       PC2       PC3       PC4 \n#>  72.96245  95.81321  99.48213 100.00000\nCorTraits <- PCA$rotation\nrownames(CorTraits) <- c(\"SepLen\", \"SepWid\", \"PetLen\", \"PetWid\")\nCorTraits\n#>               PC1         PC2        PC3        PC4\n#> SepLen  0.5210659 -0.37741762  0.7195664  0.2612863\n#> SepWid -0.2693474 -0.92329566 -0.2443818 -0.1235096\n#> PetLen  0.5804131 -0.02449161 -0.1421264 -0.8014492\n#> PetWid  0.5648565 -0.06694199 -0.6342727  0.5235971\n\nLabelsPCA <- CorTraits %>% as.data.frame %>%\n     mutate(PC1 = PC1 + 0.15, .keep = \"unused\")\nScoresSpecies <- PCA$x %>%\n     as.data.frame %>% \n     mutate(Species = data$Species)\n\nhead(ScoresSpecies)\n#>         PC1        PC2         PC3          PC4 Species\n#> 1 -2.257141 -0.4784238  0.12727962  0.024087508  setosa\n#> 2 -2.074013  0.6718827  0.23382552  0.102662845  setosa\n#> 3 -2.356335  0.3407664 -0.04405390  0.028282305  setosa\n#> 4 -2.291707  0.5953999 -0.09098530 -0.065735340  setosa\n#> 5 -2.381863 -0.6446757 -0.01568565 -0.035802870  setosa\n#> 6 -2.068701 -1.4842053 -0.02687825  0.006586116  setosa"},{"path":"workflowr-example.html","id":"figures","chapter":"16 WorkflowR example","heading":"16.2.3 Figures","text":"first figure barplot accumulated variances explained PC.\nuse color red PC selected use next figures.R markdown allows us hide code create figure, done adding argument echo = FALSE inside curly brackets chunk. Using echo argument print just result chunk, link .last figure scatter plot individuals score first two PCs correlation traits first two PCs.final results PC. Mostly variance explained 1˚PC due species Setosa Vs Versicolor Virginica. 2˚PC just explain variance within species. Also traits Petal Length, Petal Width Sepal Length used discriminate species.Back homeNow just commit new updates, follow steps link.","code":"\nbarplot(PercAc, main = \"Variance explained by PCA\",\n        ylab = \"Cumulative variance (%)\", xlab = \"Number of retained PCs\",\n        col = c(\"red\", \"red\", \"gray\", \"gray\", \"gray\"))\nggplot(data = ScoresSpecies, aes(x = PC1, y = PC2, color = Species)) +\n  geom_point() + geom_rug(alpha = 0.2, size = 1.5) +\n  geom_segment(mapping = aes(x = 0, xend = 3*PC1, y = 0, yend = 3*PC2),\n               colour = \"red\",\n               data = CorTraits %>% as.data.frame,\n               arrow = arrow(type = \"closed\",\n                             length = unit(0.2,units = \"cm\"))) +\n  geom_text(mapping = aes(x = PC1*3, y = PC2*3, label = rownames(LabelsPCA)),\n            data = LabelsPCA, colour = \"black\") + \n  theme_bw() +\n  xlab(paste(\"PC1 - \", round(Perc[1], digits = 2), \"%\", sep = \"\")) +\n     ylab(paste(\"PC2 - \", round(Perc[2], digits = 2), \"%\", sep = \"\"))"}]
